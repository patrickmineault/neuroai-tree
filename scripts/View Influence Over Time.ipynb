{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37524, 31)\n",
      "(36948, 31)\n",
      "(36948, 36)\n",
      "(36948, 38)\n",
      "(36948, 40)\n"
     ]
    }
   ],
   "source": [
    "def safe_vector(x):\n",
    "    if x is None:\n",
    "        a = np.zeros(768)\n",
    "        a[0] = 1\n",
    "        return a\n",
    "    else:\n",
    "        return x['vector']\n",
    "\n",
    "\n",
    "df = pd.read_json(\"../data/processed/works.jsonl\", lines=True)\n",
    "print(df.shape)\n",
    "df = df[~df.id.duplicated()]\n",
    "print(df.shape)\n",
    "\n",
    "# Get the classification from OpenAI\n",
    "df_class = pd.read_json(\n",
    "    \"../data/processed/coarse_classification.jsonl\", lines=True\n",
    ")\n",
    "df_class = df_class[~df_class.id.duplicated(keep='last')]\n",
    "df = df.merge(df_class, on=\"id\", how=\"left\")\n",
    "print(df.shape)\n",
    "\n",
    "df_ss = pd.read_json(\"../data/processed/semantic_scholar.jsonl\", lines=True, engine='pyarrow')\n",
    "df_ss['embedding'] = df_ss['result'].map(lambda x: safe_vector(x['embedding']))\n",
    "\n",
    "df_ss[\"ss_cited_by_count\"] = df_ss[\"result\"].map(\n",
    "    lambda x: x[\"citationCount\"]\n",
    ")\n",
    "df_ss = df_ss[[\"id\", \"ss_cited_by_count\", \"embedding\"]]\n",
    "df_ss[~df_ss.id.duplicated()]\n",
    "\n",
    "# Do a left join on the paper ID\n",
    "df = df.merge(df_ss, on=\"id\", how=\"left\")\n",
    "print(df.shape)\n",
    "\n",
    "cites = (df[\"oa_neuro_citations\"].values >= 2) | (\n",
    "    df[\"ss_neuro_citations\"].values >= 2\n",
    ")\n",
    "keywords = df[\"keywords_found\"].values >= 1\n",
    "\n",
    "# Get the coarse classification from the keyword-based detection.\n",
    "df_class = pd.read_json(\"../data/processed/categories.jsonl\", lines=True)\n",
    "df_class = df_class[~df_class.id.duplicated(keep='last')]\n",
    "df = df.merge(df_class, on=\"id\", how=\"left\")\n",
    "\n",
    "df_embedding = pd.read_json(\"../data/processed/semantic_embeddings.jsonl\", lines=True)\n",
    "df_embedding = df_embedding[~df_embedding.id.duplicated(keep='last')]\n",
    "df = df.merge(df_embedding, on=\"id\", how=\"left\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "df_ = df[df.openai_category == 'A']\n",
    "X = df_.embedding_y.values.tolist()\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean')\n",
    "labels = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>ids</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>type</th>\n",
       "      <th>open_access</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords_found</th>\n",
       "      <th>oa_neuro_citations</th>\n",
       "      <th>oa_cited_journals</th>\n",
       "      <th>ss_neuro_citations</th>\n",
       "      <th>ss_cited_journals</th>\n",
       "      <th>ss_cited_by_count</th>\n",
       "      <th>embedding_x</th>\n",
       "      <th>openai_category</th>\n",
       "      <th>embedding_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>https://openalex.org/W2133257461</td>\n",
       "      <td>None</td>\n",
       "      <td>Sparse deep belief net model for visual area V2</td>\n",
       "      <td>Sparse deep belief net model for visual area V2</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2133257461...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://a...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Motivated in part by the hierarchical organiza...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>The Journal of Physiology, Vision Research, Vi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Current Biology, Vision Research, Vision Resea...</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>[-4.500461101531982, -1.25899076461792, 3.3881...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.018410556, 0.009638387, 0.0026502125, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>https://openalex.org/W2139047169</td>\n",
       "      <td>None</td>\n",
       "      <td>Saliency Based on Information Maximization</td>\n",
       "      <td>Saliency Based on Information Maximization</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-12-05</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2139047169...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>A model of bottom-up overt attention is propos...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>1224.0</td>\n",
       "      <td>[-0.07067842781543732, -4.51436710357666, 4.31...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.02593223, 0.021043148, 0.02751281000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>https://openalex.org/W2169561119</td>\n",
       "      <td>None</td>\n",
       "      <td>Predicting human gaze using low-level saliency...</td>\n",
       "      <td>Predicting human gaze using low-level saliency...</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2169561119...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://a...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Under natural viewing conditions, human observ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Current Opinion in Neurobiology, Neuropsycholo...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Vision Research, Neuron, Vision Research, Visi...</td>\n",
       "      <td>524.0</td>\n",
       "      <td>[-2.303687810897827, -4.0537495613098145, 2.32...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.014638068, 0.015916208, 0.016736908, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>https://openalex.org/W2964115671</td>\n",
       "      <td>None</td>\n",
       "      <td>Direct Feedback Alignment Provides Learning in...</td>\n",
       "      <td>Direct Feedback Alignment Provides Learning in...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2964115671...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Artificial neural networks are most commonly t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nature Reviews Neuroscience</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nature Reviews Neuroscience</td>\n",
       "      <td>306.0</td>\n",
       "      <td>[-2.3833487033843994, -2.79158353805542, -0.85...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.03812112, 0.011723384, 0.0048892144, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>https://openalex.org/W2114168642</td>\n",
       "      <td>None</td>\n",
       "      <td>One-shot learning by inverting a compositional...</td>\n",
       "      <td>One-shot learning by inverting a compositional...</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2114168642...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://d...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>People can learn a new class from just one exa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Psychological Review, Psychological Review, Co...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Neuropsychologia, NeuroImage, American Journal...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>[-2.631121873855591, -3.3521621227264404, 1.19...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.0048758476, 0.014923152, 0.008936222, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33120</th>\n",
       "      <td>https://openalex.org/W4312527777</td>\n",
       "      <td>https://doi.org/10.1109/cvpr52688.2022.00042</td>\n",
       "      <td>RecDis-SNN: Rectifying Membrane Potential Dist...</td>\n",
       "      <td>RecDis-SNN: Rectifying Membrane Potential Dist...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W4312527777...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>The brain-inspired and event-driven Spiking Ne...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>16.0</td>\n",
       "      <td>[0.4223653972148895, -0.5852596163749695, -1.6...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.03386349, 0.0019470123, 0.0259509400000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34850</th>\n",
       "      <td>https://openalex.org/W3202619090</td>\n",
       "      <td>None</td>\n",
       "      <td>Incorporating Learnable Membrane Time Constant...</td>\n",
       "      <td>Incorporating Learnable Membrane Time Constant...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3202619090...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Spiking Neural Networks (SNNs) have attracted ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>9.0</td>\n",
       "      <td>Neuron, PLoS Comput. Biol., PLoS Comput. Biol....</td>\n",
       "      <td>145.0</td>\n",
       "      <td>[-2.8213627338409424, -0.10472381114959717, -1...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.01688445, 0.026321502, 0.013582172, -0.014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35389</th>\n",
       "      <td>https://openalex.org/W3102040318</td>\n",
       "      <td>https://doi.org/10.1109/iccv48922.2021.00266</td>\n",
       "      <td>Incorporating Learnable Membrane Time Constant...</td>\n",
       "      <td>Incorporating Learnable Membrane Time Constant...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3102040318...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'green', 'oa_url'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Spiking Neural Networks (SNNs) have attracted ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>The Journal of Neuroscience, Nature Neuroscien...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Neuron, PLoS Comput. Biol., PLoS Comput. Biol....</td>\n",
       "      <td>145.0</td>\n",
       "      <td>[-2.8213627338409424, -0.10472381114959717, -1...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.013189553000000001, 0.02633719, 0.00993408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36005</th>\n",
       "      <td>https://openalex.org/W3202425151</td>\n",
       "      <td>https://doi.org/10.1109/iccv48922.2021.00516</td>\n",
       "      <td>HIRE-SNN: Harnessing the Inherent Robustness o...</td>\n",
       "      <td>HIRE-SNN: Harnessing the Inherent Robustness o...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3202425151...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'green', 'oa_url'...</td>\n",
       "      <td>...</td>\n",
       "      <td>Low-latency deep spiking neural networks (SNNs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.8027686476707458, 0.658560037612915, -0.731...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.013812017000000001, 0.016307997, 0.0172334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36253</th>\n",
       "      <td>https://openalex.org/W3186268528</td>\n",
       "      <td>https://doi.org/10.1109/iccv48922.2021.01006</td>\n",
       "      <td>Temporal-wise Attention Spiking Neural Network...</td>\n",
       "      <td>Temporal-wise Attention Spiking Neural Network...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3186268528...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'green', 'oa_url'...</td>\n",
       "      <td>...</td>\n",
       "      <td>How to effectively and efficiently deal with s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>38.0</td>\n",
       "      <td>[-1.2768681049346924, -3.145805597305298, 1.43...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.034791242, 0.00456774, 0.03031729, -0.0062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "127    https://openalex.org/W2133257461  \\\n",
       "146    https://openalex.org/W2139047169   \n",
       "438    https://openalex.org/W2169561119   \n",
       "722    https://openalex.org/W2964115671   \n",
       "773    https://openalex.org/W2114168642   \n",
       "...                                 ...   \n",
       "33120  https://openalex.org/W4312527777   \n",
       "34850  https://openalex.org/W3202619090   \n",
       "35389  https://openalex.org/W3102040318   \n",
       "36005  https://openalex.org/W3202425151   \n",
       "36253  https://openalex.org/W3186268528   \n",
       "\n",
       "                                                doi   \n",
       "127                                            None  \\\n",
       "146                                            None   \n",
       "438                                            None   \n",
       "722                                            None   \n",
       "773                                            None   \n",
       "...                                             ...   \n",
       "33120  https://doi.org/10.1109/cvpr52688.2022.00042   \n",
       "34850                                          None   \n",
       "35389  https://doi.org/10.1109/iccv48922.2021.00266   \n",
       "36005  https://doi.org/10.1109/iccv48922.2021.00516   \n",
       "36253  https://doi.org/10.1109/iccv48922.2021.01006   \n",
       "\n",
       "                                                   title   \n",
       "127      Sparse deep belief net model for visual area V2  \\\n",
       "146           Saliency Based on Information Maximization   \n",
       "438    Predicting human gaze using low-level saliency...   \n",
       "722    Direct Feedback Alignment Provides Learning in...   \n",
       "773    One-shot learning by inverting a compositional...   \n",
       "...                                                  ...   \n",
       "33120  RecDis-SNN: Rectifying Membrane Potential Dist...   \n",
       "34850  Incorporating Learnable Membrane Time Constant...   \n",
       "35389  Incorporating Learnable Membrane Time Constant...   \n",
       "36005  HIRE-SNN: Harnessing the Inherent Robustness o...   \n",
       "36253  Temporal-wise Attention Spiking Neural Network...   \n",
       "\n",
       "                                            display_name  publication_year   \n",
       "127      Sparse deep belief net model for visual area V2              2007  \\\n",
       "146           Saliency Based on Information Maximization              2005   \n",
       "438    Predicting human gaze using low-level saliency...              2007   \n",
       "722    Direct Feedback Alignment Provides Learning in...              2016   \n",
       "773    One-shot learning by inverting a compositional...              2013   \n",
       "...                                                  ...               ...   \n",
       "33120  RecDis-SNN: Rectifying Membrane Potential Dist...              2022   \n",
       "34850  Incorporating Learnable Membrane Time Constant...              2020   \n",
       "35389  Incorporating Learnable Membrane Time Constant...              2021   \n",
       "36005  HIRE-SNN: Harnessing the Inherent Robustness o...              2021   \n",
       "36253  Temporal-wise Attention Spiking Neural Network...              2021   \n",
       "\n",
       "      publication_date                                                ids   \n",
       "127         2007-12-03  {'openalex': 'https://openalex.org/W2133257461...  \\\n",
       "146         2005-12-05  {'openalex': 'https://openalex.org/W2139047169...   \n",
       "438         2007-12-03  {'openalex': 'https://openalex.org/W2169561119...   \n",
       "722         2016-01-01  {'openalex': 'https://openalex.org/W2964115671...   \n",
       "773         2013-12-05  {'openalex': 'https://openalex.org/W2114168642...   \n",
       "...                ...                                                ...   \n",
       "33120       2022-06-01  {'openalex': 'https://openalex.org/W4312527777...   \n",
       "34850       2020-07-11  {'openalex': 'https://openalex.org/W3202619090...   \n",
       "35389       2021-10-01  {'openalex': 'https://openalex.org/W3102040318...   \n",
       "36005       2021-10-01  {'openalex': 'https://openalex.org/W3202425151...   \n",
       "36253       2021-10-01  {'openalex': 'https://openalex.org/W3186268528...   \n",
       "\n",
       "                                        primary_location                 type   \n",
       "127    {'is_oa': False, 'landing_page_url': 'http://a...  proceedings-article  \\\n",
       "146    {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "438    {'is_oa': False, 'landing_page_url': 'http://a...  proceedings-article   \n",
       "722    {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "773    {'is_oa': False, 'landing_page_url': 'http://d...  proceedings-article   \n",
       "...                                                  ...                  ...   \n",
       "33120  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "34850  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "35389  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "36005  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "36253  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "\n",
       "                                             open_access  ...   \n",
       "127    {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...  \\\n",
       "146    {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "438    {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "722    {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "773    {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "...                                                  ...  ...   \n",
       "33120  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "34850  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "35389  {'is_oa': True, 'oa_status': 'green', 'oa_url'...  ...   \n",
       "36005  {'is_oa': True, 'oa_status': 'green', 'oa_url'...  ...   \n",
       "36253  {'is_oa': True, 'oa_status': 'green', 'oa_url'...  ...   \n",
       "\n",
       "                                                abstract keywords_found   \n",
       "127    Motivated in part by the hierarchical organiza...            5.0  \\\n",
       "146    A model of bottom-up overt attention is propos...            2.0   \n",
       "438    Under natural viewing conditions, human observ...            0.0   \n",
       "722    Artificial neural networks are most commonly t...            1.0   \n",
       "773    People can learn a new class from just one exa...            0.0   \n",
       "...                                                  ...            ...   \n",
       "33120  The brain-inspired and event-driven Spiking Ne...            1.0   \n",
       "34850  Spiking Neural Networks (SNNs) have attracted ...            3.0   \n",
       "35389  Spiking Neural Networks (SNNs) have attracted ...            3.0   \n",
       "36005  Low-latency deep spiking neural networks (SNNs...            1.0   \n",
       "36253  How to effectively and efficiently deal with s...            1.0   \n",
       "\n",
       "      oa_neuro_citations                                  oa_cited_journals   \n",
       "127                  8.0  The Journal of Physiology, Vision Research, Vi...  \\\n",
       "146                  0.0                                                      \n",
       "438                 12.0  Current Opinion in Neurobiology, Neuropsycholo...   \n",
       "722                  1.0                        Nature Reviews Neuroscience   \n",
       "773                  9.0  Psychological Review, Psychological Review, Co...   \n",
       "...                  ...                                                ...   \n",
       "33120                0.0                                                      \n",
       "34850                0.0                                                      \n",
       "35389               10.0  The Journal of Neuroscience, Nature Neuroscien...   \n",
       "36005                0.0                                                      \n",
       "36253                0.0                                                      \n",
       "\n",
       "       ss_neuro_citations                                  ss_cited_journals   \n",
       "127                   5.0  Current Biology, Vision Research, Vision Resea...  \\\n",
       "146                   0.0                                                      \n",
       "438                  12.0  Vision Research, Neuron, Vision Research, Visi...   \n",
       "722                   1.0                        Nature Reviews Neuroscience   \n",
       "773                   4.0  Neuropsychologia, NeuroImage, American Journal...   \n",
       "...                   ...                                                ...   \n",
       "33120                 0.0                                                      \n",
       "34850                 9.0  Neuron, PLoS Comput. Biol., PLoS Comput. Biol....   \n",
       "35389                 9.0  Neuron, PLoS Comput. Biol., PLoS Comput. Biol....   \n",
       "36005                 0.0                                                      \n",
       "36253                 0.0                                                      \n",
       "\n",
       "       ss_cited_by_count                                        embedding_x   \n",
       "127               1066.0  [-4.500461101531982, -1.25899076461792, 3.3881...  \\\n",
       "146               1224.0  [-0.07067842781543732, -4.51436710357666, 4.31...   \n",
       "438                524.0  [-2.303687810897827, -4.0537495613098145, 2.32...   \n",
       "722                306.0  [-2.3833487033843994, -2.79158353805542, -0.85...   \n",
       "773                218.0  [-2.631121873855591, -3.3521621227264404, 1.19...   \n",
       "...                  ...                                                ...   \n",
       "33120               16.0  [0.4223653972148895, -0.5852596163749695, -1.6...   \n",
       "34850              145.0  [-2.8213627338409424, -0.10472381114959717, -1...   \n",
       "35389              145.0  [-2.8213627338409424, -0.10472381114959717, -1...   \n",
       "36005               21.0  [0.8027686476707458, 0.658560037612915, -0.731...   \n",
       "36253               38.0  [-1.2768681049346924, -3.145805597305298, 1.43...   \n",
       "\n",
       "      openai_category                                        embedding_y  \n",
       "127                 A  [-0.018410556, 0.009638387, 0.0026502125, -0.0...  \n",
       "146                 A  [-0.02593223, 0.021043148, 0.02751281000000000...  \n",
       "438                 A  [-0.014638068, 0.015916208, 0.016736908, -0.01...  \n",
       "722                 A  [-0.03812112, 0.011723384, 0.0048892144, -0.00...  \n",
       "773                 A  [-0.0048758476, 0.014923152, 0.008936222, -0.0...  \n",
       "...               ...                                                ...  \n",
       "33120               A  [-0.03386349, 0.0019470123, 0.0259509400000000...  \n",
       "34850               A  [-0.01688445, 0.026321502, 0.013582172, -0.014...  \n",
       "35389               A  [-0.013189553000000001, 0.02633719, 0.00993408...  \n",
       "36005               A  [-0.013812017000000001, 0.016307997, 0.0172334...  \n",
       "36253               A  [-0.034791242, 0.00456774, 0.03031729, -0.0062...  \n",
       "\n",
       "[235 rows x 40 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>ids</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>type</th>\n",
       "      <th>open_access</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords_found</th>\n",
       "      <th>oa_neuro_citations</th>\n",
       "      <th>oa_cited_journals</th>\n",
       "      <th>ss_neuro_citations</th>\n",
       "      <th>ss_cited_journals</th>\n",
       "      <th>ss_cited_by_count</th>\n",
       "      <th>embedding_x</th>\n",
       "      <th>openai_category</th>\n",
       "      <th>embedding_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32521</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32522</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32523</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32524</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32525</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32526</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32527</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32528</th>\n",
       "      <td>https://openalex.org/W3037532699</td>\n",
       "      <td>None</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>Image-to-image Mapping with Many Domains by Sp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3037532699...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsupervised image-to-image translation consis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.672010898590088, -3.6536552906036377, 0.73...</td>\n",
       "      <td>A</td>\n",
       "      <td>[-0.010674138000000001, -0.013286971500000001,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   doi   \n",
       "32521  https://openalex.org/W3037532699  None  \\\n",
       "32522  https://openalex.org/W3037532699  None   \n",
       "32523  https://openalex.org/W3037532699  None   \n",
       "32524  https://openalex.org/W3037532699  None   \n",
       "32525  https://openalex.org/W3037532699  None   \n",
       "32526  https://openalex.org/W3037532699  None   \n",
       "32527  https://openalex.org/W3037532699  None   \n",
       "32528  https://openalex.org/W3037532699  None   \n",
       "\n",
       "                                                   title   \n",
       "32521  Image-to-image Mapping with Many Domains by Sp...  \\\n",
       "32522  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32523  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32524  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32525  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32526  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32527  Image-to-image Mapping with Many Domains by Sp...   \n",
       "32528  Image-to-image Mapping with Many Domains by Sp...   \n",
       "\n",
       "                                            display_name  publication_year   \n",
       "32521  Image-to-image Mapping with Many Domains by Sp...              2020  \\\n",
       "32522  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32523  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32524  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32525  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32526  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32527  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "32528  Image-to-image Mapping with Many Domains by Sp...              2020   \n",
       "\n",
       "      publication_date                                                ids   \n",
       "32521       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...  \\\n",
       "32522       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32523       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32524       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32525       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32526       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32527       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "32528       2020-06-23  {'openalex': 'https://openalex.org/W3037532699...   \n",
       "\n",
       "                                        primary_location                 type   \n",
       "32521  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article  \\\n",
       "32522  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32523  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32524  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32525  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32526  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32527  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "32528  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "\n",
       "                                             open_access  ...   \n",
       "32521  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...  \\\n",
       "32522  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32523  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32524  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32525  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32526  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32527  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "32528  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "\n",
       "                                                abstract keywords_found   \n",
       "32521  Unsupervised image-to-image translation consis...            2.0  \\\n",
       "32522  Unsupervised image-to-image translation consis...            2.0   \n",
       "32523  Unsupervised image-to-image translation consis...            2.0   \n",
       "32524  Unsupervised image-to-image translation consis...            2.0   \n",
       "32525  Unsupervised image-to-image translation consis...            2.0   \n",
       "32526  Unsupervised image-to-image translation consis...            2.0   \n",
       "32527  Unsupervised image-to-image translation consis...            2.0   \n",
       "32528  Unsupervised image-to-image translation consis...            2.0   \n",
       "\n",
       "      oa_neuro_citations  oa_cited_journals  ss_neuro_citations   \n",
       "32521                0.0                                    0.0  \\\n",
       "32522                0.0                                    0.0   \n",
       "32523                0.0                                    0.0   \n",
       "32524                0.0                                    0.0   \n",
       "32525                0.0                                    0.0   \n",
       "32526                0.0                                    0.0   \n",
       "32527                0.0                                    0.0   \n",
       "32528                0.0                                    0.0   \n",
       "\n",
       "      ss_cited_journals  ss_cited_by_count   \n",
       "32521                                  0.0  \\\n",
       "32522                                  0.0   \n",
       "32523                                  0.0   \n",
       "32524                                  0.0   \n",
       "32525                                  0.0   \n",
       "32526                                  0.0   \n",
       "32527                                  0.0   \n",
       "32528                                  0.0   \n",
       "\n",
       "                                             embedding_x openai_category   \n",
       "32521  [-1.672010898590088, -3.6536552906036377, 0.73...               A  \\\n",
       "32522  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32523  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32524  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32525  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32526  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32527  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "32528  [-1.672010898590088, -3.6536552906036377, 0.73...               A   \n",
       "\n",
       "                                             embedding_y  \n",
       "32521  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32522  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32523  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32524  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32525  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32526  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32527  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "32528  [-0.010674138000000001, -0.013286971500000001,...  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_[labels==1].sort_values('ss_cited_by_count', ascending=False)\n",
    "#(labels == 0).mean()\n",
    "#labels == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>ids</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>type</th>\n",
       "      <th>open_access</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords_found</th>\n",
       "      <th>oa_neuro_citations</th>\n",
       "      <th>oa_cited_journals</th>\n",
       "      <th>ss_neuro_citations</th>\n",
       "      <th>ss_cited_journals</th>\n",
       "      <th>ss_cited_by_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>openai_category</th>\n",
       "      <th>axis_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>https://openalex.org/W2143938301</td>\n",
       "      <td>None</td>\n",
       "      <td>Modeling Saccadic Targeting in Visual Search</td>\n",
       "      <td>Modeling Saccadic Targeting in Visual Search</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-11-27</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2143938301...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://p...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual cognition depends critically on the abi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cognitive Psychology, Cognitive Psychology, Be...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Behavioral and Brain Sciences, Cognitive Psych...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[-5.353053092956543, -2.685553789138794, 2.468...</td>\n",
       "      <td>A</td>\n",
       "      <td>62.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>https://openalex.org/W2963463006</td>\n",
       "      <td>None</td>\n",
       "      <td>Task-driven convolutional recurrent models of ...</td>\n",
       "      <td>Task-driven convolutional recurrent models of ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2963463006...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Feed-forward convolutional neural networks (CN...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "      <td>Nature Neuroscience, Nature Neuroscience, PLoS...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>[-2.548363447189331, -2.1441657543182373, 3.11...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.957815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>https://openalex.org/W2165217178</td>\n",
       "      <td>None</td>\n",
       "      <td>Top-Down Control of Visual Attention: A Ration...</td>\n",
       "      <td>Top-Down Control of Visual Attention: A Ration...</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-12-05</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2165217178...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Theories of visual attention commonly posit th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Psychonomic Bulletin &amp; Review, Journal of Expe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Memory &amp; Cognition, Journal of Experimental Ps...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[-4.331010818481445, -4.602914333343506, 2.962...</td>\n",
       "      <td>A</td>\n",
       "      <td>63.876539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>https://openalex.org/W2120078010</td>\n",
       "      <td>None</td>\n",
       "      <td>VISIT: A Neural Model of Covert Visual Attention</td>\n",
       "      <td>VISIT: A Neural Model of Covert Visual Attention</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991-12-02</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2120078010...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://p...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual attention is the ability to dynamically...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Annual Review of Neuroscience, The Journal of ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual Review of Neuroscience, Journal of Expe...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[-4.208893775939941, -1.9414870738983154, 3.36...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.439898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>https://openalex.org/W3103272223</td>\n",
       "      <td>None</td>\n",
       "      <td>Simulating a Primary Visual Cortex at the Fron...</td>\n",
       "      <td>Simulating a Primary Visual Cortex at the Fron...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3103272223...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Abstract Current state-of-the-art object recog...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>16.0</td>\n",
       "      <td>Neuron, Nature Neuroscience, Neuron, Nature Ne...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[-1.0430970191955566, -1.5302278995513916, 4.2...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.901703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>https://openalex.org/W2143558878</td>\n",
       "      <td>None</td>\n",
       "      <td>Perceiving Complex Visual Scenes: An Oscillato...</td>\n",
       "      <td>Perceiving Complex Visual Scenes: An Oscillato...</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992-11-30</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2143558878...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Which processes underly our ability to quickly...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Journal of Experimental Psychology: General, T...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Journal of Cognitive Neuroscience</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[-1.9083625078201294, -4.182024955749512, 4.19...</td>\n",
       "      <td>A</td>\n",
       "      <td>63.833821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>https://openalex.org/W2138665783</td>\n",
       "      <td>None</td>\n",
       "      <td>Correlates of Attention in a Model of Dynamic ...</td>\n",
       "      <td>Correlates of Attention in a Model of Dynamic ...</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-12-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2138665783...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://h...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Given a set of objects in the visual field, ho...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Annual Review of Neuroscience, The Journal of ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Current Biology, Annual Review of Neuroscience</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[-4.240202903747559, -1.8368239402770996, 3.39...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.108883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>https://openalex.org/W2962779158</td>\n",
       "      <td>None</td>\n",
       "      <td>How deep is the feature analysis underlying ra...</td>\n",
       "      <td>How deep is the feature analysis underlying ra...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2962779158...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rapid categorization paradigms have a long his...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Neuron, Nature Neuroscience, Nature Reviews Ne...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nature Neuroscience, NeuroImage, PLoS Comput. ...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>[-4.996105670928955, -2.514051914215088, 2.323...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.142673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>https://openalex.org/W2133713135</td>\n",
       "      <td>None</td>\n",
       "      <td>A Model of Recurrent Interactions in Primary V...</td>\n",
       "      <td>A Model of Recurrent Interactions in Primary V...</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996-12-03</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2133713135...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>A general feature of the cerebral cortex is it...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Journal of Physiology</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>11.0</td>\n",
       "      <td>[-1.568152666091919, 0.6793261766433716, 4.842...</td>\n",
       "      <td>A</td>\n",
       "      <td>68.585963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8641</th>\n",
       "      <td>https://openalex.org/W3212301316</td>\n",
       "      <td>None</td>\n",
       "      <td>Towards robust vision by multi-task learning o...</td>\n",
       "      <td>Towards robust vision by multi-task learning o...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3212301316...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Deep neural networks set the state-of-the-art ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neuron, Nature Neuroscience, Neuron, Nature Ne...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[-1.3680791854858398, -3.3585171699523926, 3.3...</td>\n",
       "      <td>A</td>\n",
       "      <td>73.184808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8868</th>\n",
       "      <td>https://openalex.org/W2120707780</td>\n",
       "      <td>None</td>\n",
       "      <td>A Neurodynamical Approach to Visual Attention</td>\n",
       "      <td>A Neurodynamical Approach to Visual Attention</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-11-29</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2120707780...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>The psychophysical evidence for originates mai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Psychological Review, Psychological Review, Jo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Journal of Cognitive Neuroscience</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-4.9303436279296875, -2.6683669090270996, 4.5...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.874678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>https://openalex.org/W2964145162</td>\n",
       "      <td>None</td>\n",
       "      <td>Deep Gaze I: Boosting Saliency Prediction with...</td>\n",
       "      <td>Deep Gaze I: Boosting Saliency Prediction with...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2964145162...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Recent results suggest that state-of-the-art s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>Journal of Vision, Journal of Vision, Journal ...</td>\n",
       "      <td>356.0</td>\n",
       "      <td>[-0.5818657875061035, -3.939054489135742, 0.58...</td>\n",
       "      <td>A</td>\n",
       "      <td>65.887619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18858</th>\n",
       "      <td>https://openalex.org/W2963326422</td>\n",
       "      <td>None</td>\n",
       "      <td>A Unified Theory of Early Visual Representatio...</td>\n",
       "      <td>A Unified Theory of Early Visual Representatio...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2963326422...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>The vertebrate visual system is hierarchically...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>8.0</td>\n",
       "      <td>Neuron, Journal of Vision, Vision Research, Na...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>[-2.9844889640808105, -3.0776877403259277, 3.9...</td>\n",
       "      <td>A</td>\n",
       "      <td>71.640036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>https://openalex.org/W2892910436</td>\n",
       "      <td>None</td>\n",
       "      <td>A rotation-equivariant convolutional neural ne...</td>\n",
       "      <td>A rotation-equivariant convolutional neural ne...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2892910436...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Classical models describe primary visual corte...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>9.0</td>\n",
       "      <td>Journal of Vision, Current Biology, PLoS Compu...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[-3.7848737239837646, -2.4665281772613525, 1.7...</td>\n",
       "      <td>A</td>\n",
       "      <td>69.512196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>https://openalex.org/W3005950863</td>\n",
       "      <td>None</td>\n",
       "      <td>Rotation-invariant clustering of neuronal resp...</td>\n",
       "      <td>Rotation-invariant clustering of neuronal resp...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W3005950863...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://w...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Similar to a convolutional neural network (CNN...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>Journal of Vision, PLoS Comput. Biol., Annual ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[-4.055734157562256, -2.5337791442871094, 5.02...</td>\n",
       "      <td>A</td>\n",
       "      <td>69.463351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19540</th>\n",
       "      <td>https://openalex.org/W2963428053</td>\n",
       "      <td>None</td>\n",
       "      <td>Efficient Visual Coding: From Retina To V2</td>\n",
       "      <td>Efficient Visual Coding: From Retina To V2</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2963428053...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>The human visual system has a hierarchical str...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>Nature Neuroscience, Behavioral and Brain Scie...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-3.37908935546875, -1.7475124597549438, 3.610...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.933005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>https://openalex.org/W2996755496</td>\n",
       "      <td>None</td>\n",
       "      <td>Rotation-invariant clustering of functional ce...</td>\n",
       "      <td>Rotation-invariant clustering of functional ce...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2996755496...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'https://...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Similar to a convolutional neural network (CNN...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual Review of Neuroscience, Journal of Vision</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Journal of Vision, PLoS Comput. Biol., Annual ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-4.240407466888428, -3.203091621398926, 3.666...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.348358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>https://openalex.org/W2788164053</td>\n",
       "      <td>https://doi.org/10.1609/aaai.v32i1.12238</td>\n",
       "      <td>Lateral Inhibition-Inspired Convolutional Neur...</td>\n",
       "      <td>Lateral Inhibition-Inspired Convolutional Neur...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2788164053...</td>\n",
       "      <td>{'is_oa': True, 'landing_page_url': 'https://d...</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'bronze', 'oa_url...</td>\n",
       "      <td>...</td>\n",
       "      <td>Lateral inhibition in top-down feedback is wid...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual Review of Neuroscience, Vision Research</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vision Research, Vision Research, Annual Revie...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[-1.5111074447631836, -2.939633369445801, 1.98...</td>\n",
       "      <td>A</td>\n",
       "      <td>66.333516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31759</th>\n",
       "      <td>https://openalex.org/W2900894420</td>\n",
       "      <td>None</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2900894420...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://e...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Lateral connections in the primary visual cort...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>The Journal of Physiology, Psychological Revie...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Vision Research, Vision Research, Vision Resea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-2.170576572418213, -1.151090383529663, 3.888...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.337003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31760</th>\n",
       "      <td>https://openalex.org/W2900894420</td>\n",
       "      <td>None</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2900894420...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://e...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Lateral connections in the primary visual cort...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>The Journal of Physiology, Psychological Revie...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Vision Research, Vision Research, Vision Resea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-2.170576572418213, -1.151090383529663, 3.888...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.337003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33629</th>\n",
       "      <td>https://openalex.org/W2900894420</td>\n",
       "      <td>None</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2900894420...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://e...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Lateral connections in the primary visual cort...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>The Journal of Physiology, Psychological Revie...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Vision Research, Vision Research, Vision Resea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-2.170576572418213, -1.151090383529663, 3.888...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.337003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33630</th>\n",
       "      <td>https://openalex.org/W2900894420</td>\n",
       "      <td>None</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>A Neurodynamic model of Saliency prediction in V1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>{'openalex': 'https://openalex.org/W2900894420...</td>\n",
       "      <td>{'is_oa': False, 'landing_page_url': 'http://e...</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>...</td>\n",
       "      <td>Lateral connections in the primary visual cort...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>The Journal of Physiology, Psychological Revie...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Vision Research, Vision Research, Vision Resea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[-2.170576572418213, -1.151090383529663, 3.888...</td>\n",
       "      <td>A</td>\n",
       "      <td>67.337003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "2812   https://openalex.org/W2143938301  \\\n",
       "3255   https://openalex.org/W2963463006   \n",
       "4323   https://openalex.org/W2165217178   \n",
       "4989   https://openalex.org/W2120078010   \n",
       "5222   https://openalex.org/W3103272223   \n",
       "5651   https://openalex.org/W2143558878   \n",
       "6004   https://openalex.org/W2138665783   \n",
       "6135   https://openalex.org/W2962779158   \n",
       "6400   https://openalex.org/W2133713135   \n",
       "8641   https://openalex.org/W3212301316   \n",
       "8868   https://openalex.org/W2120707780   \n",
       "17620  https://openalex.org/W2964145162   \n",
       "18858  https://openalex.org/W2963326422   \n",
       "18975  https://openalex.org/W2892910436   \n",
       "19348  https://openalex.org/W3005950863   \n",
       "19540  https://openalex.org/W2963428053   \n",
       "19607  https://openalex.org/W2996755496   \n",
       "23441  https://openalex.org/W2788164053   \n",
       "31759  https://openalex.org/W2900894420   \n",
       "31760  https://openalex.org/W2900894420   \n",
       "33629  https://openalex.org/W2900894420   \n",
       "33630  https://openalex.org/W2900894420   \n",
       "\n",
       "                                            doi   \n",
       "2812                                       None  \\\n",
       "3255                                       None   \n",
       "4323                                       None   \n",
       "4989                                       None   \n",
       "5222                                       None   \n",
       "5651                                       None   \n",
       "6004                                       None   \n",
       "6135                                       None   \n",
       "6400                                       None   \n",
       "8641                                       None   \n",
       "8868                                       None   \n",
       "17620                                      None   \n",
       "18858                                      None   \n",
       "18975                                      None   \n",
       "19348                                      None   \n",
       "19540                                      None   \n",
       "19607                                      None   \n",
       "23441  https://doi.org/10.1609/aaai.v32i1.12238   \n",
       "31759                                      None   \n",
       "31760                                      None   \n",
       "33629                                      None   \n",
       "33630                                      None   \n",
       "\n",
       "                                                   title   \n",
       "2812        Modeling Saccadic Targeting in Visual Search  \\\n",
       "3255   Task-driven convolutional recurrent models of ...   \n",
       "4323   Top-Down Control of Visual Attention: A Ration...   \n",
       "4989    VISIT: A Neural Model of Covert Visual Attention   \n",
       "5222   Simulating a Primary Visual Cortex at the Fron...   \n",
       "5651   Perceiving Complex Visual Scenes: An Oscillato...   \n",
       "6004   Correlates of Attention in a Model of Dynamic ...   \n",
       "6135   How deep is the feature analysis underlying ra...   \n",
       "6400   A Model of Recurrent Interactions in Primary V...   \n",
       "8641   Towards robust vision by multi-task learning o...   \n",
       "8868       A Neurodynamical Approach to Visual Attention   \n",
       "17620  Deep Gaze I: Boosting Saliency Prediction with...   \n",
       "18858  A Unified Theory of Early Visual Representatio...   \n",
       "18975  A rotation-equivariant convolutional neural ne...   \n",
       "19348  Rotation-invariant clustering of neuronal resp...   \n",
       "19540         Efficient Visual Coding: From Retina To V2   \n",
       "19607  Rotation-invariant clustering of functional ce...   \n",
       "23441  Lateral Inhibition-Inspired Convolutional Neur...   \n",
       "31759  A Neurodynamic model of Saliency prediction in V1   \n",
       "31760  A Neurodynamic model of Saliency prediction in V1   \n",
       "33629  A Neurodynamic model of Saliency prediction in V1   \n",
       "33630  A Neurodynamic model of Saliency prediction in V1   \n",
       "\n",
       "                                            display_name  publication_year   \n",
       "2812        Modeling Saccadic Targeting in Visual Search              1995  \\\n",
       "3255   Task-driven convolutional recurrent models of ...              2018   \n",
       "4323   Top-Down Control of Visual Attention: A Ration...              2005   \n",
       "4989    VISIT: A Neural Model of Covert Visual Attention              1991   \n",
       "5222   Simulating a Primary Visual Cortex at the Fron...              2020   \n",
       "5651   Perceiving Complex Visual Scenes: An Oscillato...              1992   \n",
       "6004   Correlates of Attention in a Model of Dynamic ...              1997   \n",
       "6135   How deep is the feature analysis underlying ra...              2016   \n",
       "6400   A Model of Recurrent Interactions in Primary V...              1996   \n",
       "8641   Towards robust vision by multi-task learning o...              2021   \n",
       "8868       A Neurodynamical Approach to Visual Attention              1999   \n",
       "17620  Deep Gaze I: Boosting Saliency Prediction with...              2015   \n",
       "18858  A Unified Theory of Early Visual Representatio...              2019   \n",
       "18975  A rotation-equivariant convolutional neural ne...              2018   \n",
       "19348  Rotation-invariant clustering of neuronal resp...              2020   \n",
       "19540         Efficient Visual Coding: From Retina To V2              2013   \n",
       "19607  Rotation-invariant clustering of functional ce...              2020   \n",
       "23441  Lateral Inhibition-Inspired Convolutional Neur...              2018   \n",
       "31759  A Neurodynamic model of Saliency prediction in V1              2018   \n",
       "31760  A Neurodynamic model of Saliency prediction in V1              2018   \n",
       "33629  A Neurodynamic model of Saliency prediction in V1              2018   \n",
       "33630  A Neurodynamic model of Saliency prediction in V1              2018   \n",
       "\n",
       "      publication_date                                                ids   \n",
       "2812        1995-11-27  {'openalex': 'https://openalex.org/W2143938301...  \\\n",
       "3255        2018-12-01  {'openalex': 'https://openalex.org/W2963463006...   \n",
       "4323        2005-12-05  {'openalex': 'https://openalex.org/W2165217178...   \n",
       "4989        1991-12-02  {'openalex': 'https://openalex.org/W2120078010...   \n",
       "5222        2020-01-01  {'openalex': 'https://openalex.org/W3103272223...   \n",
       "5651        1992-11-30  {'openalex': 'https://openalex.org/W2143558878...   \n",
       "6004        1997-12-01  {'openalex': 'https://openalex.org/W2138665783...   \n",
       "6135        2016-12-05  {'openalex': 'https://openalex.org/W2962779158...   \n",
       "6400        1996-12-03  {'openalex': 'https://openalex.org/W2133713135...   \n",
       "8641        2021-12-06  {'openalex': 'https://openalex.org/W3212301316...   \n",
       "8868        1999-11-29  {'openalex': 'https://openalex.org/W2120707780...   \n",
       "17620       2015-05-01  {'openalex': 'https://openalex.org/W2964145162...   \n",
       "18858       2019-01-01  {'openalex': 'https://openalex.org/W2963326422...   \n",
       "18975       2018-09-27  {'openalex': 'https://openalex.org/W2892910436...   \n",
       "19348       2020-04-01  {'openalex': 'https://openalex.org/W3005950863...   \n",
       "19540       2013-12-25  {'openalex': 'https://openalex.org/W2963428053...   \n",
       "19607       2020-04-30  {'openalex': 'https://openalex.org/W2996755496...   \n",
       "23441       2018-01-01  {'openalex': 'https://openalex.org/W2788164053...   \n",
       "31759       2018-11-15  {'openalex': 'https://openalex.org/W2900894420...   \n",
       "31760       2018-11-15  {'openalex': 'https://openalex.org/W2900894420...   \n",
       "33629       2018-11-15  {'openalex': 'https://openalex.org/W2900894420...   \n",
       "33630       2018-11-15  {'openalex': 'https://openalex.org/W2900894420...   \n",
       "\n",
       "                                        primary_location                 type   \n",
       "2812   {'is_oa': False, 'landing_page_url': 'http://p...  proceedings-article  \\\n",
       "3255   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "4323   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "4989   {'is_oa': False, 'landing_page_url': 'http://p...  proceedings-article   \n",
       "5222   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "5651   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "6004   {'is_oa': False, 'landing_page_url': 'http://h...  proceedings-article   \n",
       "6135   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "6400   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "8641   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "8868   {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "17620  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "18858  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "18975  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "19348  {'is_oa': False, 'landing_page_url': 'http://w...  proceedings-article   \n",
       "19540  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "19607  {'is_oa': False, 'landing_page_url': 'https://...  proceedings-article   \n",
       "23441  {'is_oa': True, 'landing_page_url': 'https://d...      journal-article   \n",
       "31759  {'is_oa': False, 'landing_page_url': 'http://e...  proceedings-article   \n",
       "31760  {'is_oa': False, 'landing_page_url': 'http://e...  proceedings-article   \n",
       "33629  {'is_oa': False, 'landing_page_url': 'http://e...  proceedings-article   \n",
       "33630  {'is_oa': False, 'landing_page_url': 'http://e...  proceedings-article   \n",
       "\n",
       "                                             open_access  ...   \n",
       "2812   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...  \\\n",
       "3255   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "4323   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "4989   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "5222   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "5651   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "6004   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "6135   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "6400   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "8641   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "8868   {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "17620  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "18858  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "18975  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "19348  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "19540  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "19607  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "23441  {'is_oa': True, 'oa_status': 'bronze', 'oa_url...  ...   \n",
       "31759  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "31760  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "33629  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "33630  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...  ...   \n",
       "\n",
       "                                                abstract keywords_found   \n",
       "2812   Visual cognition depends critically on the abi...            0.0  \\\n",
       "3255   Feed-forward convolutional neural networks (CN...            3.0   \n",
       "4323   Theories of visual attention commonly posit th...            0.0   \n",
       "4989   Visual attention is the ability to dynamically...            4.0   \n",
       "5222   Abstract Current state-of-the-art object recog...            5.0   \n",
       "5651   Which processes underly our ability to quickly...            1.0   \n",
       "6004   Given a set of objects in the visual field, ho...            3.0   \n",
       "6135   Rapid categorization paradigms have a long his...            3.0   \n",
       "6400   A general feature of the cerebral cortex is it...            4.0   \n",
       "8641   Deep neural networks set the state-of-the-art ...            5.0   \n",
       "8868   The psychophysical evidence for originates mai...            1.0   \n",
       "17620  Recent results suggest that state-of-the-art s...            1.0   \n",
       "18858  The vertebrate visual system is hierarchically...            4.0   \n",
       "18975  Classical models describe primary visual corte...            2.0   \n",
       "19348  Similar to a convolutional neural network (CNN...            3.0   \n",
       "19540  The human visual system has a hierarchical str...            5.0   \n",
       "19607  Similar to a convolutional neural network (CNN...            3.0   \n",
       "23441  Lateral inhibition in top-down feedback is wid...            0.0   \n",
       "31759  Lateral connections in the primary visual cort...            3.0   \n",
       "31760  Lateral connections in the primary visual cort...            3.0   \n",
       "33629  Lateral connections in the primary visual cort...            3.0   \n",
       "33630  Lateral connections in the primary visual cort...            3.0   \n",
       "\n",
       "      oa_neuro_citations                                  oa_cited_journals   \n",
       "2812                 4.0  Cognitive Psychology, Cognitive Psychology, Be...  \\\n",
       "3255                 0.0                                                      \n",
       "4323                 6.0  Psychonomic Bulletin & Review, Journal of Expe...   \n",
       "4989                 5.0  Annual Review of Neuroscience, The Journal of ...   \n",
       "5222                 0.0                                                      \n",
       "5651                 4.0  Journal of Experimental Psychology: General, T...   \n",
       "6004                 3.0  Annual Review of Neuroscience, The Journal of ...   \n",
       "6135                 5.0  Neuron, Nature Neuroscience, Nature Reviews Ne...   \n",
       "6400                 1.0                          The Journal of Physiology   \n",
       "8641                 0.0                                                      \n",
       "8868                 3.0  Psychological Review, Psychological Review, Jo...   \n",
       "17620                0.0                                                      \n",
       "18858                0.0                                                      \n",
       "18975                0.0                                                      \n",
       "19348                0.0                                                      \n",
       "19540                0.0                                                      \n",
       "19607                2.0   Annual Review of Neuroscience, Journal of Vision   \n",
       "23441                2.0     Annual Review of Neuroscience, Vision Research   \n",
       "31759               37.0  The Journal of Physiology, Psychological Revie...   \n",
       "31760               37.0  The Journal of Physiology, Psychological Revie...   \n",
       "33629               37.0  The Journal of Physiology, Psychological Revie...   \n",
       "33630               37.0  The Journal of Physiology, Psychological Revie...   \n",
       "\n",
       "       ss_neuro_citations                                  ss_cited_journals   \n",
       "2812                  3.0  Behavioral and Brain Sciences, Cognitive Psych...  \\\n",
       "3255                  7.0  Nature Neuroscience, Nature Neuroscience, PLoS...   \n",
       "4323                  4.0  Memory & Cognition, Journal of Experimental Ps...   \n",
       "4989                  2.0  Annual Review of Neuroscience, Journal of Expe...   \n",
       "5222                 16.0  Neuron, Nature Neuroscience, Neuron, Nature Ne...   \n",
       "5651                  1.0                  Journal of Cognitive Neuroscience   \n",
       "6004                  2.0     Current Biology, Annual Review of Neuroscience   \n",
       "6135                  5.0  Nature Neuroscience, NeuroImage, PLoS Comput. ...   \n",
       "6400                  0.0                                                      \n",
       "8641                  7.0  Neuron, Nature Neuroscience, Neuron, Nature Ne...   \n",
       "8868                  1.0                  Journal of Cognitive Neuroscience   \n",
       "17620                 5.0  Journal of Vision, Journal of Vision, Journal ...   \n",
       "18858                 8.0  Neuron, Journal of Vision, Vision Research, Na...   \n",
       "18975                 9.0  Journal of Vision, Current Biology, PLoS Compu...   \n",
       "19348                 3.0  Journal of Vision, PLoS Comput. Biol., Annual ...   \n",
       "19540                 2.0  Nature Neuroscience, Behavioral and Brain Scie...   \n",
       "19607                 4.0  Journal of Vision, PLoS Comput. Biol., Annual ...   \n",
       "23441                 3.0  Vision Research, Vision Research, Annual Revie...   \n",
       "31759                32.0  Vision Research, Vision Research, Vision Resea...   \n",
       "31760                32.0  Vision Research, Vision Research, Vision Resea...   \n",
       "33629                32.0  Vision Research, Vision Research, Vision Resea...   \n",
       "33630                32.0  Vision Research, Vision Research, Vision Resea...   \n",
       "\n",
       "       ss_cited_by_count                                          embedding   \n",
       "2812                61.0  [-5.353053092956543, -2.685553789138794, 2.468...  \\\n",
       "3255               121.0  [-2.548363447189331, -2.1441657543182373, 3.11...   \n",
       "4323                34.0  [-4.331010818481445, -4.602914333343506, 2.962...   \n",
       "4989                32.0  [-4.208893775939941, -1.9414870738983154, 3.36...   \n",
       "5222               106.0  [-1.0430970191955566, -1.5302278995513916, 4.2...   \n",
       "5651                18.0  [-1.9083625078201294, -4.182024955749512, 4.19...   \n",
       "6004                13.0  [-4.240202903747559, -1.8368239402770996, 3.39...   \n",
       "6135                48.0  [-4.996105670928955, -2.514051914215088, 2.323...   \n",
       "6400                11.0  [-1.568152666091919, 0.6793261766433716, 4.842...   \n",
       "8641                21.0  [-1.3680791854858398, -3.3585171699523926, 3.3...   \n",
       "8868                 0.0  [-4.9303436279296875, -2.6683669090270996, 4.5...   \n",
       "17620              356.0  [-0.5818657875061035, -3.939054489135742, 0.58...   \n",
       "18858               56.0  [-2.9844889640808105, -3.0776877403259277, 3.9...   \n",
       "18975               30.0  [-3.7848737239837646, -2.4665281772613525, 1.7...   \n",
       "19348                5.0  [-4.055734157562256, -2.5337791442871094, 5.02...   \n",
       "19540                6.0  [-3.37908935546875, -1.7475124597549438, 3.610...   \n",
       "19607                0.0  [-4.240407466888428, -3.203091621398926, 3.666...   \n",
       "23441               26.0  [-1.5111074447631836, -2.939633369445801, 1.98...   \n",
       "31759                6.0  [-2.170576572418213, -1.151090383529663, 3.888...   \n",
       "31760                6.0  [-2.170576572418213, -1.151090383529663, 3.888...   \n",
       "33629                6.0  [-2.170576572418213, -1.151090383529663, 3.888...   \n",
       "33630                6.0  [-2.170576572418213, -1.151090383529663, 3.888...   \n",
       "\n",
       "      openai_category axis_aligned  \n",
       "2812                A    62.100586  \n",
       "3255                A    66.957815  \n",
       "4323                A    63.876539  \n",
       "4989                A    66.439898  \n",
       "5222                A    66.901703  \n",
       "5651                A    63.833821  \n",
       "6004                A    67.108883  \n",
       "6135                A    66.142673  \n",
       "6400                A    68.585963  \n",
       "8641                A    73.184808  \n",
       "8868                A    67.874678  \n",
       "17620               A    65.887619  \n",
       "18858               A    71.640036  \n",
       "18975               A    69.512196  \n",
       "19348               A    69.463351  \n",
       "19540               A    67.933005  \n",
       "19607               A    66.348358  \n",
       "23441               A    66.333516  \n",
       "31759               A    67.337003  \n",
       "31760               A    67.337003  \n",
       "33629               A    67.337003  \n",
       "33630               A    67.337003  \n",
       "\n",
       "[22 rows x 40 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(np.corrcoef(X[labels==0, :]))\n",
    "df_ = df[df.openai_category == 'A']\n",
    "df_[labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 413,
       "width": 561
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"axis_aligned\"] = features @ mean_axis\n",
    "\n",
    "_ = plt.hist(df[~cites].axis_aligned, 100)\n",
    "_ = plt.hist(df[cites].axis_aligned, 100)\n",
    "\n",
    "(df.loc[~cites, 'axis_aligned'] > 60).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operation can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~cites & (df.loc[:, 'axis_aligned'] > 60)].iloc[6].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.vstack(df.embedding.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2869"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classes = pd.read_json(\"../data/processed/coarse_classification.jsonl\", lines=True)\n",
    "((df_classes.ss_neuro_citations >= 2) | (df_classes.oa_neuro_citations >= 2) | (df_classes.keywords_found >= 1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/processed/works.jsonl\", lines=True)\n",
    "\n",
    "with open(\"../data/processed/features.pkl\", \"rb\") as f:\n",
    "    features = pickle.load(f)\n",
    "\n",
    "df[\"neuro_related\"] = np.where(features.sum(axis=1) >= 1, 1, 0)\n",
    "\n",
    "with open(\"../data/processed/categories.pkl\", \"rb\") as f:\n",
    "    outputs = pickle.load(f)\n",
    "\n",
    "category = np.zeros(df.shape[0], dtype=object)\n",
    "category[df[\"neuro_related\"].values == 1] = outputs\n",
    "\n",
    "df[\"category\"] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# papers')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 454,
       "width": 563
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.category.isin(['A', 'C'])].groupby('publication_year').count().title.plot()\n",
    "plt.title('Papers in ML conferences using neuro ideas')\n",
    "plt.ylabel('# papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% papers')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 454,
       "width": 576
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add up 2021 and 2022.\n",
    "count_0 = df[df.category.isin(['A', 'C'])].groupby('publication_year').count().title\n",
    "count_1 = df.groupby('publication_year').count().title\n",
    "(100 * (count_0 / count_1)).plot()\n",
    "plt.title('% papers in ML/CV conferences using neuro ideas')\n",
    "plt.ylabel('% papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Total papers in ML/CV conferences')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 434,
       "width": 561
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_1 = df.groupby('publication_year').count().title\n",
    "plt.plot(count_1)\n",
    "plt.title('Total papers in ML/CV conferences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.read_json(\"../data/processed/references.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse deep belief net model for visual area V2\n",
      "Motivated in part by the hierarchical organization of the cortex, a number of algorithms have recently been proposed that try to learn hierarchical, or deep, structure from unlabeled data. While several authors have formally or informally compared their algorithms to computations performed in visual area V1 (and the cochlea), little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hierarchy. This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2. Specifically, we develop a sparse variant of the deep belief networks of Hinton et al. (2006). We learn two layers of nodes in the network, and demonstrate that the first layer, similar to prior work on sparse coding and ICA, results in localized, oriented, edge filters, similar to the Gabor functions known to model V1 cell receptive fields. Further, the second layer in our model encodes correlations of the first layer responses in the data. Specifically, it picks up both colinear (contour) features as well as corners and junctions. More interestingly, in a quantitative comparison, the encoding of these more complex corner features matches well with the results from the Ito & Komatsu's study of biological V2 responses. This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features.\n",
      "Integrating Topics and Syntax\n",
      "Statistical approaches to language learning typically focus on either short-range syntactic dependencies or long-range semantic dependencies between words. We present a generative model that uses both kinds of dependencies, and can be used to simultaneously find syntactic classes and semantic topics despite having no representation of syntax or semantics beyond statistical dependency. This model is competitive on tasks like part-of-speech tagging and document classification with models that exclusively use short- and long-range dependencies respectively.\n",
      "Texture synthesis using convolutional neural networks\n",
      "Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition. Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion. Within the model, textures are represented by the correlations between feature maps in several layers of the network. We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit. The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.\n",
      "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images\n",
      "We address a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efficiently map 3D brain structure and connectivity. To segment biological neuron membranes, we use a special type of deep artificial neural network as a pixel classifier. The label of each pixel (membrane or non-membrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classifier is trained by plain gradient descent on a 512 × 512 × 30 stack with known ground truth, and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-specific postprocessing, our approach outperforms competing techniques by a large margin in all three considered metrics, i.e. rand error, warping error and pixel error. For pixel error, our approach is the only one outperforming a second human observer.\n",
      "Learning Convolutional Feature Hierarchies for Visual Recognition\n",
      "We propose an unsupervised method for learning multi-stage hierarchies of sparse convolutional features. While sparse coding has become an increasingly popular method for learning visual features, it is most often trained at the patch level. Applying the resulting filters convolutionally results in highly redundant codes because overlapping patches are encoded in isolation. By training convolutionally over large image windows, our method reduces the redudancy between feature vectors at neighboring locations and improves the efficiency of the overall representation. In addition to a linear decoder that reconstructs the image from sparse features, our method trains an efficient feed-forward encoder that predicts quasi-sparse features from the input. While patch-based training rarely produces anything but oriented edge detectors, we show that convolutional training produces highly diverse filters, including center-surround filters, corner detectors, cross detectors, and oriented grating detectors. We show that using these filters in multistage convolutional network architecture improves performance on a number of visual recognition and detection tasks.\n",
      "Measuring Invariances in Deep Networks\n",
      "For many pattern recognition tasks, the ideal input feature would be invariant to multiple confounding properties (such as illumination and viewing angle, in computer vision applications). Recently, architectures trained in an unsupervised manner have been proposed as an automatic method for extracting useful features. However, it is difficult to evaluate the learned features by any means other than using them in a classifier. In this paper, we propose a number of empirical tests that directly measure the degree to which these learned features are invariant to different input transformations. We find that stacked autoencoders learn modestly increasingly invariant features with depth when trained on natural images. We find that convolutional belief networks learn substantially more invariant features in each layer. These results further justify the use of deep vs. shallower representations, but suggest that mechanisms beyond merely stacking one autoencoder on top of another may be important for achieving invariance. Our evaluation metrics can also be used to evaluate future work in learning, and thus help the development of future algorithms.\n",
      "Classifying Single Trial EEG: Towards Brain Computer Interfacing\n",
      "Driven by the progress in the field of single-trial analysis of EEG, there is a growing interest in brain computer interfaces (BCIs), i.e., systems that enable human subjects to control a computer only by means of their brain signals. In a pseudo-online simulation our BCI detects upcoming finger movements in a natural keyboard typing condition and predicts their laterality. This can be done on average 100-230ms before the respective key is actually pressed, i.e., long before the onset of EMG. Our approach is appealing for its short response time and high classification accuracy (>96%) in a binary decision where no human training is involved. We compare discriminative classifiers like Support Vector Machines (SVMs) and different variants of Fisher Discriminant that possess favorable regularization properties for dealing with high noise cases (inter-trial variablity).\n",
      "Deep knowledge tracing\n",
      "Knowledge tracing—where a machine models the knowledge of a student as they interact with coursework—is a well established problem in computer supported education. Though effectively modeling student knowledge would have high educational impact, the task has many inherent challenges. In this paper we explore the utility of using Recurrent Neural Networks (RNNs) to model student learning. The RNN family of models have important advantages over previous methods in that they do not require the explicit encoding of human domain knowledge, and can capture more complex representations of student knowledge. Using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets. Moreover the learned model can be used for intelligent curriculum design and allows straightforward interpretation and discovery of structure in student tasks. These results suggest a promising new line of research for knowledge tracing and an exemplary application task for RNNs.\n",
      "Learning to combine foveal glimpses with a third-order Boltzmann machine\n",
      "We describe a model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several fixations. The model uses a retina that only has enough high resolution pixels to cover a small area of the image, so it must decide on a sequence of fixations and it must combine the glimpse at each fixation with the location of the fixation before integrating the information with information from other glimpses of the same object. We evaluate this model on a synthetic dataset and two image classification datasets, showing that it can perform at least as well as a model trained on whole images.\n",
      "Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes\n",
      "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random field for jointly solving the tasks of object detection and scene classification.\n",
      "Galileo: perceiving physical object properties by integrating a physics engine with deep learning\n",
      "Humans demonstrate remarkable abilities to predict physical events in dynamic scenes, and to infer the physical properties of objects from static images. We propose a generative model for solving these problems of physical scene understanding from real-world videos and images. At the core of our generative model is a 3D physics engine, operating on an object-based representation of physical properties, including mass, position, 3D shape, and friction. We can infer these latent properties using relatively brief runs of MCMC, which drive simulations in the physics engine to fit key features of visual observations. We further explore directly mapping visual inputs to physical properties, inverting a part of the generative process using deep learning. We name our model Galileo, and evaluate it on a video dataset with simple yet physically rich scenarios. Results show that Galileo is able to infer the physical properties of objects and predict the outcome of a variety of physical events, with an accuracy comparable to human subjects. Our study points towards an account of human vision with generative physical knowledge at its core, and various recognition models as helpers leading to efficient inference.\n",
      "Bayesian Surprise Attracts Human Attention\n",
      "The concept of surprise is central to sensory processing, adaptation, learning, and attention. Yet, no widely-accepted mathematical theory currently exists to quantitatively characterize surprise elicited by a stimulus or event, for observers that range from single neurons to complex natural or engineered systems. We describe a formal Bayesian definition of surprise that is the only consistent formulation under minimal axiomatic assumptions. Surprise quantifies how data affects a natural or artificial observer, by measuring the difference between posterior and prior beliefs of the observer. Using this framework we measure the extent to which humans direct their gaze towards surprising items while watching television and video games. We find that subjects are strongly attracted towards surprising locations, with 72% of all human gaze shifts directed towards locations more surprising than the average, a figure which rises to 84% when considering only gaze targets simultaneously selected by all subjects. The resulting theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.\n",
      "Predicting human gaze using low-level saliency combined with face detection\n",
      "Under natural viewing conditions, human observers shift their gaze to allocate processing resources to subsets of the visual input. Many computational models try to predict such voluntary eye and attentional shifts. Although the important role of high level stimulus properties (e.g., semantic information) in search stands undisputed, most models are based on low-level image properties. We here demonstrate that a combined model of face detection and low-level saliency significantly outperforms a low-level model in predicting locations humans fixate on, based on eye-movement recordings of humans observing photographs of natural scenes, most of which contained at least one person. Observers, even when not instructed to look for anything particular, fixate on a face with a probability of over 80% within their first two fixations; furthermore, they exhibit more similar scan-paths when faces are present. Remarkably, our model's predictive performance in images that do not contain faces is not impaired, and is even improved in some cases by spurious face detector responses.\n",
      "Discrete Graph Hashing\n",
      "Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic databases. In particular, learning based hashing has received considerable attention due to its appealing storage and search efficiency. However, the performance of most unsupervised learning based hashing methods deteriorates rapidly as the hash code length increases. We argue that the degraded performance is due to inferior optimization procedures used to achieve discrete binary codes. This paper presents a graph-based unsupervised hashing model to preserve the neighborhood structure of massive data in a discrete code space. We cast the graph hashing problem into a discrete optimization framework which directly learns the binary codes. A tractable alternating maximization algorithm is then proposed to explicitly deal with the discrete constraints, yielding high-quality codes to well capture the local neighborhoods. Extensive experiments performed on four large datasets with up to one million samples show that our discrete optimization based graph hashing method obtains superior search accuracy over state-of-the-art un-supervised hashing methods, especially for longer codes.\n",
      "Extended ICA Removes Artifacts from Electroencephalographic Recordings\n",
      "Severe contamination of electroencephalographic (EEG) activity by eye movements, blinks, muscle, heart and line noise is a serious problem for EEG interpretation and analysis. Rejecting contaminated EEG segments results in a considerable loss of information and may be impractical for clinical data. Many methods have been proposed to remove eye movement and blink artifacts from EEG recordings. Often regression in the time or frequency domain is performed on simultaneous EEG and electrooculographic (EOG) recordings to derive parameters characterizing the appearance and spread of EOG artifacts in the EEG channels. However, EOG records also contain brain signals [1, 2], so regressing out EOG activity inevitably involves subtracting a portion of the relevant EEG signal from each recording as well. Regression cannot be used to remove muscle noise or line noise, since these have no reference channels. Here, we propose a new and generally applicable method for removing a wide variety of artifacts from EEG records. The method is based on an extended version of a previous Independent Component Analysis (ICA) algorithm [3, 4] for performing blind source separation on linear mixtures of independent source signals with either sub-Gaussian or super-Gaussian distributions. Our results show that ICA can effectively detect, separate and remove activity in EEG records from a wide variety of artifactual sources, with results comparing favorably to those obtained using regression-based methods.\n",
      "Dynamic visual attention: searching for coding length increments\n",
      "A visual attention system should respond placidly when common stimuli are presented, while at the same time keep alert to anomalous visual inputs. In this paper, a dynamic visual attention model based on the rarity of features is proposed. We introduce the Incremental Coding Length (ICL) to measure the perspective entropy gain of each feature. The objective of our model is to maximize the entropy of the sampled visual features. In order to optimize energy consumption, the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length. By selecting features with large coding length increments, the computational system can achieve attention selectivity in both static and dynamic scenes. We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation. Moreover, we also show that our model captures several less-reported dynamic visual search behaviors, such as attentional swing and inhibition of return.\n",
      "Generalisation in humans and deep neural networks\n",
      "We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.\n",
      "Visual Interaction Networks: Learning a Physics Simulator from Video\n",
      "From just a glance, humans can make rich predictions about the future of a wide range of physical systems. On the other hand, modern approaches from engineering, robotics, and graphics are often restricted to narrow domains or require information about the underlying state. We introduce the Visual Interaction Network, a general-purpose model for learning the dynamics of a physical system from raw visual observations. Our model consists of a perceptual front-end based on convolutional neural networks and a dynamics predictor based on interaction networks. Through joint training, the perceptual front-end learns to parse a dynamic visual scene into a set of factored latent object representations. The dynamics predictor learns to roll these states forward in time by computing their interactions, producing a predicted physical trajectory of arbitrary length. We found that from just six input video frames the Visual Interaction Network can generate accurate future trajectories of hundreds of time steps on a wide range of physical systems. Our model can also be applied to scenes with invisible objects, inferring their future states from their effects on the visible objects, and can implicitly infer the unknown mass of objects. This work opens new opportunities for model-based decision-making and planning from raw sensory observations in complex physical environments.\n",
      "EMPATH: Face, Emotion, and Gender Recognition Using Holons\n",
      "The dimensionality of a set of 160 face images of 10 male and 10 female subjects is reduced from 4096 to 40 via an autoencoder network. The extracted features do not correspond to the features used in previous face recognition systems (Kanade, 1973), such as ratios of distances between facial elements. Rather, they are whole-face features we call holons. The holons are given to 1 and 2 layer back propagation networks that are trained to classify the input features for identity, feigned emotional state and gender. The automatically extracted holons provide a sufficient basis for all of the gender discriminations, 99% of the identity discriminations and several of the emotion discriminations among the training set. Network and human judgements of the emotions are compared, and it is found that the networks tend to confuse more distant emotions than humans do.\n",
      "Unsupervised feature extraction by time-contrastive learning and nonlinear ICA\n",
      "Nonlinear independent component analysis (ICA) provides an appealing framework for unsupervised feature learning, but the models proposed so far are not identifiable. Here, we first propose a new intuitive principle of unsupervised deep learning from time series which uses the nonstationary structure of the data. Our learning principle, time-contrastive learning (TCL), finds a representation which allows optimal discrimination of time segments (windows). Surprisingly, we show how TCL can be related to a nonlinear ICA model, when ICA is redefined to include temporal nonstationarities. In particular, we show that TCL combined with linear ICA estimates the nonlinear ICA model up to point-wise transformations of the sources, and this solution is unique — thus providing the first identifiability result for nonlinear ICA which is rigorous, constructive, as well as very general.\n",
      "One-shot learning by inverting a compositional causal process\n",
      "People can learn a new class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on com-positionality and causality that can learn a wide range of natural (although simple) concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classification task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also tested the model on another conceptual task, generating new examples, by using a visual Turing test to show that our model produces human-like performance.\n",
      "Visual Speech Recognition with Stochastic Networks\n",
      "This paper presents ongoing work on a speaker independent visual speech recognition system. The work presented here builds on previous research efforts in this area and explores the potential use of simple hidden Markov models for limited vocabulary, speaker independent visual speech recognition. The task at hand is recognition of the first four English digits, a task with possible applications in car-phone dialing. The images were modeled as mixtures of independent Gaussian distributions, and the temporal dependencies were captured with standard left-to-right hidden Markov models. The results indicate that simple hidden Markov models may be used to successfully recognize relatively unprocessed image sequences. The system achieved performance levels equivalent to untrained humans when asked to recognize the first four English digits.\n",
      "Empirical models of spiking in neural populations\n",
      "Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within a local network? We argue that in the cortex, where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by comparing a latent dynamical model with realistic spiking observations to coupled generalised linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms the GLM in terms of goodness-of-fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly better goodness-of-fit and more realistic population spike counts.\n",
      "Invariant Common Spatial Patterns: Alleviating Nonstationarities in Brain-Computer Interfacing\n",
      "Brain-Computer Interfaces can suffer from a large variance of the subject conditions within and across sessions. For example vigilance fluctuations in the individual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to define features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefficient representation of CSP such as disturbance covariance matrices from fluctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classification engine for BCI. As a proof of concept we present a BCI classifier that is robust to changes in the level of parietal α-activity. In other words, the EEG decoding still works when there are lapses in vigilance.\n",
      "Local Phase Coherence and the Perception of Blur\n",
      "Humans are able to detect blurring of visual images, but the mechanism by which they do so is not clear. A traditional view is that a blurred image looks unnatural because of the reduction in energy (either globally or locally) at high frequencies. In this paper, we propose that the disruption of local phase can provide an alternative explanation for blur perception. We show that precisely localized features such as step edges result in strong local phase coherence structures across scale and space in the complex wavelet transform domain, and blurring causes loss of such phase coherence. We propose a technique for coarse-to-fine phase prediction of wavelet coefficients, and observe that (1) such predictions are highly effective in natural images, (2) phase coherence increases with the strength of image features, and (3) blurring disrupts the phase coherence relationship in images. We thus lay the groundwork for a new theory of perceptual blur estimation, as well as a variety of algorithms for restoration and manipulation of photographic images.\n",
      "Learning Human-like Knowledge by Singular Value Decomposition: A Progress Report\n",
      "Singular value decomposition (SVD) can be viewed as a method for unsupervised training of a network that associates two classes of events reciprocally by linear connections through a single hidden layer. SVD was used to learn and represent relations among very large numbers of words (20k-60k) and very large numbers of natural text passages (1k- 70k) in which they occurred. The result was 100-350 dimensional semantic spaces in which any trained or newly added word or passage could be represented as a vector, and similarities were measured by the cosine of the contained angle between vectors. Good accuracy in simulating human judgments and behaviors has been demonstrated by performance on multiple-choice vocabulary and domain knowledge tests, emulation of expert essay evaluations, and in several other ways. Examples are also given of how the kind of knowledge extracted by this method can be applied.\n",
      "Help or Hinder: Bayesian Models of Social Goal Inference\n",
      "Everyday social interactions are heavily influenced by our snap judgments about others' goals. Even young infants can infer the goals of intentional agents from observing how they interact with objects and other agents in their environment: e.g., that one agent is 'helping' or 'hindering' another's attempt to get up a hill or open a box. We propose a model for how people can infer these social goals from actions, based on inverse planning in multiagent Markov decision problems (MDPs). The model infers the goal most likely to be driving an agent's behavior by assuming the agent acts approximately rationally given environmental constraints and its model of other agents present. We also present behavioral evidence in support of this model over a simpler, perceptual cue-based alternative.\n",
      "Structure Learning in Human Causal Induction\n",
      "We use graphical models to explore the question of how people learn simple causal relationships from data. The two leading psychological theories can both be seen as estimating the parameters of a fixed graph. We argue that a complete account of causal induction should also consider how people learn the underlying causal graph structure, and we propose to model this inductive process as a Bayesian inference. Our argument is supported through the discussion of three data sets.\n",
      "Neural Decoding of Cursor Motion Using a Kalman Filter\n",
      "The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean firing rates of the cells in 70ms bins. We focus on a realistic cursor control task in which the subject must move a cursor to hit randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman filter which has a number of advantages over previous linear filtering techniques. In particular, the Kalman filter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement.\n",
      "Hippocampal Contributions to Control: The Third Way\n",
      "Recent experimental studies have focused on the specialization of different neural structures for different types of instrumental behavior. Recent theoretical work has provided normative accounts for why there should be more than one control system, and how the output of different controllers can be integrated. Two particlar controllers have been identified, one associated with a forward model and the prefrontal cortex and a second associated with computationally simpler, habitual, actor-critic methods and part of the striatum. We argue here for the normative appropriateness of an additional, but so far marginalized control system, associated with episodic memory, and involving the hippocampus and medial temporal cortices. We analyze in depth a class of simple environments to show that episodic control should be useful in a range of cases characterized by complexity and inferential noise, and most particularly at the very early stages of learning, long before habitization has set in. We interpret data on the transfer of control from the hippocampus to the striatum in the light of this hypothesis.\n",
      "An Information-Theoretic Approach to Deciphering the Hippocampal Code\n",
      "Information theory is used to derive a simple formula for the amount of information conveyed by the firing rate of a neuron about any experimentally measured variable or combination of variables (e.g. running speed, head direction, location of the animal, etc.). The derivation treats the cell as a communication channel whose input is the measured variable and whose output is the cell's spike train. Applying the formula, we find systematic differences in the information content of hippocampal place cells in different experimental conditions.\n",
      "The discriminant center-surround hypothesis for bottom-up saliency\n",
      "The classical hypothesis, that bottom-up saliency is a center-surround process, is combined with a more recent hypothesis that all saliency decisions are optimal in a decision-theoretic sense. The combined hypothesis is denoted as discriminant center-surround saliency, and the corresponding optimal saliency architecture is derived. This architecture equates the saliency of each image location to the discriminant power of a set of features with respect to the classification problem that opposes stimuli at center and surround, at that location. It is shown that the resulting saliency detector makes accurate quantitative predictions for various aspects of the psychophysics of human saliency, including non-linear properties beyond the reach of previous saliency models. Furthermore, it is shown that discriminant center-surround saliency can be easily generalized to various stimulus modalities (such as color, orientation and motion), and provides optimal solutions for many other saliency problems of interest for computer vision. Optimal solutions, under this hypothesis, are derived for a number of the former (including static natural images, dense motion fields, and even dynamic textures), and applied to a number of the latter (the prediction of human eye fixations, motion-based saliency in the presence of ego-motion, and motion-based saliency in the presence of highly dynamic backgrounds). In result, discriminant saliency is shown to predict eye fixations better than previous models, and produces background subtraction algorithms that outperform the state-of-the-art in computer vision.\n",
      "Compositionality of optimal control laws\n",
      "We present a theory of compositionality in stochastic optimal control, showing how task-optimal controllers can be constructed from certain primitives. The primitives are themselves feedback controllers pursuing their own agendas. They are mixed in proportion to how much progress they are making towards their agendas and how compatible their agendas are with the present task. The resulting composite control law is provably optimal when the problem belongs to a certain class. This class is rather general and yet has a number of unique properties - one of which is that the Bellman equation can be made linear even for non-linear or discrete dynamics. This gives rise to the compositionality developed here. In the special case of linear dynamics and Gaussian noise our framework yields analytical solutions (i.e. non-linear mixtures of LQG controllers) without requiring the final cost to be quadratic. More generally, a natural set of control primitives can be constructed by applying SVD to Green's function of the Bellman equation. We illustrate the theory in the context of human arm movements. The ideas of optimality and compositionality are both very prominent in the field of motor control, yet they have been difficult to reconcile. Our work makes this possible.\n",
      "Where are they looking\n",
      "Humans have the remarkable ability to follow the gaze of other people to identify what they are looking at. Following eye gaze, or gaze-following, is an important ability that allows us to understand what other people are thinking, the actions they are performing, and even predict what they might do next. Despite the importance of this topic, this problem has only been studied in limited scenarios within the computer vision community. In this paper, we propose a deep neural network-based approach for gaze-following and a new benchmark dataset, GazeFollow, for thorough evaluation. Given an image and the location of a head, our approach follows the gaze of the person and identifies the object being looked at. Our deep network is able to discover how to extract head pose and gaze orientation, and to select objects in the scene that are in the predicted line of sight and likely to be looked at (such as televisions, balls and food). The quantitative evaluation shows that our approach produces reliable results, even when viewing only the back of the head. While our method outperforms several baseline approaches, we are still far from reaching human performance on this task. Overall, we believe that gaze-following is a challenging and important problem that deserves more attention from the community.\n",
      "Deep Learning of Invariant Features via Simulated Fixations in Video\n",
      "We apply salient feature detection and tracking in videos to simulate fixations and smooth pursuit in human vision. With tracked sequences as input, a hierarchical network of modules learns invariant features using a temporal slowness constraint. The network encodes invariance which are increasingly complex with hierarchy. Although learned from videos, our features are spatial instead of spatial-temporal, and well suited for extracting features from still images. We applied our features to four datasets (COIL-100, Caltech 101, STL-10, PubFig), and observe a consistent improvement of 4% to 5% in classification accuracy. With this approach, we achieve state-of-the-art recognition accuracy 61% on STL-10 dataset.\n",
      "Bayesian models of human action understanding\n",
      "We present a Bayesian framework for explaining how people reason about and predict the actions of an intentional agent, based on observing its behavior. Action-understanding is cast as a problem of inverting a probabilistic generative model, which assumes that agents tend to act rationally in order to achieve their goals given the constraints of their environment. Working in a simple sprite-world domain, we show how this model can be used to infer the goal of an agent and predict how the agent will act in novel situations or when environmental constraints change. The model provides a qualitative account of several kinds of inferences that preverbal infants have been shown to perform, and also fits quantitative predictions that adult observers make in a new experiment.\n",
      "Viewpoint Invariant Face Recognition using Independent Component Analysis and Attractor Networks\n",
      "We have explored two approaches to recognizing faces across changes in pose. First, we developed a representation of face images based on independent component analysis (ICA) and compared it to a principal component analysis (PCA) representation for face recognition. The ICA basis vectors for this data set were more spatially local than the PCA basis vectors and the ICA representation had greater invariance to changes in pose. Second, we present a model for the development of viewpoint invariant responses to faces from visual experience in a biological system. The temporal continuity of natural visual experience was incorporated into an attractor network model by Hebbian learning following a lowpass temporal filter on unit activities. When combined with the temporal filter, a basic Hebbian update rule became a generalization of Griniasty et al. (1993), which associates temporally proximal input patterns into basins of attraction. The system acquired representations of faces that were largely independent of pose.\n",
      "Learning Lie Groups for Invariant Visual Perception\n",
      "One of the most important problems in visual perception is that of visual invariance: how are objects perceived to be the same despite undergoing transformations such as translations, rotations or scaling? In this paper, we describe a Bayesian method for learning invariances based on Lie group theory. We show that previous approaches based on first-order Taylor series expansions of inputs can be regarded as special cases of the Lie group approach, the latter being capable of handling in principle arbitrarily large transfonnations. Using a matrix-exponential based generative model of images, we derive an unsupervised algorithm for learning Lie group operators from input data containing infinitesimal transfonnations. The on-line unsupervised learning algorithm maximizes the posterior probability of generating the training data. We provide experimental results suggesting that the proposed method can learn Lie group operators for handling reasonably large 1-D translations and 2-D rotations.\n",
      "Learning Generative Models with Visual Attention\n",
      "Attention has long been proposed by psychologists to be important for efficiently dealing with the massive amounts of sensory stimulus in the neocortex. Inspired by the attention models in visual neuroscience and the need for object-centered data for generative models, we propose a deep-learning based generative framework using attention. The attentional mechanism propagates signals from the region of interest in a scene to an aligned canonical representation for generative modeling. By ignoring scene background clutter, the generative model can concentrate its resources on the object of interest. A convolutional neural net is employed to provide good initializations during posterior inference which uses Hamiltonian Monte Carlo. Upon learning images of faces, our model can robustly attend to the face region of novel test subjects. More importantly, our model can learn generative models of new faces from a novel dataset of large images where the face locations are not known.\n",
      "Learning Horizontal Connections in a Sparse Coding Model of Natural Images\n",
      "It has been shown that adapting a dictionary of basis functions to the statistics of natural images so as to maximize sparsity in the coefficients results in a set of dictionary elements whose spatial properties resemble those of V1 (primary visual cortex) receptive fields. However, the resulting sparse coefficients still exhibit pronounced statistical dependencies, thus violating the independence assumption of the sparse coding model. Here, we propose a model that attempts to capture the dependencies among the basis function coefficients by including a pairwise coupling term in the prior over the coefficient activity states. When adapted to the statistics of natural images, the coupling terms learn a combination of facilitatory and inhibitory interactions among neighboring basis functions. These learned interactions may offer an explanation for the function of horizontal connections in V1 in terms of a prior over natural images.\n",
      "Sparse Filtering\n",
      "Unsupervised feature learning has been shown to be effective at learning representations that perform well on image, video and audio classification. However, many existing feature learning algorithms are hard to use and require extensive hyperparameter tuning. In this work, we present sparse filtering, a simple new algorithm which is efficient and only has one hyperparameter, the number of features to learn. In contrast to most other feature learning methods, sparse filtering does not explicitly attempt to construct a model of the data distribution. Instead, it optimizes a simple cost function – the sparsity of l2-normalized features – which can easily be implemented in a few lines of MATLAB code. Sparse filtering scales gracefully to handle high-dimensional inputs, and can also be used to learn meaningful features in additional layers with greedy layer-wise stacking. We evaluate sparse filtering on natural images, object classification (STL-10), and phone classification (TIMET), and show that our method works well on a range of different modalities.\n",
      "Methods Towards Invasive Human Brain Computer Interfaces\n",
      "During the last ten years there has been growing interest in the development of Brain Computer Interfaces (BCIs). The field has mainly been driven by the needs of completely paralyzed patients to communicate. With a few exceptions, most human BCIs are based on extracranial electroencephalography (EEG). However, reported bit rates are still low. One reason for this is the low signal-to-noise ratio of the EEG [16]. We are currently investigating if BCIs based on electrocorticography (ECoG) are a viable alternative. In this paper we present the method and examples of intracranial EEG recordings of three epilepsy patients with electrode grids placed on the motor cortex. The patients were asked to repeatedly imagine movements of two kinds, e.g., tongue or finger movements. We analyze the classifiability of the data using Support Vector Machines (SVMs) [18,21] and Recursive Channel Elimination (RCE) [11].\n",
      "A Bayesian Framework for Cross-Situational Word-Learning\n",
      "For infants, early word learning is a chicken-and-egg problem. One way to learn a word is to observe that it co-occurs with a particular referent across different situations. Another way is to use the social context of an utterance to infer the intended referent of a word. Here we present a Bayesian model of cross-situational word learning, and an extension of this model that also learns which social cues are relevant to determining reference. We test our model on a small corpus of mother-infant interaction and find it performs better than competing models. Finally, we show that our model accounts for experimental phenomena including mutual exclusivity, fast-mapping, and generalization from social cues.\n",
      "Showing versus doing: Teaching by demonstration\n",
      "People often learn from others' demonstrations, and classic inverse reinforcement learning (IRL) algorithms have brought us closer to realizing this capacity in machines. In contrast, teaching by demonstration has been less well studied computationally. Here, we develop a novel Bayesian model for teaching by demonstration. Stark differences arise when demonstrators are intentionally teaching a task versus simply performing a task. In two experiments, we show that human participants systematically modify their teaching behavior consistent with the predictions of our model. Further, we show that even standard IRL algorithms benefit when learning from behaviors that are intentionally pedagogical. We conclude by discussing IRL algorithms that can take advantage of intentional pedagogy.\n",
      "Control of Selective Visual Attention: Modeling the \"Where\" Pathway\n",
      "Intermediate and higher vision processes require selection of a subset of the available sensory information before further processing. Usually, this selection is implemented in the form of a spatially circumscribed region of the visual field, the so-called of which scans the visual scene dependent on the input and on the attentional state of the subject. We here present a model for the control of the focus of attention in primates, based on a saliency map. This mechanism is not only expected to model the functionality of biological vision but also to be essential for the understanding of complex scenes in machine vision.\n",
      "Unsupervised learning by program synthesis\n",
      "We introduce an unsupervised learning algorithm that combines probabilistic modeling with solver-based techniques for program synthesis. We apply our techniques to both a visual learning domain and a language learning problem, showing that our algorithm can learn many visual concepts from only a few examples and that it can recover some English inflectional morphology. Taken together, these results give both a new approach to unsupervised learning of symbolic compositional structures, and a technique for applying program synthesis tools to noisy data.\n",
      "Deep Networks with Internal Selective Attention through Feedback Connections\n",
      "Traditional convolutional neural networks (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNet's feedback structure can dynamically alter its convolutional filter sensitivities during classification. It harnesses the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strategies (SNES). On the CIFAR-10 and CIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model on unaugmented datasets.\n",
      "Improving Transfer Rates in Brain Computer Interfacing: A Case Study\n",
      "In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the transfer rates based on offline analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The objective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classification and on the other hand we augmented the data space by using more electrodes for the interface. For the classification task we utilized SVMs and, as motivated by recent findings on the learning of discriminative densities, we accumulated the values of the classification function in order to combine several classifications, which finally lead to significantly improved rates as compared with techniques applied in the original work. In combination with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min.\n",
      "Inference, Attention, and Decision in a Bayesian Neural Architecture\n",
      "We study the synthesis of neural coding, selective attention and perceptual decision making. A hierarchical neural architecture is proposed, which implements Bayesian integration of noisy sensory input and top-down attentional priors, leading to sound perceptual discrimination. The model offers an explicit explanation for the experimentally observed modulation that prior information in one stimulus feature (location) can have on an independent feature (orientation). The network's intermediate levels of representation instantiate known physiological properties of visual cortical neurons. The model also illustrates a possible reconciliation of cortical and neuromodulatory representations of uncertainty.\n",
      "Increase Information Transfer Rates in BCI by CSP Extension to Multi-class\n",
      "Brain-Computer Interfaces (BCI) are an interesting emerging technology that is driven by the motivation to develop an effective communication interface translating human intentions into a control signal for devices like computers or neuroprostheses. If this can be done bypassing the usual human output pathways like peripheral nerves and muscles it can ultimately become a valuable tool for paralyzed patients. Most activity in BCI research is devoted to finding suitable features and algorithms to increase information transfer rates (ITRs). The present paper studies the implications of using more classes, e.g., left vs. right hand vs. foot, for operating a BCI. We contribute by (1) a theoretical study showing under some mild assumptions that it is practically not useful to employ more than three or four classes, (2) two extensions of the common spatial pattern (CSP) algorithm, one interestingly based on simultaneous diagonalization, and (3) controlled EEG experiments that underline our theoretical findings and show excellent improved ITRs.\n",
      "Learning Transformational Invariants from Natural Movies\n",
      "We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the first layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the first layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in VI and MT. In addition, the model demonstrates how feedback from higher levels can influence representations at lower levels as a by-product of inference in a graphical model.\n",
      "STDP enables spiking neurons to detect hidden causes of their inputs\n",
      "The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits, and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain this computational function, are unknown. We show here that STDP, in conjunction with a stochastic soft winner-take-all (WTA) circuit, induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or causes) of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits, a common network motif of cortical microcircuits, could therefore be a drastic dimensionality reduction of information streams, together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular, we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.\n",
      "Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream\n",
      "Humans recognize visually-presented objects rapidly and accurately. To understand this ability, we seek to construct models of the ventral stream, the series of cortical areas thought to subserve object recognition. One tool to assess the quality of a model of the ventral stream is the Representational Dissimilarity Matrix (RDM), which uses a set of visual stimuli and measures the distances produced in either the brain (i.e. fMRI voxel responses, neural firing rates) or in models (features). Previous work has shown that all known models of the ventral stream fail to capture the RDM pattern observed in either IT cortex, the highest ventral area, or in the human ventral stream. In this work, we construct models of the ventral stream using a novel optimization procedure for category-level object recognition problems, and produce RDMs resembling both macaque IT and human ventral stream. The model, while novel in the optimization procedure, further develops a long-standing functional hypothesis that the ventral visual stream is a hierarchically arranged series of processing stages optimized for visual object recognition.\n",
      "Rules and Similarity in Concept Learning\n",
      "This paper argues that two apparently distinct modes of generalizing concepts - abstracting rules and computing similarity to exemplars - should both be seen as special cases of a more general Bayesian learning framework. Bayes explains the specific workings of these two modes - which rules are abstracted, how similarity is measured - as well as why generalization should appear rule - or similarity-based in different situations. This analysis also suggests why the rules/similarity distinction, even if not computationally fundamental, may still be useful at the algorithmic level as part of a principled approximation to fully Bayesian learning.\n",
      "Theory-Based Causal Inference\n",
      "People routinely make sophisticated causal inferences unconsciously, effortlessly, and from very little data - often from just one or a few observations. We argue that these inferences can be explained as Bayesian computations over a hypothesis space of causal graphical models, shaped by strong top-down prior knowledge in the form of intuitive theories. We present two case studies of our approach, including quantitative models of human causal judgments and brief comparisons with traditional bottom-up models of inference.\n",
      "Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior\n",
      "The responses of cortical sensory neurons are notoriously variable, with the number of spikes evoked by identical stimuli varying significantly from trial to trial. This variability is most often interpreted as 'noise', purely detrimental to the sensory system. In this paper, we propose an alternative view in which the variability is related to the uncertainty, about world parameters, which is inherent in the sensory stimulus. Specifically, the responses of a population of neurons are interpreted as stochastic samples from the posterior distribution in a latent variable model. In addition to giving theoretical arguments supporting such a representational scheme, we provide simulations suggesting how some aspects of response variability might be understood in this framework.\n",
      "Maximin affinity learning of image segmentation\n",
      "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure.\n",
      "\n",
      "The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity.\n",
      "Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding\n",
      "Learning long-term dependencies in extended temporal sequences requires credit assignment to events far back in the past. The most common method for training recurrent neural networks, back-propagation through time (BPTT), requires credit information to be propagated backwards through every single step of the forward computation, potentially over thousands or millions of time steps. This becomes computationally expensive or even infeasible when used with long sequences. Importantly, biological brains are unlikely to perform such detailed reverse replay over very long sequences of internal states (consider days, months, or years.) However, humans are often reminded of past memories or mental states which are associated with the current mental state. We consider the hypothesis that such memory associations between past and present could be used for credit assignment through arbitrarily long sequences, propagating the credit assigned to the current state to the associated past state. Based on this principle, we study a novel algorithm which only back-propagates through a few of these temporal skip connections, realized by a learned attention mechanism that associates current states with relevant past states. We demonstrate in experiments that our method matches or outperforms regular BPTT and truncated BPTT in tasks involving particularly long-term dependencies, but without requiring the biologically implausible backward replay through the whole history of states. Additionally, we demonstrate that the proposed method transfers to longer sequences significantly better than LSTMs trained with BPTT and LSTMs trained with full self-attention.\n",
      "Modeling Surround Suppression in V1 Neurons with a Statistically Derived Normalization Model\n",
      "We examine the statistics of natural monochromatic images decomposed using a multi-scale wavelet basis. Although the coefficients of this representation are nearly decorrelated, they exhibit important higher-order statistical dependencies that cannot be eliminated with purely linear procssing. In particular, rectified coefficients corresponding to basis functions at neighboring spatial positions, orientations and scales are highly correlated. A method of removing these dependencies is to divide each coefficient by a weighted combination of its rectified neighbors. Several successful models of the steady -state behavior of neurons in primary visual cortex are based on such divisive computations, and thus our analysis provides a theoretical justification for these models. Perhaps more importantly, the statistical measurements explicitly specify the weights that should be used in computing the normalization signal. We demonstrate that this weighting is qualitatively consistent with recent physiological experiments that characterize the suppressive effect of stimuli presented outside of the classical receptive field. Our observations thus provide evidence for the hypothesis that early visual neural processing is well matched to these statistical properties of images.\n",
      "Slow, Decorrelated Features for Pretraining Complex Cell-like Networks\n",
      "We introduce a new type of neural network activation function based on recent physiological rate models for complex cells in visual area V1. A single-hidden-layer neural network of this kind of model achieves 1.50% error on MNIST. We also introduce an existing criterion for learning slow, decorrelated features as a pretraining strategy for image models. This pretraining strategy results in orientation-selective features, similar to the receptive fields of complex cells. With this pretraining, the same single-hidden-layer model achieves 1.34% error, even though the pretraining sample distribution is very different from the fine-tuning distribution. To implement this pretraining strategy, we derive a fast algorithm for online learning of decorrelated features such that each iteration of the algorithm runs in linear time with respect to the number of features.\n",
      "Learning and using language via recursive pragmatic reasoning about other agents\n",
      "Language users are remarkably good at making inferences about speakers' intentions in context, and children learning their native language also display substantial skill in acquiring the meanings of unknown words. These two cases are deeply related: Language users invent new terms in conversation, and language learners learn the literal meanings of words based on their pragmatic inferences about how those words are used. While pragmatic inference and word learning have both been independently characterized in probabilistic terms, no current work unifies these two. We describe a model in which language learners assume that they jointly approximate a shared, external lexicon and reason recursively about the goals of others in using this lexicon. This model captures phenomena in word learning and pragmatic inference; it additionally leads to insights about the emergence of communicative systems in conversation and the mechanisms by which pragmatic inferences become incorporated into word meanings.\n",
      "Multiple Paired Forward-Inverse Models for Human Motor Learning and Control\n",
      "Humans demonstrate a remarkable ability to generate accurate and appropriate motor behavior under many different and oftpn uncprtain environmental conditions. This paper describes a new modular approach to human motor learning and control, based on multiple pairs of inverse (controller) and forward (prpdictor) models. This architecture simultaneously learns the multiple inverse models necessary for control as well as how to select the inverse models appropriate for a given environment. Simulations of object manipulation demonstrates the ability to learn mUltiple objects, appropriate generalization to novel objects and the inappropriate activation of motor programs based on visual cues, followed by on-line correction, seen in the size-weight illusion.\n",
      "Brain covariance selection: better individual functional connectivity models using population prior\n",
      "Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reflects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data. Learning such models entails two main challenges: i) modeling full brain connectivity is a difficult estimation problem that faces the curse of dimensionality and ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging. We describe subject-level brain functional connectivity structure as a multivari-ate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the first report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the first time that known cognitive networks appear as the integrated communities of functional connectivity graph.\n",
      "The Role of Top-down and Bottom-up Processes in Guiding Eye Movements during Visual Search\n",
      "To investigate how top-down (TD) and bottom-up (BU) information is weighted in the guidance of human search behavior, we manipulated the proportions of BU and TD components in a saliency-based model. The model is biologically plausible and implements an artificial retina and a neuronal population code. The BU component is based on feature-contrast. The TD component is defined by a feature-template match to a stored target representation. We compared the model's behavior at different mixtures of TD and BU components to the eye movement behavior of human observers performing the identical search task. We found that a purely TD model provides a much closer match to human behavior than any mixture model using BU information. Only when biological constraints are removed (e.g., eliminating the retina) did a BU/TD mixture model begin to approximate human behavior.\n",
      "Mutual Boosting for Contextual Inference\n",
      "Mutual Boosting is a method aimed at incorporating contextual information to augment object detection. When multiple detectors of objects and parts are trained in parallel using AdaBoost [1], object detectors might use the remaining intermediate detectors to enrich the weak learner set. This method generalizes the efficient features suggested by Viola and Jones [2] thus enabling information inference between parts and objects in a compositional hierarchy. In our experiments eye-, nose-, mouth- and face detectors are trained using the Mutual Boosting framework. Results show that the method outperforms applications overlooking contextual information. We suggest that achieving contextual integration is a step toward human-like detection capabilities.\n",
      "A Minimal Intervention Principle for Coordinated Movement\n",
      "Behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Here we offer an explanation: we show that not only are variability and goal achievement compatible, but indeed that allowing variability in redundant dimensions is the optimal control strategy in the face of uncertainty. The optimal feedback control laws for typical motor tasks obey a minimal intervention principle: deviations from the average trajectory are only corrected when they interfere with the task goals. The resulting behavior exhibits task-constrained variability, as well as synergetic coupling among actuators—which is another unexplained empirical phenomenon.\n",
      "Dynamical Causal Learning\n",
      "Current psychological theories of human causal learning and judgment focus primarily on long-run predictions: two by estimating parameters of a causal Bayes nets (though for different parameterizations), and a third through structural learning. This paper focuses on people's short-run behavior by examining dynamical versions of these three theories, and comparing their predictions to a real-world dataset.\n",
      "Optimal Teaching for Limited-Capacity Human Learners\n",
      "Basic decisions, such as judging a person as a friend or foe, involve categorizing novel stimuli. Recent work finds that people's category judgments are guided by a small set of examples that are retrieved from memory at decision time. This limited and stochastic retrieval places limits on human performance for probabilistic classification decisions. In light of this capacity limitation, recent work finds that idealizing training items, such that the saliency of ambiguous cases is reduced, improves human performance on novel test items. One shortcoming of previous work in idealization is that category distributions were idealized in an ad hoc or heuristic fashion. In this contribution, we take a first principles approach to constructing idealized training sets. We apply a machine teaching procedure to a cognitive model that is either limited capacity (as humans are) or unlimited capacity (as most machine learning systems are). As predicted, we find that the machine teacher recommends idealized training sets. We also find that human learners perform best when training recommendations from the machine teacher are based on a limited-capacity model. As predicted, to the extent that the learning model used by the machine teacher conforms to the true nature of human learners, the recommendations of the machine teacher prove effective. Our results provide a normative basis (given capacity constraints) for idealization procedures and offer a novel selection procedure for models of human learning.\n",
      "Playing Pinball with non-invasive BCI\n",
      "Compared to invasive Brain-Computer Interfaces (BCI), non-invasive BCI systems based on Electroencephalogram (EEG) signals have not been applied successfully for precisely timed control tasks. In the present study, however, we demonstrate and report on the interaction of subjects with a real device: a pinball machine. Results of this study clearly show that fast and well-timed control well beyond chance level is possible, even though the environment is extremely rich and requires precisely timed and complex predictive behavior. Using machine learning methods for mental state decoding, BCI-based pinball control is possible within the first session without the necessity to employ lengthy subject training. The current study shows clearly that very compelling control with excellent timing and dynamics is possible for a non-invasive BCI.\n",
      "Explaining human multiple object tracking as resource-constrained approximate inference in a dynamic probabilistic model\n",
      "Multiple object tracking is a task commonly used to investigate the architecture of human visual attention. Human participants show a distinctive pattern of successes and failures in tracking experiments that is often attributed to limits on an object system, a tracking module, or other specialized cognitive structures. Here we use a computational analysis of the task of object tracking to ask which human failures arise from cognitive limitations and which are consequences of inevitable perceptual uncertainty in the tracking task. We find that many human performance phenomena, measured through novel behavioral experiments, are naturally produced by the operation of our ideal observer model (a Rao-Blackwelized particle filter). The tradeoff between the speed and number of objects being tracked, however, can only arise from the allocation of a flexible cognitive resource, which can be formalized as either memory or attention.\n",
      "Spike-based Learning Rules and Stabilization of Persistent Neural Activity\n",
      "We analyze the conditions under which synaptic learning rules based on action potential timing can be approximated by learning rules based on firing rates. In particular, we consider a form of plasticity in which synapses depress when a presynaptic spike is followed by a postsynaptic spike, and potentiate with the opposite temporal ordering. Such differential anti-Hebbian plasticity can be approximated under certain conditions by a learning rule that depends on the time derivative of the postsynaptic firing rate. Such a learning rule acts to stabilize persistent neural activity patterns in recurrent neural networks.\n",
      "Human Active Learning\n",
      "We investigate a topic at the interface of machine learning and cognitive science. Human active learning, where learners can actively query the world for information, is contrasted with passive learning from random examples. Furthermore, we compare human active learning performance with predictions from statistical learning theory. We conduct a series of human category learning experiments inspired by a machine learning task for which active and passive learning error bounds are well understood, and dramatically distinct. Our results indicate that humans are capable of actively selecting informative queries, and in doing so learn better and faster than if they are given random training data, as predicted by learning theory. However, the improvement over passive learning is not as dramatic as that achieved by machine active learning algorithms. To the best of our knowledge, this is the first quantitative study comparing human category learning in active versus passive settings.\n",
      "Predicting the Optimal Spacing of Study: A Multiscale Context Model of Memory\n",
      "When individuals learn facts (e.g., foreign language vocabulary) over multiple study sessions, the temporal spacing of study has a significant impact on memory retention. Behavioral experiments have shown a nonmonotonic relationship between spacing and retention: short or long intervals between study sessions yield lower cued-recall accuracy than intermediate intervals. Appropriate spacing of study can double retention on educationally relevant time scales. We introduce a Multiscale Context Model (MCM) that is able to predict the influence of a particular study schedule on retention for specific material. MCM's prediction is based on empirical data characterizing forgetting of the material following a single study session. MCM is a synthesis of two existing memory models (Staddon, Chelaru, & Higa, 2002; Raaijmakers, 2003). On the surface, these models are unrelated and incompatible, but we show they share a core feature that allows them to be integrated. MCM can determine study schedules that maximize the durability of learning, and has implications for education and training. MCM can be cast either as a neural network with inputs that fluctuate over time, or as a cascade of leaky integrators. MCM is intriguingly similar to a Bayesian multiscale model of memory (Kording, Tenenbaum, & Shadmehr, 2007), yet MCM is better able to account for human declarative memory.\n",
      "Bayesian Source Localization with the Multivariate Laplace Prior\n",
      "We introduce a novel multivariate Laplace (MVL) distribution as a sparsity promoting prior for Bayesian source localization that allows the specification of constraints between and within sources. We represent the MVL distribution as a scale mixture that induces a coupling between source variances instead of their means. Approximation of the posterior marginals using expectation propagation is shown to be very efficient due to properties of the scale mixture representation. The computational bottleneck amounts to computing the diagonal elements of a sparse matrix inverse. Our approach is illustrated using a mismatch negativity paradigm for which MEG data and a structural MRI have been acquired. We show that spatial coupling leads to sources which are active over larger cortical areas as compared with an uncoupled prior.\n",
      "Temporally Asymmetric Hebbian Learning, Spike liming and Neural Response Variability\n",
      "Recent experimental data indicate that the strengthening or weakening of synaptic connections between neurons depends on the relative timing of pre- and postsynaptic action potentials. A Hebbian synaptic modification rule based on these data leads to a stable state in which the excitatory and inhibitory inputs to a neuron are balanced, producing an irregular pattern of firing. It has been proposed that neurons in vivo operate in such a mode.\n",
      "A reduced-dimension fMRI shared response model\n",
      "Multi-subject fMRI data is critical for evaluating the generality and validity of findings across subjects, and its effective utilization helps improve analysis sensitivity. We develop a shared response model for aggregating multi-subject fMRI data that accounts for different functional topographies among anatomically aligned datasets. Our model demonstrates improved sensitivity in identifying a shared response for a variety of datasets and anatomical brain regions of interest. Furthermore, by removing the identified shared response, it allows improved detection of group differences. The ability to identify what is shared and what is not shared opens the model to a wide range of multi-subject fMRI studies.\n",
      "Memorability of Image Regions\n",
      "While long term human visual memory can store a remarkable amount of visual information, it tends to degrade over time. Recent works have shown that image memorability is an intrinsic property of an image that can be reliably estimated using state-of-the-art image features and machine learning algorithms. However, the class of features and image information that is forgotten has not been explored yet. In this work, we propose a probabilistic framework that models how and which local regions from an image may be forgotten using a data-driven approach that combines local and global images features. The model automatically discovers memorability maps of individual images without any human annotation. We incorporate multiple image region attributes in our algorithm, leading to improved memorability prediction of images as compared to previous works.\n",
      "The Wisdom of Crowds in the Recollection of Order Information\n",
      "When individuals independently recollect events or retrieve facts from memory, how can we aggregate these retrieved memories to reconstruct the actual set of events or facts? In this research, we report the performance of individuals in a series of general knowledge tasks, where the goal is to reconstruct from memory the order of historic events, or the order of items along some physical dimension. We introduce two Bayesian models for aggregating order information based on a Thurstonian approach and Mallows model. Both models assume that each individual's reconstruction is based on either a random permutation of the unobserved ground truth, or by a pure guessing strategy. We apply MCMC to make inferences about the underlying truth and the strategies employed by individuals. The models demonstrate a wisdom of crowds effect, where the aggregated orderings are closer to the true ordering than the orderings of the best individual.\n",
      "Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis\n",
      "In this study, we present a new method for establishing fMRI pattern-based functional connectivity between brain regions by estimating their multivariate mutual information. Recent advances in the numerical approximation of high-dimensional probability distributions allow us to successfully estimate mutual information from scarce fMRI data. We also show that selecting voxels based on the multivariate mutual information of local activity patterns with respect to ground truth labels leads to higher decoding accuracy than established voxel selection methods. We validate our approach with a 6-way scene categorization fMRI experiment. Multivariate information analysis is able to find strong information sharing between PPA and RSC, consistent with existing neuroscience studies on scenes. Furthermore, an exploratory whole-brain analysis uncovered other brain regions that share information with the PPA-RSC scene network.\n",
      "Modeling the effects of memory on human online sentence processing with particle filters\n",
      "Language comprehension in humans is significantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and fielded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle filter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the first rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information.\n",
      "Audio-Visual Sound Separation Via Hidden Markov Models\n",
      "It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factorially combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information.\n",
      "An Auditory Paradigm for Brain-Computer Interfaces\n",
      "Motivated by the particular problems involved in communicating with locked-in paralysed patients, we aim to develop a brain-computer interface that uses auditory stimuli. We describe a paradigm that allows a user to make a binary decision by focusing attention on one of two concurrent auditory stimulus sequences. Using Support Vector Machine classification and Recursive Channel Elimination on the independent components of averaged event-related potentials, we show that an untrained user's EEG data can be classified with an encouragingly high level of accuracy. This suggests that it is possible for users to modulate EEG signals in a single trial by the conscious direction of attention, well enough to be useful in BCI.\n",
      "Optimizing spatio-temporal filters for improving Brain-Computer Interfacing\n",
      "Brain-Computer Interface (BCI) systems create a novel communication channel from the brain to an output device by bypassing conventional motor output pathways of nerves and muscles. Therefore they could provide a new communication and control option for paralyzed patients. Modern BCI technology is essentially based on techniques for the classification of single-trial brain signals. Here we present a novel technique that allows the simultaneous optimization of a spatial and a spectral filter enhancing discriminability of multi-channel EEG single-trials. The evaluation of 60 experiments involving 22 different subjects demonstrates the superiority of the proposed algorithm. Apart from the enhanced classification, the spatial and/or the spectral filter that are determined by the algorithm can also be used for further analysis of the data, e.g., for source localization of the respective brain rhythms.\n",
      "Modularity in the motor system: decomposition of muscle patterns as combinations of time-varying synergies\n",
      "The question of whether the nervous system produces movement through the combination of a few discrete elements has long been central to the study of motor control. Muscle synergies, i.e. coordinated patterns of muscle activity, have been proposed as possible building blocks. Here we propose a model based on combinations of muscle synergies with a specific amplitude and temporal structure. Time-varying synergies provide a realistic basis for the decomposition of the complex patterns observed in natural behaviors. To extract time-varying synergies from simultaneous recording of EMG activity we developed an algorithm which extends existing non-negative matrix factorization techniques.\n",
      "Goal-Based Imitation as Probabilistic Inference over Graphical Models\n",
      "Humans are extremely adept at learning new skills by imitating the actions of others. A progression of imitative abilities has been observed in children, ranging from imitation of simple body movements to goal-based imitation based on inferring intent. In this paper, we show that the problem of goal-based imitation can be formulated as one of inferring goals and selecting actions using a learned probabilistic graphical model of the environment. We first describe algorithms for planning actions to achieve a goal state using probabilistic inference. We then describe how planning can be used to bootstrap the learning of goal-dependent policies by utilizing feedback from the environment. The resulting graphical model is then shown to be powerful enough to allow goal-based imitation. Using a simple maze navigation task, we illustrate how an agent can infer the goals of an observed teacher and imitate the teacher even when the goals are uncertain and the demonstration is incomplete.\n",
      "Analog VLSI Circuits for Attention-Based, Visual Tracking\n",
      "A one-dimensional visual tracking chip has been implemented using neuromorphic, analog VLSI techniques to model selective visual attention in the control of saccadic and smooth pursuit eye movements. The chip incorporates focal-plane processing to compute image saliency and a winner-take-all circuit to select a feature for tracking. The target position and direction of motion are reported as the target moves across the array. We demonstrate its functionality in a closed-loop system which performs saccadic and smooth pursuit tracking movements using a one-dimensional mechanical eye.\n",
      "Learning the Structure of Similarity\n",
      "The additive clustering (ADCLUS) model (Shepard & Arabie, 1979) treats the similarity of two stimuli as a weighted additive measure of their common features. Inspired by recent work in unsupervised learning with multiple cause models, we propose a new, statistically well-motivated algorithm for discovering the structure of natural stimulus classes using the ADCLUS model, which promises substantial gains in conceptual simplicity, practical efficiency, and solution quality over earlier efforts. We also present preliminary results with artificial data and two classic similarity data sets.\n",
      "Learning to Agglomerate Superpixel Hierarchies\n",
      "An agglomerative clustering algorithm merges the most similar pair of clusters at every iteration. The function that evaluates similarity is traditionally hand-designed, but there has been recent interest in supervised or semisupervised settings in which ground-truth clustered data is available for training. Here we show how to train a similarity function by regarding it as the action-value function of a reinforcement learning problem. We apply this general method to segment images by clustering superpixels, an application that we call Learning to Agglomerate Superpixel Hierarchies (LASH). When applied to a challenging dataset of brain images from serial electron microscopy, LASH dramatically improved segmentation accuracy when clustering supervoxels generated by state of the boundary detection algorithms. The naive strategy of directly training only supervoxel similarities and applying single linkage clustering produced less improvement.\n",
      "Model Uncertainty in Classical Conditioning\n",
      "We develop a framework based on Bayesian model averaging to explain how animals cope with uncertainty about contingencies in classical conditioning experiments. Traditional accounts of conditioning fit parameters within a fixed generative model of reinforcer delivery; uncertainty over the model structure is not considered. We apply the theory to explain the puzzling relationship between second-order conditioning and conditioned inhibition, two similar conditioning regimes that nonetheless result in strongly divergent behavioral outcomes. According to the theory, second-order conditioning results when limited experience leads animals to prefer a simpler world model that produces spurious correlations; conditioned inhibition results when a more complex model is justified by additional experience.\n",
      "Modelling motion primitives and their timing in biologically executed movements\n",
      "Biological movement is built up of sub-blocks or motion primitives. Such primitives provide a compact representation of movement which is also desirable in robotic control applications. We analyse handwriting data to gain a better understanding of primitives and their timings in biological movements. Inference of the shape and the timing of primitives can be done using a factorial HMM based model, allowing the handwriting to be represented in primitive timing space. This representation provides a distribution of spikes corresponding to the primitive activations, which can also be modelled using HMM architectures. We show how the coupling of the low level primitive model, and the higher level timing model during inference can produce good reconstructions of handwriting, with shared primitives for all characters modelled. This coupled model also captures the variance profile of the dataset which is accounted for by spike timing jitter. The timing code provides a compact representation of the movement while generating a movement without an explicit timing model produces a scribbling style of output.\n",
      "Modeling human function learning with Gaussian processes\n",
      "Accounts of how people learn functional relationships between continuous variables have tended to focus on two possibilities: that people are estimating explicit functions, or that they are performing associative learning supported by similarity. We provide a rational analysis of function learning, drawing on work on regression in machine learning and statistics. Using the equivalence of Bayesian linear regression and Gaussian processes, we show that learning explicit rules and using similarity can be seen as two views of one solution to this problem. We use this insight to define a Gaussian process model of human function learning that combines the strengths of both approaches.\n",
      "Parallel multi-dimensional LSTM, with application to fast biomedical volumetric image segmentation\n",
      "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages, however, unlike CNNs, previous MD-LSTM variants were hard to parallelise on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelise, especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).\n",
      "Implications of Recursive Distributed Representations\n",
      "I will describe my recent results on the automatic development of fixed-width recursive distributed representations of variable-sized hierarchal data structures. One implication of this work is that certain types of AI-style data-structures can now be represented in fixed-width analog vectors. Simple inferences can be performed using the type of pattern associations that neural networks excel at Another implication arises from noting that these representations become self-similar in the limit. Once this door to chaos is opened, many interesting new questions about the representational basis of intelligence emerge, and can (and will) be discussed.\n",
      "A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data\n",
      "Point processes are popular models of neural spiking behavior as they provide a statistical distribution over temporal sequences of spikes and help to reveal the complexities underlying a series of recorded action potentials. However, the most common neural point process models, the Poisson process and the gamma renewal process, do not capture interactions and correlations that are critical to modeling populations of neurons. We develop a novel model based on a determinantal point process over latent embeddings of neurons that effectively captures and helps visualize complex inhibitory and competitive interaction. We show that this model is a natural extension of the popular generalized linear model to sets of interacting neurons. The model is extended to incorporate gain control or divisive normalization, and the modulation of neural spiking based on periodic phenomena. Applied to neural spike recordings from the rat hippocampus, we see that the model captures inhibitory relationships, a dichotomy of classes of neurons, and a periodic modulation by the theta rhythm known to be present in the data.\n",
      "Local Dimensionality Reduction\n",
      "If globally high dimensional data has locally only low dimensional distributions, it is advantageous to perform a local dimensionality reduction before further processing the data. In this paper we examine several techniques for local dimensionality reduction in the context of locally weighted linear regression. As possible candidates, we derive local versions of factor analysis regression, principle component regression, principle component regression on joint distributions, and partial least squares regression. After outlining the statistical bases of these methods, we perform Monte Carlo simulations to evaluate their robustness with respect to violations of their statistical assumptions. One surprising outcome is that locally weighted partial least squares regression offers the best average results, thus outperforming even factor analysis, the theoretically most appealing of our candidate techniques.\n",
      "Learning Brain Connectivity of Alzheimer's Disease from Neuroimaging Data\n",
      "Recent advances in neuroimaging techniques provide great potentials for effective diagnosis of Alzheimer's disease (AD), the most common form of dementia. Previous studies have shown that AD is closely related to the alternation in the functional brain network, i.e., the functional connectivity among different brain regions. In this paper, we consider the problem of learning functional brain connectivity from neuroimaging, which holds great promise for identifying image-based markers used to distinguish Normal Controls (NC), patients with Mild Cognitive Impairment (MCI), and patients with AD. More specifically, we study sparse inverse covariance estimation (SICE), also known as exploratory Gaussian graphical models, for brain connectivity modeling. In particular, we apply SICE to learn and analyze functional brain connectivity patterns from different subject groups, based on a key of SICE, called the monotone property we established in this paper. Our experimental results on neuroimaging PET data of 42 AD, 116 MCI, and 67 NC subjects reveal several interesting connectivity patterns consistent with literature findings, and also some new patterns that can help the knowledge discovery of AD.\n",
      "Automatic Acquisition and Efficient Representation of Syntactic Structures\n",
      "The distributional principle according to which morphemes that occur in identical contexts belong, in some sense, to the same category [1] has been advanced as a means for extracting syntactic structures from corpus data. We extend this principle by applying it recursively, and by using mutual information for estimating category coherence. The resulting model learns, in an unsupervised fashion, highly structured, distributed representations of syntactic knowledge from corpora. It also exhibits promising behavior in tasks usually thought to require representations anchored in a grammar, such as systematicity.\n",
      "Synergies in learning words and their referents\n",
      "This paper presents Bayesian non-parametric models that simultaneously learn to segment words from phoneme strings and learn the referents of some of those words, and shows that there is a synergistic interaction in the acquisition of these two kinds of linguistic information. The models themselves are novel kinds of Adaptor Grammars that are an extension of an embedding of topic models into PCFGs. These models simultaneously segment phoneme sequences into words and learn the relationship between non-linguistic objects to the words that referto them. We show (i) that modelling inter-word dependencies not only improves the accuracy of the word segmentation but also of word-object relationships, and (ii) that a model that simultaneously learns word-object relationships and word segmentation segments more accurately than one that just learns word segmentation on its own. We argue that these results support an interactive view of language acquisition that can take advantage of synergies such as these.\n",
      "Spectral learning of linear dynamics from generalised-linear observations with application to neural population data\n",
      "Latent linear dynamical systems with generalised-linear observation models arise in a variety of applications, for instance when modelling the spiking activity of populations of neurons. Here, we show how spectral learning methods (usually called subspace identification in this context) for linear systems with linear-Gaussian observations can be extended to estimate the parameters of a generalised-linear dynamical system model despite a non-linear and non-Gaussian observation process. We use this approach to obtain estimates of parameters for a dynamical model of neural population data, where the observed spike-counts are Poisson-distributed with log-rates determined by the latent dynamical process, possibly driven by external inputs. We show that the extended subspace identification algorithm is consistent and accurately recovers the correct parameters on large simulated data sets with a single calculation, avoiding the costly iterative computation of approximate expectation-maximisation (EM). Even on smaller data sets, it provides an effective initialisation for EM, avoiding local optima and speeding convergence. These benefits are shown to extend to real neural data.\n",
      "Modeling Saccadic Targeting in Visual Search\n",
      "Visual cognition depends critically on the ability to make rapid eye movements known as saccades that orient the fovea over targets of interest in a visual scene. Saccades are known to be ballistic: the pattern of muscle activation for foveating a prespecified target location is computed prior to the movement and visual feedback is precluded. Despite these distinctive properties, there has been no general model of the saccadic targeting strategy employed by the human visual system during visual search in natural scenes. This paper proposes a model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales. Visual search proceeds in a coarse-to-fine fashion with the largest scale filter responses being compared first. The model was empirically tested by comparing its performance with actual eye movement data from human subjects in a natural visual search task; preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects.\n",
      "Using Convolutional Neural Networks to Recognize Rhythm ï¿¼Stimuli from Electroencephalography Recordings\n",
      "Electroencephalography (EEG) recordings of rhythm perception might contain enough information to distinguish different rhythm types/genres or even identify the rhythms themselves. We apply convolutional neural networks (CNNs) to analyze and classify EEG data recorded within a rhythm perception study in Kigali, Rwanda which comprises 12 East African and 12 Western rhythmic stimuli - each presented in a loop for 32 seconds to 13 participants. We investigate the impact of the data representation and the pre-processing steps for this classification tasks and compare different network structures. Using CNNs, we are able to recognize individual rhythms from the EEG with a mean classification accuracy of 24.4% (chance level 4.17%) over all subjects by looking at less than three seconds from a single channel. Aggregating predictions for multiple channels, a mean accuracy of up to 50% can be achieved for individual subjects.\n",
      "Generative versus discriminative training of RBMs for classification of fMRI images\n",
      "Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overfitting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classification task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by fitting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training.\n",
      "The pigeon as particle filter\n",
      "Although theorists have interpreted classical conditioning as a laboratory model of Bayesian belief updating, a recent reanalysis showed that the key features that theoretical models capture about learning are artifacts of averaging over subjects. Rather than learning smoothly to asymptote (reflecting, according to Bayesian models, the gradual tradeoff from prior to posterior as data accumulate), subjects learn suddenly and their predictions fluctuate perpetually. We suggest that abrupt and unstable learning can be modeled by assuming subjects are conducting inference using sequential Monte Carlo sampling with a small number of samples — one, in our simulations. Ensemble behavior resembles exact Bayesian models since, as in particle filters, it averages over many samples. Further, the model is capable of exhibiting sophisticated behaviors like retrospective revaluation at the ensemble level, even given minimally sophisticated individuals that do not track uncertainty in their beliefs over trials.\n",
      "Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes\n",
      "We introduce a novel framework for statistical analysis of populations of non-degenerate Gaussian processes (GPs), which are natural representations of uncertain curves. This allows inherent variation or uncertainty in function-valued data to be properly incorporated in the population analysis. Using the 2-Wasserstein metric we geometrize the space of GPs with L2 mean and covariance functions over compact index spaces. We prove uniqueness of the barycenter of a population of GPs, as well as convergence of the metric and the barycenter of their finite-dimensional counterparts. This justifies practical computations. Finally, we demonstrate our framework through experimental validation on GP datasets representing brain connectivity and climate development. A Matlab library for relevant computations will be published at https://sites.google.com/view/antonmallasto/software.\n",
      "Lipreading by neural networks: Visual preprocessing, learning, and sensory integration\n",
      "We have developed visual preprocessing algorithms for extracting phonologically relevant features from the grayscale video image of a speaker, to provide speaker-independent inputs for an automatic lipreading (speechreading) system. Visual features such as mouth open/closed, tongue visible/not-visible, teeth visible/notvisible, and several shape descriptors of the mouth and its motion are all rapidly computable in a manner quite insensitive to lighting conditions. We formed a hybrid speechreading system consisting of two time delay neural networks (video and acoustic) and integrated their responses by means of independent opinion pooling - the Bayesian optimal method given conditional independence, which seems to hold for our data. This hybrid system had an error rate 25% lower than that of the acoustic subsystem alone on a five-utterance speaker-independent task, indicating that video can be used to improve speech recognition.\n",
      "Combining Features for BCI\n",
      "Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the 'Brain-Computer Interface' (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neuro-physiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classification. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of 'adding' evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reflect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.\n",
      "Characterizing neural dependencies with copula models\n",
      "The coding of information by neural populations depends critically on the statistical dependencies between neuronal responses. However, there is no simple model that can simultaneously account for (1) marginal distributions over single-neuron spike counts that are discrete and non-negative; and (2) joint distributions over the responses of multiple neurons that are often strongly dependent. Here, we show that both marginal and joint properties of neural responses can be captured using copula models. Copulas are joint distributions that allow random variables with arbitrary marginals to be combined while incorporating arbitrary dependencies between them. Different copulas capture different kinds of dependencies, allowing for a richer and more detailed description of dependencies than traditional summary statistics, such as correlation coefficients. We explore a variety of copula models for joint neural response distributions, and derive an efficient maximum likelihood procedure for estimating them. We apply these models to neuronal data collected in macaque pre-motor cortex, and quantify the improvement in coding accuracy afforded by incorporating the dependency structure between pairs of neurons. We find that more than one third of neuron pairs shows dependency concentrated in the lower or upper tails for their firing rate distribution.\n",
      "Bayesian Inference for Spiking Neuron Models with a Sparsity Prior\n",
      "Generalized linear models are the most commonly used tools to describe the stimulus selectivity of sensory neurons. Here we present a Bayesian treatment of such models. Using the expectation propagation algorithm, we are able to approximate the full posterior distribution over all weights. In addition, we use a Laplacian prior to favor sparse solutions. Therefore, stimulus features that do not critically influence neural activity will be assigned zero weights and thus be effectively excluded by the model. This feature selection mechanism facilitates both the interpretation of the neuron model as well as its predictive abilities. The posterior distribution can be used to obtain confidence intervals which makes it possible to assess the statistical significance of the solution. In neural data analysis, the available amount of experimental measurements is often limited whereas the parameter space is large. In such a situation, both regularization by a sparsity prior and uncertainty estimates for the model parameters are essential. We apply our method to multi-electrode recordings of retinal ganglion cells and use our uncertainty estimate to test the statistical significance of functional couplings between neurons. Furthermore we used the sparsity of the Laplace prior to select those filters from a spike-triggered covariance analysis that are most informative about the neural response.\n",
      "Analogy-- Watershed or Waterloo? Structural alignment and the development of connectionist models of analogy\n",
      "Neural network models have been criticized for their inability to make use of compositional representations. In this paper, we describe a series of psychological phenomena that demonstrate the role of structured representations in cognition. These findings suggest that people compare relational representations via a process of structural alignment. This process will have to be captured by any model of cognition, symbolic or subsymbolic.\n",
      "High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer's Disease Progression Prediction\n",
      "Alzheimer's disease (AD) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions. Regression analysis has been studied to relate neuroimaging measures to cognitive status. However, whether these measures have further predictive power to infer a trajectory of cognitive performance over time is still an under-explored but important topic in AD research. We propose a novel high-order multi-task learning model to address this issue. The proposed model explores the temporal correlations existing in imaging and cognitive data by structured sparsity-inducing norms. The sparsity of the model enables the selection of a small number of imaging measures while maintaining high prediction accuracy. The empirical studies, using the longitudinal imaging and cognitive data of the ADNI cohort, have yielded promising results.\n",
      "A Novel Reinforcement Model of Birdsong Vocalization Learning\n",
      "Songbirds learn to imitate a tutor song through auditory and motor learning. We have developed a theoretical framework for song learning that accounts for response properties of neurons that have been observed in many of the nuclei that are involved in song learning. Specifically, we suggest that the anterior forebrain pathway, which is not needed for song production in the adult but is essential for song acquisition, provides synaptic perturbations and adaptive evaluations for syllable vocalization learning. A computer model based on reinforcement learning was constructed that could replicate a real zebra finch song with 90% accuracy based on a spectrographic measure. The second generation of the birdsong model replicated the tutor song with 96% accuracy.\n",
      "Variational Learning for Recurrent Spiking Networks\n",
      "We derive a plausible learning rule for feedforward, feedback and lateral connections in a recurrent network of spiking neurons. Operating in the context of a generative model for distributions of spike sequences, the learning mechanism is derived from variational inference principles. The synaptic plasticity rules found are interesting in that they are strongly reminiscent of experimental Spike Time Dependent Plasticity, and in that they differ for excitatory and inhibitory neurons. A simulation confirms the method's applicability to learning both stationary and temporal spike patterns.\n",
      "Design Principles of the Hippocampal Cognitive Map\n",
      "Hippocampal place fields have been shown to reflect behaviorally relevant aspects of space. For instance, place fields tend to be skewed along commonly traveled directions, they cluster around rewarded locations, and they are constrained by the geometric structure of the environment. We hypothesize a set of design principles for the hippocampal cognitive map that explain how place fields represent space in a way that facilitates navigation and reinforcement learning. In particular, we suggest that place fields encode not just information about the current location, but also predictions about future locations under the current transition distribution. Under this model, a variety of place field phenomena arise naturally from the structure of rewards, barriers, and directional biases as reflected in the transition policy. Furthermore, we demonstrate that this representation of space can support efficient reinforcement learning. We also propose that grid cells compute the eigendecomposition of place fields in part because is useful for segmenting an enclosure along natural boundaries. When applied recursively, this segmentation can be used to discover a hierarchical decomposition of space. Thus, grid cells might be involved in computing subgoals for hierarchical reinforcement learning.\n",
      "Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling\n",
      "The goal of perception is to infer the hidden states in the hierarchical process by which sensory data are generated. Human behavior is consistent with the optimal statistical solution to this problem in many tasks, including cue combination and orientation detection. Understanding the neural mechanisms underlying this behavior is of particular importance, since probabilistic computations are notoriously challenging. Here we propose a simple mechanism for Bayesian inference which involves averaging over a few feature detection neurons which fire at a rate determined by their similarity to a sensory stimulus. This mechanism is based on a Monte Carlo method known as importance sampling, commonly used in computer science and statistics. Moreover, a simple extension to recursive importance sampling can be used to perform hierarchical Bayesian inference. We identify a scheme for implementing importance sampling with spiking neurons, and show that this scheme can account for human behavior in cue combination and the oblique effect.\n",
      "Direction Selective Silicon Retina that uses Null Inhibition\n",
      "Biological retinas extract spatial and temporal features in an attempt to reduce the complexity of performing visual tasks. We have built and tested a silicon retina which encodes several useful temporal features found in vertebrate retinas. The cells in our silicon retina are selective to direction, highly sensitive to positive contrast changes around an ambient light level, and tuned to a particular velocity. Inhibitory connections in the null direction perform the direction selectivity we desire. This silicon retina is on a 4.6 × 6.8mm die and consists of a 47 × 41 array of photoreceptors.\n",
      "Hierarchical Bayesian Inference in Networks of Spiking Neurons\n",
      "There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-fire neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4.\n",
      "Markov Chain Monte Carlo with People\n",
      "Many formal models of cognition implicitly use subjective probability distributions to capture the assumptions of human learners. Most applications of these models determine these distributions indirectly. We propose a method for directly determining the assumptions of human learners by sampling from subjective probability distributions. Using a correspondence between a model of human choice and Markov chain Monte Carlo (MCMC), we describe a method for sampling from the distributions over objects that people associate with different categories. In our task, subjects choose whether to accept or reject a proposed change to an object. The task is constructed so that these decisions follow an MCMC acceptance rule, defining a Markov chain for which the stationary distribution is the category distribution. We test this procedure for both artificial categories acquired in the laboratory, and natural categories acquired from experience.\n",
      "A Neural Implementation of the Kalman Filter\n",
      "Recent experimental evidence suggests that the brain is capable of approximating Bayesian inference in the face of noisy input stimuli. Despite this progress, the neural underpinnings of this computation are still poorly understood. In this paper we focus on the Bayesian filtering of stochastic time series and introduce a novel neural network, derived from a line attractor architecture, whose dynamics map directly onto those of the Kalman filter in the limit of small prediction error. When the prediction error is large we show that the network responds robustly to changepoints in a way that is qualitatively compatible with the optimal Bayesian model. The model suggests ways in which probability distributions are encoded in the brain and makes a number of testable experimental predictions.\n",
      "Action from Still Image Dataset and Inverse Optimal Control to Learn Task Specific Visual Scanpaths\n",
      "Human eye movements provide a rich source of information into the human visual information processing. The complex interplay between the task and the visual stimulus is believed to determine human eye movements, yet it is not fully understood, making it difficult to develop reliable eye movement prediction systems. Our work makes three contributions towards addressing this problem. First, we complement one of the largest and most challenging static computer vision datasets, VOC 2012 Actions, with human eye movement recordings collected under the primary task constraint of action recognition, as well as, separately, for context recognition, in order to analyze the impact of different tasks. Our dataset is unique among the eyetracking datasets of still images in terms of large scale (over 1 million fixations recorded in 9157 images) and different task controls. Second, we propose Markov models to automatically discover areas of interest (AOI) and introduce novel sequential consistency metrics based on them. Our methods can automatically determine the number, the spatial support and the transitions between AOIs, in addition to their locations. Based on such encodings, we quantitatively show that given unconstrained read-world stimuli, task instructions have significant influence on the human visual search patterns and are stable across subjects. Finally, we leverage powerful machine learning techniques and computer vision features in order to learn task-sensitive reward functions from eye movement data within models that allow to effectively predict the human visual search patterns based on inverse optimal control. The methodology achieves state of the art scanpath modeling results.\n",
      "Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies\n",
      "Learning a visual concept from a small number of positive examples is a significant challenge for machine learning algorithms. Current methods typically fail to find the appropriate level of generalization in a concept hierarchy for a given set of visual examples. Recent work in cognitive science on Bayesian models of generalization addresses this challenge, but prior results assumed that objects were perfectly recognized. We present an algorithm for learning visual concepts directly from images, using probabilistic predictions generated by visual classifiers as the input to a Bayesian generalization model. As no existing challenge data tests this paradigm, we collect and make available a new, large-scale dataset for visual concept learning using the ImageNet hierarchy as the source of possible concepts, with human annotators to provide ground truth labels as to whether a new image is an instance of each concept using a paradigm similar to that used in experiments studying word learning in children. We compare the performance of our system to several baseline algorithms, and show a significant advantage results from combining visual classifiers with the ability to identify an appropriate level of abstraction using Bayesian generalization.\n",
      "How fast to work: Response vigor, motivation and tonic dopamine\n",
      "Reinforcement learning models have long promised to unify computational, psychological and neural accounts of appetitively conditioned behavior. However, the bulk of data on animal conditioning comes from free-operant experiments measuring how fast animals will work for reinforcement. Existing reinforcement learning (RL) models are silent about these tasks, because they lack any notion of vigor. They thus fail to address the simple observation that hungrier animals will work harder for food, as well as stranger facts such as their sometimes greater productivity even when working for irrelevant outcomes such as water. Here, we develop an RL framework for free-operant behavior, suggesting that subjects choose how vigorously to perform selected actions by optimally balancing the costs and benefits of quick responding. Motivational states such as hunger shift these factors, skewing the tradeoff. This accounts normatively for the effects of motivation on response rates, as well as many other classic findings. Finally, we suggest that tonic levels of dopamine may be involved in the computation linking motivational state to optimal responding, thereby explaining the complex vigor-related effects of pharmacological manipulation of dopamine.\n",
      "An Analog VLSI Model of the Fly Elementary Motion Detector\n",
      "Flies are capable of rapidly detecting and integrating visual motion information in behaviorly-relevant ways. The first stage of visual motion processing in flies is a retinotopic array of functional units known as elementary motion detectors (EMDs). Several decades ago, Reichardt and colleagues developed a correlation-based model of motion detection that described the behavior of these neural circuits. We have implemented a variant of this model in a 2.0-µm analog CMOS VLSI process. The result is a low-power, continuous-time analog circuit with integrated photoreceptors that responds to motion in real time. The responses of the circuit to drifting sinusoidal gratings qualitatively resemble the temporal frequency response, spatial frequency response, and direction selectivity of motion-sensitive neurons observed in insects. In addition to its possible engineering applications, the circuit could potentially be used as a building block for constructing hardware models of higher-level insect motion integration.\n",
      "A Recurrent Model of Orientation Maps with Simple and Complex Cells\n",
      "We describe a neuromorphic chip that utilizes transistor heterogeneity, introduced by the fabrication process, to generate orientation maps similar to those imaged in vivo. Our model consists of a recurrent network of excitatory and inhibitory cells in parallel with a push-pull stage. Similar to a previous model the recurrent network displays hotspots of activity that give rise to visual feature maps. Unlike previous work, however, the map for orientation does not depend on the sign of contrast. Instead, sign-independent cells driven by both ON and OFF channels anchor the map, while push-pull interactions give rise to sign-preserving cells. These two groups of orientation-selective cells are similar to complex and simple cells observed in V1.\n",
      "Real Time Voice Processing with Audiovisual Feedback: Toward Autonomous Agents with Perfect Pitch\n",
      "We have implemented a real time front end for detecting voiced speech and estimating its fundamental frequency. The front end performs the signal processing for voice-driven agents that attend to the pitch contours of human speech and provide continuous audiovisual feedback. The algorithm we use for pitch tracking has several distinguishing features: it makes no use of FFTs or autocorrelation at the pitch period; it updates the pitch incrementally on a sample-by-sample basis; it avoids peak picking and does not require interpolation in time or frequency to obtain high resolution estimates; and it works reliably over a four octave range, in real time, without the need for postprocessing to produce smooth contours. The algorithm is based on two simple ideas in neural computation: the introduction of a purposeful nonlinearity, and the error signal of a least squares fit. The pitch tracker is used in two real time multimedia applications: a voice-to-MIDI player that synthesizes electronic music from vocalized melodies, and an audiovisual Karaoke machine with multimodal feedback. Both applications run on a laptop and display the user's pitch scrolling across the screen as he or she sings into the computer.\n",
      "Learning and using relational theories\n",
      "Much of human knowledge is organized into sophisticated systems that are often called intuitive theories. We propose that intuitive theories are mentally represented in a logical language, and that the subjective complexity of a theory is determined by the length of its representation in this language. This complexity measure helps to explain how theories are learned from relational data, and how they support inductive inferences about unobserved relations. We describe two experiments that test our approach, and show that it provides a better account of human learning and reasoning than an approach developed by Goodman [1].\n",
      "GP kernels for cross-spectrum analysis\n",
      "Multi-output Gaussian processes provide a convenient framework for multi-task problems. An illustrative and motivating example of a multi-task problem is multi-region electrophysiological time-series data, where experimentalists are interested in both power and phase coherence between channels. Recently, Wilson and Adams (2013) proposed the spectral mixture (SM) kernel to model the spectral density of a single task in a Gaussian process framework. In this paper, we develop a novel covariance kernel for multiple outputs, called the cross-spectral mixture (CSM) kernel. This new, flexible kernel represents both the power and phase relationship between multiple observation channels. We demonstrate the expressive capabilities of the CSM kernel through implementation of a Bayesian hidden Markov model, where the emission distribution is a multi-output Gaussian process with a CSM covariance kernel. Results are presented for measured multi-region electrophysiological data.\n",
      "Fast and accurate spike sorting of high-channel count probes with KiloSort\n",
      "New silicon technology is enabling large-scale electrophysiological recordings in vivo from hundreds to thousands of channels. Interpreting these recordings requires scalable and accurate automated methods for spike sorting, which should minimize the time required for manual curation of the results. Here we introduce KiloSort, a new integrated spike sorting framework that uses template matching both during spike detection and during spike clustering. KiloSort models the electrical voltage as a sum of template waveforms triggered on the spike times, which allows overlapping spikes to be identified and resolved. Unlike previous algorithms that compress the data with PCA, KiloSort operates on the raw data which allows it to construct a more accurate model of the waveforms. Processing times are faster than in previous algorithms thanks to batch-based optimization on GPUs. We compare KiloSort to an established algorithm and show favorable performance, at much reduced processing times. A novel post-clustering merging step based on the continuity of the templates further reduced substantially the number of manual operations required on this data, for the neurons with near-zero error rates, paving the way for fully automated spike sorting of multichannel electrode recordings.\n",
      "Boosting with Spatial Regularization\n",
      "By adding a spatial regularization kernel to a standard loss function formulation of the boosting problem, we develop a framework for spatially informed boosting. From this regularized loss framework we derive an efficient boosting algorithm that uses additional weights/priors on the base classifiers. We prove that the proposed algorithm exhibits a grouping effect, which encourages the selection of all spatially local, discriminative base classifiers. The algorithm's primary advantage is in applications where the trained classifier is used to identify the spatial pattern of discriminative information, e.g. the voxel selection problem in fMRI. We demonstrate the algorithm's performance on various data sets.\n",
      "Onset-based Sound Segmentation\n",
      "A technique for segmenting sounds using processing based on mammalian early auditory processing is presented. The technique is based on features in sound which neuron spike recording suggests are detected in the cochlear nucleus. The sound signal is bandpassed and each signal processed to enhance onsets and offsets. The onset and offset signals are compressed, then clustered both in time and across frequency channels using a network of integrate-and-fire neurons. Onsets and offsets are signalled by spikes, and the timing of these spikes used to segment the sound.\n",
      "Sparse Coding of Natural Images Using an Overcomplete Set of Limited Capacity Units\n",
      "It has been suggested that the primary goal of the sensory system is to represent input in such a way as to reduce the high degree of redundancy. Given a noisy neural representation, however, solely reducing redundancy is not desirable, since redundancy is the only clue to reduce the effects of noise. Here we propose a model that best balances redundancy reduction and redundant representation. Like previous models, our model accounts for the localized and oriented structure of simple cells, but it also predicts a different organization for the population. With noisy, limited-capacity units, the optimal representation becomes an overcomplete, multi-scale representation, which, compared to previous models, is in closer agreement with physiological data. These results offer a new perspective on the expansion of the number of neurons from retina to V1 and provide a theoretical model of incorporating useful redundancy into efficient neural representations.\n",
      "Subject independent EEG-based BCI decoding\n",
      "In the quest to make Brain Computer Interfacing (BCI) more usable, dry electrodes have emerged that get rid of the initial 30 minutes required for placing an electrode cap. Another time consuming step is the required individualized adaptation to the BCI user, which involves another 30 minutes calibration for assessing a subject's brain signature. In this paper we aim to also remove this calibration proceedure from BCI setup time by means of machine learning. In particular, we harvest a large database of EEG BCI motor imagination recordings (83 subjects) for constructing a library of subject-specific spatio-temporal filters and derive a subject independent BCI classifier. Our offline results indicate that BCI-native users could start real-time BCI use with no prior calibration at only a very moderate performance loss.\n",
      "A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model\n",
      "We describe an accelerated hardware neuron being capable of emulating the adaptive exponential integrate-and-fire neuron model. Firing patterns of the membrane stimulated by a step current are analyzed in transistor level simulations and in silicon on a prototype chip. The neuron is destined to be the hardware neuron of a highly integrated wafer-scale system reaching out for new computational paradigms and opening new experimentation possibilities. As the neuron is dedicated as a universal device for neuroscientific experiments, the focus lays on parameterizability and reproduction of the analytical model.\n",
      "Burn-in, bias, and the rationality of anchoring\n",
      "Bayesian inference provides a unifying framework for addressing problems in machine learning, artificial intelligence, and robotics, as well as the problems facing the human mind. Unfortunately, exact Bayesian inference is intractable in all but the simplest models. Therefore minds and machines have to approximate Bayesian inference. Approximate inference algorithms can achieve a wide range of time-accuracy tradeoffs, but what is the optimal tradeoff? We investigate time-accuracy tradeoffs using the Metropolis-Hastings algorithm as a metaphor for the mind's inference algorithm(s). We find that reasonably accurate decisions are possible long before the Markov chain has converged to the posterior distribution, i.e. during the period known as burn-in. Therefore the strategy that is optimal subject to the mind's bounded processing speed and opportunity costs may perform so few iterations that the resulting samples are biased towards the initial value. The resulting cognitive process model provides a rational basis for the anchoring-and-adjustment heuristic. The model's quantitative predictions are tested against published data on anchoring in numerical estimation tasks. Our theoretical and empirical results suggest that the anchoring bias is consistent with approximate Bayesian inference.\n",
      "Sensory Adaptation within a Bayesian Framework for Perception\n",
      "We extend a previously developed Bayesian framework for perception to account for sensory adaptation. We first note that the perceptual effects of adaptation seems inconsistent with an adjustment of the internally represented prior distribution. Instead, we postulate that adaptation increases the signal-to-noise ratio of the measurements by adapting the operational range of the measurement stage to the input range. We show that this changes the likelihood function in such a way that the Bayesian estimator model can account for reported perceptual behavior. In particular, we compare the model's predictions to human motion discrimination data and demonstrate that the model accounts for the commonly observed perceptual adaptation effects of repulsion and enhanced discriminability.\n",
      "The Maximal Causes of Natural Scenes are Edge Filters\n",
      "We study the application of a strongly non-linear generative model to image patches. As in standard approaches such as Sparse Coding or Independent Component Analysis, the model assumes a sparse prior with independent hidden variables. However, in the place where standard approaches use the sum to combine basis functions we use the maximum. To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization. The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables. Furthermore, we can infer all model parameters including observation noise and the degree of sparseness. In applications to image patches we find that Gabor-like basis functions are obtained. Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition. Quantitatively, the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions. The distribution of basis function shapes reflects properties of simple cell receptive fields that are not reproduced by standard linear approaches. In the study of natural image statistics, the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging. The presented algorithm represents the first large-scale application of such an approach.\n",
      "Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions\n",
      "The human brain can be described as containing a number of functional regions. These regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions, ignoring the connections between them. In this paper we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classifier of one region of interest (ROI) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level (the classifier combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs.\n",
      "Dependent Dirichlet Process Spike Sorting\n",
      "In this paper we propose a new incremental spike sorting model that automatically eliminates refractory period violations, accounts for action potential waveform drift, and can handle appearance and disappearance of neurons. Our approach is to augment a known time-varying Dirichlet process that ties together a sequence of infinite Gaussian mixture models, one per action potential waveform observation, with an interspike-interval-dependent likelihood that prohibits refractory period violations. We demonstrate this model by showing results from sorting two publicly available neural data recordings for which a partial ground truth labeling is known.\n",
      "Toddler-Inspired Visual Object Learning\n",
      "Real-world learning systems have practical limitations on the quality and quantity of the datasets that they can collect and consider. How should a system go about choosing a subset of the possible examples that still allows for learning accurate, generalizable models? To help address this question, we draw inspiration from a highly efficient practical learning system: the human child. Using head-mounted cameras, eye gaze trackers, and a model of foveated vision, we collected first-person (egocentric) images that represents a highly accurate approximation of the training that toddlers' visual systems collect in everyday, naturalistic learning contexts. We used state-of-the-art computer vision learning models (convolutional neural networks) to help characterize the structure of these data, and found that child data produce significantly better object models than egocentric data experienced by adults in exactly the same environment. By using the CNNs as a modeling tool to investigate the properties of the child data that may enable this rapid learning, we found that child data exhibit a unique combination of quality and diversity, with not only many similar large, high-quality object views but also a greater number and diversity of rare views. This novel methodology of analyzing the visual training used by children may not only reveal insights to improve machine learning, but also may suggest new experimental tools to better understand infant learning in developmental psychology.\n",
      "What is a Cluster? Perspectives from Graph Theory\n",
      "There is no shortage of clustering algorithms, and recently a new wave of excitement has spread across the machine learning community mainly because of the important development of spectral methods. At the same time, there is also growing interest around fundamental questions pertaining to the very nature of the clustering problem (see, e.g., [17, 1, 28]). Yet, despite the tremendous progress in the field, the clustering problem remains elusive and a satisfactory answer even to the most basic questions is still to come.\n",
      "Neural Reconstruction with Approximate Message Passing (NeuRAMP)\n",
      "Many functional descriptions of spiking neurons assume a cascade structure where inputs are passed through an initial linear filtering stage that produces a low-dimensional signal that drives subsequent nonlinear stages. This paper presents a novel and systematic parameter estimation procedure for such models and applies the method to two neural estimation problems: (i) compressed-sensing based neural mapping from multi-neuron excitation, and (ii) estimation of neural receptive fields in sensory neurons. The proposed estimation algorithm models the neurons via a graphical model and then estimates the parameters in the model using a recently-developed generalized approximate message passing (GAMP) method. The GAMP method is based on Gaussian approximations of loopy belief propagation. In the neural connectivity problem, the GAMP-based method is shown to be computational efficient, provides a more exact modeling of the sparsity, can incorporate nonlinearities in the output and significantly outperforms previous compressed-sensing methods. For the receptive field estimation, the GAMP method can also exploit inherent structured sparsity in the linear weights. The method is validated on estimation of linear nonlinear Poisson (LNP) cascade models for receptive fields of salamander retinal ganglion cells.\n",
      "Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech\n",
      "An eigenvalue method is developed for analyzing periodic structure in speech. Signals are analyzed by a matrix diagonalization reminiscent of methods for principal component analysis (PCA) and independent component analysis (ICA). Our method--called periodic component analysis (πCA)--uses constructive interference to enhance periodic components of the frequency spectrum and destructive interference to cancel noise. The front end emulates important aspects of auditory processing, such as cochlear filtering, nonlinear compression, and insensitivity to phase, with the aim of approaching the robustness of human listeners. The method avoids the inefficiencies of autocorrelation at the pitch period: it does not require long delay lines, and it correlates signals at a clock rate on the order of the actual pitch, as opposed to the original sampling rate. We derive its cost function and present some experimental results.\n",
      "Learning optimal spike-based representations\n",
      "How can neural networks learn to represent information optimally? We answer this question by deriving spiking dynamics and learning dynamics directly from a measure of network performance. We find that a network of integrate-and-fire neurons undergoing Hebbian plasticity can learn an optimal spike-based representation for a linear decoder. The learning rule acts to minimise the membrane potential magnitude, which can be interpreted as a representation error after learning. In this way, learning reduces the representation error and drives the network into a robust, balanced regime. The network becomes balanced because small representation errors correspond to small membrane potentials, which in turn results from a balance of excitation and inhibition. The representation is robust because neurons become self-correcting, only spiking if the representation error exceeds a threshold. Altogether, these results suggest that several observed features of cortical dynamics, such as excitatory-inhibitory balance, integrate-and-fire dynamics and Hebbian plasticity, are signatures of a robust, optimal spike-based code.\n",
      "Bayesian optimization explains human active search\n",
      "Many real-world problems have complicated objective functions. To optimize such functions, humans utilize sophisticated sequential decision-making strategies. Many optimization algorithms have also been developed for this same purpose, but how do they compare to humans in terms of both performance and behavior? We try to unravel the general underlying algorithm people may be using while searching for the maximum of an invisible 1D function. Subjects click on a blank screen and are shown the ordinate of the function at each clicked abscissa location. Their task is to find the function's maximum in as few clicks as possible. Subjects win if they get close enough to the maximum location. Analysis over 23 non-maths undergraduates, optimizing 25 functions from different families, shows that humans outperform 24 well-known optimization algorithms. Bayesian Optimization based on Gaussian Processes, which exploits all the x values tried and all the f (x) values obtained so far to pick the next x, predicts human performance and searched locations better. In 6 follow-up controlled experiments over 76 subjects, covering interpolation, extrapolation, and optimization tasks, we further confirm that Gaussian Processes provide a general and unified theoretical account to explain passive and active function learning and search in humans.\n",
      "Policy Gradient Coagent Networks\n",
      "We present a novel class of actor-critic algorithms for actors consisting of sets of interacting modules. We present, analyze theoretically, and empirically evaluate an update rule for each module, which requires only local information: the module's input, output, and the TD error broadcast by a critic. Such updates are necessary when computation of compatible features becomes prohibitively difficult and are also desirable to increase the biological plausibility of reinforcement learning methods.\n",
      "Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement\n",
      "Working memory is a central topic of cognitive neuroscience because it is critical for solving real-world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior. However, an often neglected fact is that learning to use working memory effectively is itself a difficult problem. The Gating framework [1-4] is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems. We unite Gating with machine learning theory concerning the general problem of memory-based optimal control [5-6]. We present a normative model that learns, by online temporal difference methods, to use working memory to maximize discounted future reward in partially observable settings. The model successfully solves a benchmark working memory problem, and exhibits limitations similar to those observed in humans. Our purpose is to introduce a concise, normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards.\n",
      "Human memory search as a random walk in a semantic network\n",
      "The human mind has a remarkable ability to store a vast amount of information in memory, and an even more remarkable ability to retrieve these experiences when needed. Understanding the representations and algorithms that underlie human memory search could potentially be useful in other information retrieval settings, including internet search. Psychological studies have revealed clear regularities in how people search their memory, with clusters of semantically related items tending to be retrieved together. These findings have recently been taken as evidence that human memory search is similar to animals foraging for food in patchy environments, with people making a rational decision to switch away from a cluster of related information as it becomes depleted. We demonstrate that the results that were taken as evidence for this account also emerge from a random walk on a semantic network, much like the random web surfer model used in internet search engines. This offers a simpler and more unified account of how people search their memory, postulating a single process rather than one process for exploring a cluster and one process for switching between clusters.\n",
      "Probabilistic amplitude and frequency demodulation\n",
      "A number of recent scientific and engineering problems require signals to be decomposed into a product of a slowly varying positive envelope and a quickly varying carrier whose instantaneous frequency also varies slowly over time. Although signal processing provides algorithms for so-called amplitude- and frequency-demodulation (AFD), there are well known problems with all of the existing methods. Motivated by the fact that AFD is ill-posed, we approach the problem using probabilistic inference. The new approach, called probabilistic amplitude and frequency demodulation (PAFD), models instantaneous frequency using an auto-regressive generalization of the von Mises distribution, and the envelopes using Gaussian auto-regressive dynamics with a positivity constraint. A novel form of expectation propagation is used for inference. We demonstrate that although PAFD is computationally demanding, it outperforms previous approaches on synthetic and real signals in clean, noisy and missing data settings.\n",
      "Sequential effects reflect parallel learning of multiple environmental regularities\n",
      "Across a wide range of cognitive tasks, recent experience influences behavior. For example, when individuals repeatedly perform a simple two-alternative forced-choice task (2AFC), response latencies vary dramatically based on the immediately preceding trial sequence. These sequential effects have been interpreted as adaptation to the statistical structure of an uncertain, changing environment (e.g., Jones and Sieck, 2003; Mozer, Kinoshita, and Shettel, 2007; Yu and Cohen, 2008). The Dynamic Belief Model (DBM) (Yu and Cohen, 2008) explains sequential effects in 2AFC tasks as a rational consequence of a dynamic internal representation that tracks second-order statistics of the trial sequence (repetition rates) and predicts whether the upcoming trial will be a repetition or an alternation of the previous trial. Experimental results suggest that first-order statistics (base rates) also influence sequential effects. We propose a model that learns both first- and second-order sequence properties, each according to the basic principles of the DBM but under a unified inferential framework. This model, the Dynamic Belief Mixture Model (DBM2), obtains precise, parsimonious fits to data. Furthermore, the model predicts dissociations in behavioral (Maloney, Martello, Sahm, and Spillmann, 2005) and electrophysiological studies (Jentzsch and Sommer, 2002), supporting the psychological and neurobiological reality of its two components.\n",
      "Targeting EEG/LFP Synchrony with Neural Nets\n",
      "We consider the analysis of Electroencephalography (EEG) and Local Field Potential (LFP) datasets, which are “big” in terms of the size of recorded data but rarely have sufficient labels required to train complex models (e.g., conventional deep learning methods). Furthermore, in many scientific applications, the goal is to be able to understand the underlying features related to the classification, which prohibits the blind application of deep networks. This motivates the development of a new model based on {\\em parameterized} convolutional filters guided by previous neuroscience research; the filters learn relevant frequency bands while targeting synchrony, which are frequency-specific power and phase correlations between electrodes. This results in a highly expressive convolutional neural network with only a few hundred parameters, applicable to smaller datasets. The proposed approach is demonstrated to yield competitive (often state-of-the-art) predictive performance during our empirical tests while yielding interpretable features. Furthermore, a Gaussian process adapter is developed to combine analysis over distinct electrode layouts, allowing the joint processing of multiple datasets to address overfitting and improve generalizability. Finally, it is demonstrated that the proposed framework effectively tracks neural dynamics on children in a clinical trial on Autism Spectrum Disorder.\n",
      "A normative theory of adaptive dimensionality reduction in neural networks\n",
      "To make sense of the world our brains must analyze high-dimensional datasets streamed by our sensory organs. Because such analysis begins with dimensionality reduction, modeling early sensory processing requires biologically plausible online dimensionality reduction algorithms. Recently, we derived such an algorithm, termed similarity matching, from a Multidimensional Scaling (MDS) objective function. However, in the existing algorithm, the number of output dimensions is set a priori by the number of output neurons and cannot be changed. Because the number of informative dimensions in sensory inputs is variable there is a need for adaptive dimensionality reduction. Here, we derive biologically plausible dimensionality reduction algorithms which adapt the number of output dimensions to the eigenspectrum of the input covariance matrix. We formulate three objective functions which, in the offline setting, are optimized by the projections of the input dataset onto its principal subspace scaled by the eigenvalues of the output covariance matrix. In turn, the output eigenvalues are computed as i) soft-thresholded, ii) hard-thresholded, iii) equalized thresholded eigenvalues of the input covariance matrix. In the online setting, we derive the three corresponding adaptive algorithms and map them onto the dynamics of neuronal activity in networks with biologically plausible local learning rules. Remarkably, in the last two networks, neurons are divided into two classes which we identify with principal neurons and interneurons in biological circuits.\n",
      "Modeling Neuronal Interactivity using Dynamic Bayesian Networks\n",
      "Functional Magnetic Resonance Imaging (fMRI) has enabled scientists to look into the active brain. However, interactivity between functional brain regions, is still little studied. In this paper, we contribute a novel framework for modeling the interactions between multiple active brain regions, using Dynamic Bayesian Networks (DBNs) as generative models for brain activation patterns. This framework is applied to modeling of neuronal circuits associated with reward. The novelty of our framework from a Machine Learning perspective lies in the use of DBNs to reveal the brain connectivity and interactivity. Such interactivity models which are derived from fMRI data are then validated through a group classification task. We employ and compare four different types of DBNs: Parallel Hidden Markov Models, Coupled Hidden Markov Models, Fully-linked Hidden Markov Models and Dynamically Multi-Linked HMMs (DML-HMM). Moreover, we propose and compare two schemes of learning DML-HMMs. Experimental results show that by using DBNs, group classification can be performed even if the DBNs are constructed from as few as 5 brain regions. We also demonstrate that, by using the proposed learning algorithms, different DBN structures characterize drug addicted subjects vs. control subjects. This finding provides an independent test for the effect of psychopathology on brain function. In general, we demonstrate that incorporation of computer science principles into functional neuroimaging clinical studies provides a novel approach for probing human brain function.\n",
      "Inferring neural population dynamics from multiple partial recordings of the same neural circuit\n",
      "Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for stitching together sequentially imaged sets of neurons into one model by phrasing the problem as fitting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs.\n",
      "Using Feedforward Neural Networks to Monitor Alertness from Changes in EEG Correlation and Coherence\n",
      "We report here that changes in the normalized electroencephalographic (EEG) cross-spectrum can be used in conjunction with feedforward neural networks to monitor changes in alertness of operators continuously and in near-real time. Previously, we have shown that EEG spectral amplitudes covary with changes in alertness as indexed by changes in behavioral error rate on an auditory detection task [6,4]. Here, we report for the first time that increases in the frequency of detection errors in this task are also accompanied by patterns of increased and decreased spectral coherence in several frequency bands and EEG channel pairs. Relationships between EEG coherence and performance vary between subjects, but within subjects, their topographic and spectral profiles appear stable from session to session. Changes in alertness also covary with changes in correlations among EEG waveforms recorded at different scalp sites, and neural networks can also estimate alertness from correlation changes in spontaneous and unobtrusively-recorded EEG signals.\n",
      "Extracting regions of interest from biological images with convolutional sparse block coding\n",
      "Biological tissue is often composed of cells with similar morphologies replicated throughout large volumes and many biological applications rely on the accurate identification of these cells and their locations from image data. Here we develop a generative model that captures the regularities present in images composed of repeating elements of a few different types. Formally, the model can be described as convolutional sparse block coding. For inference we use a variant of convolutional matching pursuit adapted to block-based representations. We extend the K-SVD learning algorithm to subspaces by retaining several principal vectors from the SVD decomposition instead of just one. Good models with little cross-talk between subspaces can be obtained by learning the blocks incrementally. We perform extensive experiments on simulated images and the inference algorithm consistently recovers a large proportion of the cells with a small number of false positives. We fit the convolutional model to noisy GCaMP6 two-photon images of spiking neurons and to Nissl-stained slices of cortical tissue and show that it recovers cell body locations without supervision. The flexibility of the block-based representation is reflected in the variability of the recovered cell shapes.\n",
      "Algorithm selection by rational metareasoning as a model of human strategy selection\n",
      "Selecting the right algorithm is an important problem in computer science, because the algorithm often has to exploit the structure of the input to be efficient. The human mind faces the same challenge. Therefore, solutions to the algorithm selection problem can inspire models of human strategy selection and vice versa. Here, we view the algorithm selection problem as a special case of metareasoning and derive a solution that outperforms existing methods in sorting algorithm selection. We apply our theory to model how people choose between cognitive strategies and test its prediction in a behavioral experiment. We find that people quickly learn to adaptively choose between cognitive strategies. People's choices in our experiment are consistent with our model but inconsistent with previous theories of human strategy selection. Rational metareasoning appears to be a promising framework for reverse-engineering how people choose among cognitive strategies and translating the results into better solutions to the algorithm selection problem.\n",
      "Heuristics for Ordering Cue Search in Decision Making\n",
      "Simple lexicographic decision heuristics that consider cues one at a time in a particular order and stop searching for cues as soon as a decision can be made have been shown to be both accurate and frugal in their use of information. But much of the simplicity and success of these heuristics comes from using an appropriate cue order. For instance, the Take The Best heuristic uses validity order for cues, which requires considerable computation, potentially undermining the computational advantages of the simple decision mechanism. But many cue orders can achieve good decision performance, and studies of sequential search for data records have proposed a number of simple ordering rules that may be of use in constructing appropriate decision cue orders as well. Here we consider a range of simple cue ordering mechanisms, including tallying, swapping, and move-to-front rules, and show that they can find cue orders that lead to reasonable accuracy and considerable frugality when used with lexicographic decision heuristics.\n",
      "Near-Maximum Entropy Models for Binary Neural Representations of Natural Images\n",
      "Maximum entropy analysis of binary variables provides an elegant way for studying the role of pairwise correlations in neural populations. Unfortunately, these approaches suffer from their poor scalability to high dimensions. In sensory coding, however, high-dimensional data is ubiquitous. Here, we introduce a new approach using a near-maximum entropy model, that makes this type of analysis feasible for very high-dimensional data—the model parameters can be derived in closed form and sampling is easy. Therefore, our NearMaxEnt approach can serve as a tool for testing predictions from a pairwise maximum entropy model not only for low-dimensional marginals, but also for high dimensional measurements of more than thousand units. We demonstrate its usefulness by studying natural images with dichotomized pixel intensities. Our results indicate that the statistics of such higher-dimensional measurements exhibit additional structure that are not predicted by pairwise correlations, despite the fact that pairwise correlations explain the lower-dimensional marginal statistics surprisingly well up to the limit of dimensionality where estimation of the full joint distribution is feasible.\n",
      "A rational model of preference learning and choice prediction by children\n",
      "Young children demonstrate the ability to make inferences about the preferences of other agents based on their choices. However, there exists no overarching account of what children are doing when they learn about preferences or how they use that knowledge. We use a rational model of preference learning, drawing on ideas from economics and computer science, to explain the behavior of children in several recent experiments. Specifically, we show how a simple econometric model can be extended to capture two- to four-year-olds' use of statistical information in inferring preferences, and their generalization of these preferences.\n",
      "Convergence Properties of Some Spike-Triggered Analysis Techniques\n",
      "We analyze the convergence properties of three spike-triggered data analysis techniques. All of our results are obtained in the setting of a (possibly multidimensional) linear-nonlinear (LN) cascade model for stimulus-driven neural activity. We start by giving exact rate of convergence results for the common spike-triggered average (STA) technique. Next, we analyze a spike-triggered covariance method, variants of which have been recently exploited successfully by Bialek, Simoncelli, and colleagues. These first two methods suffer from extraneous conditions on their convergence; therefore, we introduce an estimator for the LN model parameters which is designed to be consistent under general conditions. We provide an algorithm for the computation of this estimator and derive its rate of convergence. We close with a brief discussion of the efficiency of these estimators and an application to data recorded from the primary motor cortex of awake, behaving primates.\n",
      "Why are some word orders more common than others? A uniform information density account\n",
      "Languages vary widely in many ways, including their canonical word order. A basic aspect of the observed variation is the fact that some word orders are much more common than others. Although this regularity has been recognized for some time, it has not been well-explained. In this paper we offer an information-theoretic explanation for the observed word-order distribution across languages, based on the concept of Uniform Information Density (UID). We suggest that object-first languages are particularly disfavored because they are highly non-optimal if the goal is to distribute information content approximately evenly throughout a sentence, and that the rest of the observed word-order distribution is at least partially explainable in terms of UID. We support our theoretical analysis with data from child-directed speech and experimental work.\n",
      "Spatial Representations in the Parietal Cortex May Use Basis Functions\n",
      "The parietal cortex is thought to represent the egocentric positions of objects in particular coordinate systems. We propose an alternative approach to spatial perception of objects in the parietal cortex from the perspective of sensorimotor transformations. The responses of single parietal neurons can be modeled as a gaussian function of retinal position multiplied by a sigmoid function of eye position, which form a set of basis functions. We show here how these basis functions can be used to generate receptive fields in either retinotopic or head-centered coordinates by simple linear transformations. This raises the possibility that the parietal cortex does not attempt to compute the positions of objects in a particular frame of reference but instead computes a general purpose representation of the retinal location and eye position from which any transformation can be synthesized by direct projection. This representation predicts that hemineglect, a neurological syndrome produced by parietal lesions, should not be confined to egocentric coordinates, but should be observed in multiple frames of reference in single patients, a prediction supported by several experiments.\n",
      "Automatic Discovery of Cognitive Skills to Improve the Prediction of Student Learning\n",
      "To master a discipline such as algebra or physics, students must acquire a set of cognitive skills. Traditionally, educators and domain experts use intuition to determine what these skills are and then select practice exercises to hone a particular skill. We propose a technique that uses student performance data to automatically discover the skills needed in a discipline. The technique assigns a latent skill to each exercise such that a student's expected accuracy on a sequence of same-skill exercises improves monotonically with practice. Rather than discarding the skills identified by experts, our technique incorporates a nonparametric prior over the exercise-skill assignments that is based on the expert-provided skills and a weighted Chinese restaurant process. We test our technique on datasets from five different intelligent tutoring systems designed for students ranging in age from middle school through college. We obtain two surprising results. First, in three of the five datasets, the skills inferred by our technique support significantly improved predictions of student performance over the expert-provided skills. Second, the expert-provided skills have little value: our technique predicts student performance nearly as well when it ignores the domain expertise as when it attempts to leverage it. We discuss explanations for these surprising results and also the relationship of our skill-discovery technique to alternative approaches.\n",
      "Robust learning of low-dimensional dynamics from large neural ensembles\n",
      "Recordings from large populations of neurons make it possible to search for hypothesized low-dimensional dynamics. Finding these dynamics requires models that take into account biophysical constraints and can be fit efficiently and robustly. Here, we present an approach to dimensionality reduction for neural data that is convex, does not make strong assumptions about dynamics, does not require averaging over many trials and is extensible to more complex statistical models that combine local and global influences. The results can be combined with spectral methods to learn dynamical systems models. The basic method extends PCA to the exponential family using nuclear norm minimization. We evaluate the effectiveness of this method using an exact decomposition of the Bregman divergence that is analogous to variance explained for PCA. We show on model data that the parameters of latent linear dynamical systems can be recovered, and that even if the dynamics are not stationary we can still recover the true latent subspace. We also demonstrate an extension of nuclear norm minimization that can separate sparse local connections from global latent dynamics. Finally, we demonstrate improved prediction on real neural data from monkey motor cortex compared to fitting linear dynamical models without nuclear norm smoothing.\n",
      "Distributional Population Codes and Multiple Motion Models\n",
      "Most theoretical and empirical studies of population codes make the assumption that underlying neuronal activities is a unique and unambiguous value of an encoded quantity. However, population activities can contain additional information about such things as multiple values of or uncertainty about the quantity. We have previously suggested a method to recover extra information by treating the activities of the population of cells as coding for a complete distribution over the coded quantity rather than just a single value. We now show how this approach bears on psychophysical and neurophysiological studies of population codes for motion direction in tasks involving transparent motion stimuli. We show that, unlike standard approaches, it is able to recover multiple motions from population responses, and also that its output is consistent with both correct and erroneous human performance on psychophysical tasks.\n",
      "An exploration-exploitation model based on norepinepherine and dopamine activity\n",
      "We propose a model by which dopamine (DA) and norepinepherine (NE) combine to alternate behavior between relatively exploratory and exploitative modes. The model is developed for a target detection task for which there is extant single neuron recording data available from locus coeruleus (LC) NE neurons. An exploration-exploitation trade-off is elicited by regularly switching which of the two stimuli are rewarded. DA functions within the model to change synaptic weights according to a reinforcement learning algorithm. Exploration is mediated by the state of LC firing, with higher tonic and lower phasic activity producing greater response variability. The opposite state of LC function, with lower baseline firing rate and greater phasic responses, favors exploitative behavior. Changes in LC firing mode result from combined measures of response conflict and reward rate, where response conflict is monitored using models of anterior cingulate cortex (ACC). Increased long-term response conflict and decreased reward rate, which occurs following reward contingency switch, favors the higher tonic state of LC function and NE release. This increases exploration, and facilitates discovery of the new target.\n",
      "Continuous Time Particle Filtering for fMRI\n",
      "We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difficult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle filter and smoother to the task, and discuss some of the practical approaches used to tackle the difficulties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study.\n",
      "A P300 BCI for the Masses: Prior Information Enables Instant Unsupervised Spelling\n",
      "The usability of Brain Computer Interfaces (BCI) based on the P300 speller is severely hindered by the need for long training times and many repetitions of the same stimulus. In this contribution we introduce a set of unsupervised hierarchical probabilistic models that tackle both problems simultaneously by incorporating prior knowledge from two sources: information from other training subjects (through transfer learning) and information about the words being spelled (through language models). We show, that due to this prior knowledge, the performance of the unsupervised models parallels and in some cases even surpasses that of supervised models, while eliminating the tedious training session.\n",
      "Face Reconstruction from Voice using Generative Adversarial Networks\n",
      "Voice profiling aims at inferring various human parameters from their speech, e.g. gender, age, etc. In this paper, we address the challenge posed by a subtask of voice profiling - reconstructing someone's face from their voice. The task is designed to answer the question: given an audio clip spoken by an unseen person, can we picture a face that has as many common elements, or associations as possible with the speaker, in terms of identity? To address this problem, we propose a simple but effective computational framework based on generative adversarial networks (GANs). The network learns to generate faces from voices by matching the identities of generated faces to those of the speakers, on a training set. We evaluate the performance of the network by leveraging a closely related task - cross-modal matching. The results show that our model is able to generate faces that match several biometric characteristics of the speaker, and results in matching accuracies that are much better than chance. The code is publicly available in https://github.com/cmu-mlsp/reconstructing_faces_from_voices\n",
      "Spectral methods for neural characterization using generalized quadratic models\n",
      "We describe a set of fast, tractable methods for characterizing neural responses to high-dimensional sensory stimuli using a model we refer to as the generalized quadratic model (GQM). The GQM consists of a low-rank quadratic function followed by a point nonlinearity and exponential-family noise. The quadratic function characterizes the neuron's stimulus selectivity in terms of a set linear receptive fields followed by a quadratic combination rule, and the invertible nonlinearity maps this output to the desired response range. Special cases of the GQM include the 2nd-order Volterra model [1, 2] and the elliptical Linear-Nonlinear-Poisson model [3]. Here we show that for canonical form GQMs, spectral decomposition of the first two response-weighted moments yields approximate maximum-likelihood estimators via a quantity called the expected log-likelihood. The resulting theory generalizes moment-based estimators such as the spike-triggered co-variance, and, in the Gaussian noise case, provides closed-form estimators under a large class of non-Gaussian stimulus distributions. We show that these estimators are fast and provide highly accurate estimates with far lower computational cost than full maximum likelihood. Moreover, the GQM provides a natural framework for combining multi-dimensional stimulus sensitivity and spike-history dependencies within a single model. We show applications to both analog and spiking data using intracellular recordings of V1 membrane potential and extracellular recordings of retinal spike trains.\n",
      "Cocktail Party Processing via Structured Prediction\n",
      "While human listeners excel at selectively attending to a conversation in a cocktail party, machine performance is still far inferior by comparison. We show that the cocktail party problem, or the speech separation problem, can be effectively approached via structured prediction. To account for temporal dynamics in speech, we employ conditional random fields (CRFs) to classify speech dominance within each time-frequency unit for a sound mixture. To capture complex, nonlinear relationship between input and output, both state and transition feature functions in CRFs are learned by deep neural networks. The formulation of the problem as classification allows us to directly optimize a measure that is well correlated with human speech intelligibility. The proposed system substantially outperforms existing ones in a variety of noises.\n",
      "Why The Brain Separates Face Recognition From Object Recognition\n",
      "Many studies have uncovered evidence that visual cortex contains specialized regions involved in processing faces but not other object classes. Recent electro-physiology studies of cells in several of these specialized regions revealed that at least some of these regions are organized in a hierarchical manner with viewpoint-specific cells projecting to downstream viewpoint-invariant identity-specific cells [1]. A separate computational line of reasoning leads to the claim that some transformations of visual inputs that preserve viewed object identity are class-specific. In particular, the 2D images evoked by a face undergoing a 3D rotation are not produced by the same image transformation (2D) that would produce the images evoked by an object of another class undergoing the same 3D rotation. However, within the class of faces, knowledge of the image transformation evoked by 3D rotation can be reliably transferred from previously viewed faces to help identify a novel face at a new viewpoint. We show, through computational simulations, that an architecture which applies this method of gaining invariance to class-specific transformations is effective when restricted to faces and fails spectacularly when applied to other object classes. We argue here that in order to accomplish viewpoint-invariant face identification from a single example view, visual cortex must separate the circuitry involved in discounting 3D rotations of faces from the generic circuitry involved in processing other objects. The resulting model of the ventral stream of visual cortex is consistent with the recent physiology results showing the hierarchical organization of the face processing network.\n",
      "Recursive training of 2D-3D convolutional networks for neuronal boundary detection\n",
      "Efforts to automate the reconstruction of neural circuits from 3D electron microscopic (EM) brain images are critical for the field of connectomics. An important computation for reconstruction is the detection of neuronal boundaries. Images acquired by serial section EM, a leading 3D EM technique, are highly anisotropic, with inferior quality along the third dimension. For such images, the 2D max-pooling convolutional network has set the standard for performance at boundary detection. Here we achieve a substantial gain in accuracy through three innovations. Following the trend towards deeper networks for object recognition, we use a much deeper network than previously employed for boundary detection. Second, we incorporate 3D as well as 2D filters, to enable computations that use 3D context. Finally, we adopt a recursively trained architecture in which a first network generates a preliminary boundary map that is provided as input along with the original image to a second network that generates a final boundary map. Back-propagation training is accelerated by ZNN, a new implementation of 3D convolutional networks that uses multicore CPU parallelism for speed. Our hybrid 2D-3D architecture could be more generally applicable to other types of anisotropic 3D images, including video, and our recursive framework for any image labeling problem.\n",
      "Learning to Learn with Compound HD Models\n",
      "We introduce HD (or Hierarchical-Deep) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian models. Specifically we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a Deep Boltzmann Machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training examples, by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.\n",
      "Low-dimensional models of neural population activity in sensory cortical circuits\n",
      "Neural responses in visual cortex are influenced by visual stimuli and by ongoing spiking activity in local circuits. An important challenge in computational neuroscience is to develop models that can account for both of these features in large multi-neuron recordings and to reveal how stimulus representations interact with and depend on cortical dynamics. Here we introduce a statistical model of neural population activity that integrates a nonlinear receptive field model with a latent dynamical model of ongoing cortical activity. This model captures temporal dynamics and correlations due to shared stimulus drive as well as common noise. Moreover, because the nonlinear stimulus inputs are mixed by the ongoing dynamics, the model can account for a multiple idiosyncratic receptive field shapes with a small number of nonlinear inputs to a low-dimensional dynamical model. We introduce a fast estimation method using online expectation maximization with Laplace approximations, for which inference scales linearly in both population size and recording duration. We test this model to multi-channel recordings from primary visual cortex and show that it accounts for neural tuning properties as well as cross-neural correlations.\n",
      "Bayesian Models of Inductive Generalization\n",
      "We argue that human inductive generalization is best explained in a Bayesian framework, rather than by traditional models based on similarity computations. We go beyond previous work on Bayesian concept learning by introducing an unsupervised method for constructing flexible hypothesis spaces, and we propose a version of the Bayesian Occam's razor that trades off priors and likelihoods to prevent under- or over-generalization in these flexible spaces. We analyze two published data sets on inductive reasoning as well as the results of a new behavioral study that we have carried out.\n",
      "A Bayesian Framework for Figure-Ground Interpretation\n",
      "Figure/ground assignment, in which the visual image is divided into nearer (figural) and farther (ground) surfaces, is an essential step in visual processing, but its underlying computational mechanisms are poorly understood. Figural assignment (often referred to as border ownership) can vary along a contour, suggesting a spatially distributed process whereby local and global cues are combined to yield local estimates of border ownership. In this paper we model figure/ground estimation in a Bayesian belief network, attempting to capture the propagation of border ownership across the image as local cues (contour curvature and T-junctions) interact with more global cues to yield a figure/ground assignment. Our network includes as a nonlocal factor skeletal (medial axis) structure, under the hypothesis that medial structure draws border ownership so that borders are owned by the skeletal hypothesis that best explains them. We also briefly present a psychophysical experiment in which we measured local border ownership along a contour at various distances from an inducing cue (a T-junction). Both the human subjects and the network show similar patterns of performance, converging rapidly to a similar pattern of spatial variation in border ownership along contours.\n",
      "Bayesian Spike-Triggered Covariance Analysis\n",
      "Neurons typically respond to a restricted number of stimulus features within the high-dimensional space of natural stimuli. Here we describe an explicit model-based interpretation of traditional estimators for a neuron's multi-dimensional feature space, which allows for several important generalizations and extensions. First, we show that traditional estimators based on the spike-triggered average (STA) and spike-triggered covariance (STC) can be formalized in terms of the expected log-likelihood of a Linear-Nonlinear-Poisson (LNP) model with Gaussian stimuli. This model-based formulation allows us to define maximum-likelihood and Bayesian estimators that are statistically consistent and efficient in a wider variety of settings, such as with naturalistic (non-Gaussian) stimuli. It also allows us to employ Bayesian methods for regularization, smoothing, sparsification, and model comparison, and provides Bayesian confidence intervals on model parameters. We describe an empirical Bayes method for selecting the number of features, and extend the model to accommodate an arbitrary elliptical nonlinear response function, which results in a more powerful and more flexible model for feature space inference. We validate these methods using neural data recorded extracellularly from macaque primary visual cortex.\n",
      "The Noisy-Logical Distribution and its Application to Causal Inference\n",
      "We describe a novel noisy-logical distribution for representing the distribution of a binary output variable conditioned on multiple binary input variables. The distribution is represented in terms of noisy-or's and noisy-and-not's of causal features which are conjunctions of the binary inputs. The standard noisy-or and noisy-and-not models, used in causal reasoning and artificial intelligence, are special cases of the noisy-logical distribution. We prove that the noisy-logical distribution is complete in the sense that it can represent all conditional distributions provided a sufficient number of causal factors are used. We illustrate the noisy-logical distribution by showing that it can account for new experimental findings on how humans perform causal reasoning in complex contexts. We speculate on the use of the noisy-logical distribution for causal reasoning and artificial intelligence.\n",
      "Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model\n",
      "The Charles Bonnet Syndrome (CBS) is characterized by complex vivid visual hallucinations in people with, primarily, eye diseases and no other neurological pathology. We present a Deep Boltzmann Machine model of CBS, exploring two core hypotheses: First, that the visual cortex learns a generative or predictive model of sensory input, thus explaining its capability to generate internal imagery. And second, that homeostatic mechanisms stabilize neuronal activity levels, leading to hallucinations being formed when input is lacking. We reproduce a variety of qualitative findings in CBS. We also introduce a modification to the DBM that allows us to model a possible role of acetylcholine in CBS as mediating the balance of feed-forward and feed-back processing. Our model might provide new insights into CBS and also demonstrates that generative frameworks are promising as hypothetical models of cortical learning and perception.\n",
      "Sparse Space-Time Deconvolution for Calcium Image Analysis\n",
      "We describe a unified formulation and algorithm to find an extremely sparse representation for Calcium image sequences in terms of cell locations, cell shapes, spike timings and impulse responses. Solution of a single optimization problem yields cell segmentations and activity estimates that are on par with the state of the art, without the need for heuristic pre- or postprocessing. Experiments on real and synthetic data demonstrate the viability of the proposed method.\n",
      "The Early Word Catches the Weights\n",
      "The strong correlation between the frequency of words and their naming latency has been well documented. However, as early as 1973, the Age of Acquisition (AoA) of a word was alleged to be the actual variable of interest, but these studies seem to have been ignored in most of the literature. Recently, there has been a resurgence of interest in AoA. While some studies have shown that frequency has no effect when AoA is controlled for, more recent studies have found independent contributions of frequency and AoA. Connectionist models have repeatedly shown strong effects of frequency, but little attention has been paid to whether they can also show AoA effects. Indeed, several researchers have explicitly claimed that they cannot show AoA effects. In this work, we explore these claims using a simple feed forward neural network. We find a significant contribution of AoA to naming latency, as well as conditions under which frequency provides an independent contribution.\n",
      "Robust Spatial Filtering with Beta Divergence\n",
      "The efficiency of Brain-Computer Interfaces (BCI) largely depends upon a reliable extraction of informative features from the high-dimensional EEG signal. A crucial step in this protocol is the computation of spatial filters. The Common Spatial Patterns (CSP) algorithm computes filters that maximize the difference in band power between two conditions, thus it is tailored to extract the relevant information in motor imagery experiments. However, CSP is highly sensitive to artifacts in the EEG data, i.e. few outliers may alter the estimate drastically and decrease classification performance. Inspired by concepts from the field of information geometry we propose a novel approach for robustifying CSP. More precisely, we formulate CSP as a divergence maximization problem and utilize the property of a particular type of divergence, namely beta divergence, for robustifying the estimation of spatial filters in the presence of artifacts in the data. We demonstrate the usefulness of our method on toy data and on EEG recordings from 80 subjects.\n",
      "Spatio-temporal Representations of Uncertainty in Spiking Neural Networks\n",
      "It has been long argued that, because of inherent ambiguity and noise, the brain needs to represent uncertainty in the form of probability distributions. The neural encoding of such distributions remains however highly controversial. Here we present a novel circuit model for representing multidimensional real-valued distributions using a spike based spatio-temporal code. Our model combines the computational advantages of the currently competing models for probabilistic codes and exhibits realistic neural responses along a variety of classic measures. Furthermore, the model highlights the challenges associated with interpreting neural activity in relation to behavioral uncertainty and points to alternative population-level approaches for the experimental validation of distributed representations.\n",
      "Fast Active Set Methods for Online Spike Inference from Calcium Imaging\n",
      "Fluorescent calcium indicators are a popular means for observing the spiking activity of large neuronal populations. Unfortunately, extracting the spike train of each neuron from raw fluorescence calcium imaging data is a nontrivial problem. We present a fast online active set method to solve this sparse nonnegative deconvolution problem. Importantly, the algorithm progresses through each time series sequentially from beginning to end, thus enabling real-time online spike inference during the imaging session. Our algorithm is a generalization of the pool adjacent violators algorithm (PAVA) for isotonic regression and inherits its linear-time computational complexity. We gain remarkable increases in processing speed: more than one order of magnitude compared to currently employed state of the art convex solvers relying on interior point methods. Our method can exploit warm starts; therefore optimizing model hyperparameters only requires a handful of passes through the data. The algorithm enables real-time simultaneous deconvolution of $O(10^5)$ traces of whole-brain zebrafish imaging data on a laptop.\n",
      "A memory frontier for complex synapses\n",
      "An incredible gulf separates theoretical models of synapses, often described solely by a single scalar value denoting the size of a postsynaptic potential, from the immense complexity of molecular signaling pathways underlying real synapses. To understand the functional contribution of such molecular complexity to learning and memory, it is essential to expand our theoretical conception of a synapse from a single scalar to an entire dynamical system with many internal molecular functional states. Moreover, theoretical considerations alone demand such an expansion; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity. This raises the fundamental question, how does synaptic complexity give rise to memory? To address this, we develop new mathematical theorems elucidating the relationship between the structural organization and memory properties of complex synapses that are themselves molecular networks. Moreover, in proving such theorems, we uncover a framework, based on first passage time theory, to impose an order on the internal states of complex synaptic models, thereby simplifying the relationship between synaptic structure and function.\n",
      "Forgetful Bayes and myopic planning: Human learning and decision-making in a bandit setting\n",
      "How humans achieve long-term goals in an uncertain environment, via repeated trials and noisy observations, is an important problem in cognitive science. We investigate this behavior in the context of a multi-armed bandit task. We compare human behavior to a variety of models that vary in their representational and computational complexity. Our result shows that subjects' choices, on a trial-to-trial basis, are best captured by a forgetful Bayesian iterative learning model [21] in combination with a partially myopic decision policy known as Knowledge Gradient [7]. This model accounts for subjects' trial-by-trial choice better than a number of other previously proposed models, including optimal Bayesian learning and risk minimization, e-greedy and win-stay-lose-shift. It has the added benefit of being closest in performance to the optimal Bayesian model than all the other heuristic models that have the same computational complexity (all are significantly less complex than the optimal model). These results constitute an advancement in the theoretical understanding of how humans negotiate the tension between exploration and exploitation in a noisy, imperfectly known environment.\n",
      "A Theoretical Analysis of Robust Coding over Noisy Overcomplete Channels\n",
      "Biological sensory systems are faced with the problem of encoding a high-fidelity sensory signal with a population of noisy, low-fidelity neurons. This problem can be expressed in information theoretic terms as coding and transmitting a multi-dimensional, analog signal over a set of noisy channels. Previously, we have shown that robust, overcomplete codes can be learned by minimizing the reconstruction error with a constraint on the channel capacity. Here, we present a theoretical analysis that characterizes the optimal linear coder and decoder for one- and two-dimensional data. The analysis allows for an arbitrary number of coding units, thus including both under- and over-complete representations, and provides a number of important insights into optimal coding strategies. In particular, we show how the form of the code adapts to the number of coding units and to different data and noise conditions to achieve robustness. We also report numerical solutions for robust coding of high-dimensional image data and show that these codes are substantially more robust compared against other image codes such as ICA and wavelets.\n",
      "Learning invariant representations and applications to face verification\n",
      "One approach to computer object recognition and modeling the brain's ventral stream involves unsupervised learning of representations that are invariant to common transformations. However, applications of these ideas have usually been limited to 2D affine transformations, e.g., translation and scaling, since they are easiest to solve via convolution. In accord with a recent theory of transformation-invariance [1], we propose a model that, while capturing other common convolutional networks as special cases, can also be used with arbitrary identity-preserving transformations. The model's wiring can be learned from videos of transforming objects—or any other grouping of images into sets by their depicted object. Through a series of successively more complex empirical tests, we study the invariance/discriminability properties of this model with respect to different transformations. First, we empirically confirm theoretical predictions (from [1]) for the case of 2D affine transformations. Next, we apply the model to non-affine transformations; as expected, it performs well on face verification tasks requiring invariance to the relatively smooth of 3D rotation-in-depth and changes in illumination direction. Surprisingly, it can also tolerate clutter transformations which map an image of a face on one background to an image of the same face on a different background. Motivated by these empirical findings, we tested the same model on face verification benchmark tasks from the computer vision literature: Labeled Faces in the Wild, PubFig [2, 3, 4] and a new dataset we gathered—achieving strong performance in these highly unconstrained cases as well.\n",
      "Select and Sample - A Model of Efficient Neural Inference and Learning\n",
      "An increasing number of experimental studies indicate that perception encodes a posterior probability distribution over possible causes of sensory stimuli, which is used to act close to optimally in the environment. One outstanding difficulty with this hypothesis is that the exact posterior will in general be too complex to be represented directly, and thus neurons will have to represent an approximation of this distribution. Two influential proposals of efficient posterior representation by neural populations are: 1) neural activity represents samples of the underlying distribution, or 2) they represent a parametric representation of a variational approximation of the posterior. We show that these approaches can be combined for an inference scheme that retains the advantages of both: it is able to represent multiple modes and arbitrary correlations, a feature of sampling methods, and it reduces the represented space to regions of high probability mass, a strength of variational approximations. Neurally, the combined method can be interpreted as a feed-forward preselection of the relevant state space, followed by a neural dynamics implementation of Markov Chain Monte Carlo (MCMC) to approximate the posterior over the relevant states. We demonstrate the effectiveness and efficiency of this approach on a sparse coding model. In numerical experiments on artificial data and image patches, we compare the performance of the algorithms to that of exact EM, variational state space selection alone, MCMC alone, and the combined select and sample approach. The select and sample approach integrates the advantages of the sampling and variational approximations, and forms a robust, neurally plausible, and very efficient model of processing and learning in cortical networks. For sparse coding we show applications easily exceeding a thousand observed and a thousand hidden dimensions.\n",
      "Perceptual Multistability as Markov Chain Monte Carlo Inference\n",
      "While many perceptual and cognitive phenomena are well described in terms of Bayesian inference, the necessary computations are intractable at the scale of real-world tasks, and it remains unclear how the human mind approximates Bayesian computations algorithmically. We explore the proposal that for some tasks, humans use a form of Markov Chain Monte Carlo to approximate the posterior distribution over hidden variables. As a case study, we show how several phenomena of perceptual multistability can be explained as MCMC inference in simple graphical models for low-level vision.\n",
      "Noise Characterization, Modeling, and Reduction for In Vivo Neural Recording\n",
      "Studying signal and noise properties of recorded neural data is critical in developing more efficient algorithms to recover the encoded information. Important issues exist in this research including the variant spectrum spans of neural spikes that make it difficult to choose a globally optimal bandpass filter. Also, multiple sources produce aggregated noise that deviates from the conventional white Gaussian noise. In this work, the spectrum variability of spikes is addressed, based on which the concept of adaptive bandpass filter that fits the spectrum of individual spikes is proposed. Multiple noise sources have been studied through analytical models as well as empirical measurements. The dominant noise source is identified as neuron noise followed by interface noise of the electrode. This suggests that major efforts to reduce noise from electronics are not well spent. The measured noise from in vivo experiments shows a family of 1/fx spectrum that can be reduced using noise shaping techniques. In summary, the methods of adaptive bandpass filtering and noise shaping together result in several dB signal-to-noise ratio (SNR) enhancement.\n",
      "Neural characterization in partially observed populations of spiking neurons\n",
      "Point process encoding models provide powerful statistical methods for understanding the responses of neurons to sensory stimuli. Although these models have been successfully applied to neurons in the early sensory pathway, they have fared less well capturing the response properties of neurons in deeper brain areas, owing in part to the fact that they do not take into account multiple stages of processing. Here we introduce a new twist on the point-process modeling approach: we include unobserved as well as observed spiking neurons in a joint encoding model. The resulting model exhibits richer dynamics and more highly nonlinear response properties, making it more powerful and more flexible for fitting neural data. More importantly, it allows us to estimate connectivity patterns among neurons (both observed and unobserved), and may provide insight into how networks process sensory input. We formulate the estimation procedure using variational EM and the wake-sleep algorithm, and illustrate the model's performance using a simulated example network consisting of two coupled neurons.\n",
      "Ideal Observers for Detecting Motion: Correspondence Noise\n",
      "We derive a Bayesian Ideal Observer (BIO) for detecting motion and solving the correspondence problem. We obtain Barlow and Tripathy's classic model as an approximation. Our psychophysical experiments show that the trends of human performance are similar to the Bayesian Ideal, but overall human performance is far worse. We investigate ways to degrade the Bayesian Ideal but show that even extreme degradations do not approach human performance. Instead we propose that humans perform motion tasks using generic, general purpose, models of motion. We perform more psychophysical experiments which are consistent with humans using a Slow-and-Smooth model and which rule out an alternative model using Slowness.\n",
      "Statistical Models of Conditioning\n",
      "Conditioning experiments probe the ways that animals make predictions about rewards and punishments and use those predictions to control their behavior. One standard model of conditioning paradigms which involve many conditioned stimuli suggests that individual predictions should be added together. Various key results show that this model fails in some circumstances, and motivate an alternative model, in which there is attentional selection between different available stimuli. The new model is a form of mixture of experts, has a close relationship with some other existing psychological suggestions, and is statistically well-founded.\n",
      "Time-rescaling methods for the estimation and assessment of non-Poisson neural encoding models\n",
      "Recent work on the statistical modeling of neural responses has focused on modulated renewal processes in which the spike rate is a function of the stimulus and recent spiking history. Typically, these models incorporate spike-history dependencies via either: (A) a conditionally-Poisson process with rate dependent on a linear projection of the spike train history (e.g., generalized linear model); or (B) a modulated non-Poisson renewal process (e.g., inhomogeneous gamma process). Here we show that the two approaches can be combined, resulting in a conditional renewal (CR) model for neural spike trains. This model captures both real-time and rescaled-time history effects, and can be fit by maximum likelihood using a simple application of the time-rescaling theorem [1]. We show that for any modulated renewal process model, the log-likelihood is concave in the linear filter parameters only under certain restrictive conditions on the renewal density (ruling out many popular choices, e.g. gamma with shape k ≠ 1), suggesting that real-time history effects are easier to estimate than non-Poisson renewal properties. Moreover, we show that goodness-of-fit tests based on the time-rescaling theorem [1] quantify relative-time effects, but do not reliably assess accuracy in spike prediction or stimulus-response modeling. We illustrate the CR model with applications to both real and simulated neural data.\n",
      "From Algorithmic to Subjective Randomness\n",
      "We explore the phenomena of subjective randomness as a case study in understanding how people discover structure embedded in noise. We present a rational account of randomness perception based on the statistical problem of model selection: given a stimulus, inferring whether the process that generated it was random or regular. Inspired by the mathematical definition of randomness given by Kolmogorov complexity, we characterize regularity in terms of a hierarchy of automata that augment a finite controller with different forms of memory. We find that the regularities detected in binary sequences depend upon presentation format, and that the kinds of automata that can identify these regularities are informative about the cognitive processes engaged by different formats.\n",
      "High-dimensional neural spike train analysis with generalized count linear dynamical systems\n",
      "Latent factor models have been widely used to analyze simultaneous recordings of spike trains from large, heterogeneous neural populations. These models assume the signal of interest in the population is a low-dimensional latent intensity that evolves over time, which is observed in high dimension via noisy point-process observations. These techniques have been well used to capture neural correlations across a population and to provide a smooth, denoised, and concise representation of high-dimensional spiking data. One limitation of many current models is that the observation model is assumed to be Poisson, which lacks the flexibility to capture under- and over-dispersion that is common in recorded neural data, thereby introducing bias into estimates of covariance. Here we develop the generalized count linear dynamical system, which relaxes the Poisson assumption by using a more general exponential family for count data. In addition to containing Poisson, Bernoulli, negative binomial, and other common count distributions as special cases, we show that this model can be tractably learned by extending recent advances in variational inference techniques. We apply our model to data from primate motor cortex and demonstrate performance improvements over state-of-the-art methods, both in capturing the variance structure of the data and in held-out prediction.\n",
      "Can the Brain Do Backpropagation? -Exact Implementation of Backpropagation in Predictive Coding Networks.\n",
      "Backpropagation (BP) has been the most successful algorithm used to train artificial neural networks. However, there are several gaps between BP and learning in biologically plausible neuronal networks of the brain (learning in the brain, or simply BL, for short), in particular, (1) it has been unclear to date, if BP can be implemented exactly via BL, (2) there is a lack of local plasticity in BP, i.e., weight updates require information that is not locally available, while BL utilizes only locally available information, and (3) there is a lack of autonomy in BP, i.e., some external control over the neural network is required (e.g., switching between prediction and learning stages requires changes to dynamics and synaptic plasticity rules), while BL works fully autonomously. Bridging such gaps, i.e., understanding how BP can be approximated by BL, has been of major interest in both neuroscience and machine learning. Despite tremendous efforts, however, no previous model has bridged the gaps at a degree of demonstrating an equivalence to BP, instead, only approximations to BP have been shown. Here, we present for the first time a framework within BL that bridges the above crucial gaps. We propose a BL model that (1) produces exactly the same updates of the neural weights as BP, while (2) employing local plasticity, i.e., all neurons perform only local computations, done simultaneously. We then modify it to an alternative BL model that (3) also works fully autonomously. Overall, our work provides important evidence for the debate on the long-disputed question whether the brain can perform BP.\n",
      "Abstraction and Relational learning\n",
      "Most models of categorization learn categories defined by characteristic features but some categories are described more naturally in terms of relations. We present a generative model that helps to explain how relational categories are learned and used. Our model learns abstract schemata that specify the relational similarities shared by instances of a category, and our emphasis on abstraction departs from previous theoretical proposals that focus instead on comparison of concrete instances. Our first experiment suggests that abstraction can help to explain some of the findings that have previously been used to support comparison-based approaches. Our second experiment focuses on one-shot schema learning, a problem that raises challenges for comparison-based approaches but is handled naturally by our abstraction-based account.\n",
      "Constraining a Bayesian Model of Human Visual Speed Perception\n",
      "It has been demonstrated that basic aspects of human visual motion perception are qualitatively consistent with a Bayesian estimation framework, where the prior probability distribution on velocity favors slow speeds. Here, we present a refined probabilistic model that can account for the typical trial-to-trial variabilities observed in psychophysical speed perception experiments. We also show that data from such experiments can be used to constrain both the likelihood and prior functions of the model. Specifically, we measured matching speeds and thresholds in a two-alternative forced choice speed discrimination task. Parametric fits to the data reveal that the likelihood function is well approximated by a LogNormal distribution with a characteristic contrast-dependent variance, and that the prior distribution on velocity exhibits significantly heavier tails than a Gaussian, and approximately follows a power-law function.\n",
      "Congruence between model and human attention reveals unique signatures of critical visual events\n",
      "Current computational models of bottom-up and top-down components of attention are predictive of eye movements across a range of stimuli and of simple, fixed visual tasks (such as visual search for a target among distractors). However, to date there exists no computational framework which can reliably mimic human gaze behavior in more complex environments and tasks, such as driving a vehicle through traffic. Here, we develop a hybrid computational/behavioral framework, combining simple models for bottom-up salience and top-down relevance, and looking for changes in the predictive power of these components at different critical event times during 4.7 hours (500,000 video frames) of observers playing car racing and flight combat video games. This approach is motivated by our observation that the predictive strengths of the salience and relevance models exhibit reliable temporal signatures during critical event windows in the task sequence—for example, when the game player directly engages an enemy plane in a flight combat game, the predictive strength of the salience model increases significantly, while that of the relevance model decreases significantly. Our new framework combines these temporal signatures to implement several event detectors. Critically, we find that an event detector based on fused behavioral and stimulus information (in the form of the model's predictive strength) is much stronger than detectors based on behavioral information alone (eye position) or image information alone (model prediction maps). This approach to event detection, based on eye tracking combined with computational models applied to the visual input, may have useful applications as a less-invasive alternative to other event detection approaches based on neural signatures derived from EEG or fMRI recordings.\n",
      "Estimating image bases for visual image reconstruction from human brain activity\n",
      "Image representation based on image bases provides a framework for understanding neural representation of visual perception. A recent fMRI study has shown that arbitrary contrast-defined visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases. In the reconstruction model, the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images. But the shapes of the images bases were fixed, and thus may not be optimal for reconstruction. Here, we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data. We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables. The mapping from the latent variables to the visual image space can be regarded as a set of image bases. We found that spatially localized, multi-scale image bases were estimated near the fovea, and that the model using the estimated image bases was able to accurately reconstruct novel visual images. The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns.\n",
      "A Bayesian Analysis of Dynamics in Free Recall\n",
      "We develop a probabilistic model of human memory performance in free recall experiments. In these experiments, a subject first studies a list of words and then tries to recall them. To model these data, we draw on both previous psychological research and statistical topic models of text documents. We assume that memories are formed by assimilating the semantic meaning of studied words (represented as a distribution over topics) into a slowly changing latent context (represented in the same space). During recall, this context is reinstated and used as a cue for retrieving studied words. By conceptualizing memory retrieval as a dynamic latent variable model, we are able to use Bayesian inference to represent uncertainty and reason about the cognitive processes underlying memory. We present a particle filter algorithm for performing approximate posterior inference, and evaluate our model on the prediction of recalled words in experimental data. By specifying the model hierarchically, we are also able to capture inter-subject variability.\n",
      "A Hippocampal Model of Recognition Memory\n",
      "A rich body of data exists showing that recollection of specific information makes an important contribution to recognition memory, which is distinct from the contribution of familiarity, and is not adequately captured by existing unitary memory models. Furthermore, neuropsychological evidence indicates that recollection is subserved by the hippocampus. We present a model, based largely on known features of hippocampal anatomy and physiology, that accounts for the following key characteristics of recollection: 1) false recollection is rare (i.e., participants rarely claim to recollect having studied nonstudied items), and 2) increasing interference leads to less recollection but apparently does not compromise the quality of recollection (i.e., the extent to which recollected information veridically reflects events that occurred at study).\n",
      "Phase Synchrony Rate for the Recognition of Motor Imagery in Brain-Computer Interface\n",
      "Motor imagery attenuates EEG µ and β rhythms over sensorimotor cortices. These amplitude changes are most successfully captured by the method of Common Spatial Patterns (CSP) and widely used in brain-computer interfaces (BCI). BCI methods based on amplitude information, however, have not incoporated the rich phase dynamics in the EEG rhythm. This study reports on a BCI method based on phase synchrony rate (SR). SR, computed from binarized phase locking value, describes the number of discrete synchronization events within a window. Statistical nonparametric tests show that SRs contain significant differences between 2 types of motor imageries. Classifiers trained on SRs consistently demonstrate satisfactory results for all 5 subjects. It is further observed that, for 3 subjects, phase is more discriminative than amplitude in the first 1.5-2.0 s, which suggests that phase has the potential to boost the information transfer rate in BCIs.\n",
      "Monaural Speech Separation\n",
      "Monaural speech separation has been studied in previous systems that incorporate auditory scene analysis principles. A major problem for these systems is their inability to deal with speech in the high-frequency range. Psychoacoustic evidence suggests that different perceptual mechanisms are involved in handling resolved and unresolved harmonics. Motivated by this, we propose a model for monaural separation that deals with low-frequency and high-frequency signals differently. For resolved harmonics, our model generates segments based on temporal continuity and cross-channel correlation, and groups them according to periodicity. For unresolved harmonics, the model generates segments based on amplitude modulation (AM) in addition to temporal continuity and groups them according to AM repetition rates derived from sinusoidal modeling. Underlying the separation process is a pitch contour obtained according to psychoacoustic constraints. Our model is systematically evaluated, and it yields substantially better performance than previous systems, especially in the high-frequency range.\n",
      "Contextual Modulation of Target Saliency\n",
      "The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. In this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes.\n",
      "Probabilistic Computation in Spiking Populations\n",
      "As animals interact with their environments, they must constantly update estimates about their states. Bayesian models combine prior probabilities, a dynamical model and sensory evidence to update estimates optimally. These models are consistent with the results of many diverse psychophysical studies. However, little is known about the neural representation and manipulation of such Bayesian information, particularly in populations of spiking neurons. We consider this issue, suggesting a model based on standard neural architecture and activations. We illustrate the approach on a simple random walk example, and apply it to a sensorimotor integration task that provides a particularly compelling example of dynamic probabilistic computation.\n",
      "Natural Sound Statistics and Divisive Normalization in the Auditory System\n",
      "We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities.\n",
      "Just One View: Invariances in Inferotemporal Cell Tuning\n",
      "In macaque inferotemporal cortex (IT), neurons have been found to respond selectively to complex shapes while showing broad tuning (invariance) with respect to stimulus transformations such as translation and scale changes and a limited tuning to rotation in depth. Training monkeys with novel, paperclip-like objects, Logothetis et al. could investigate whether these invariance properties are due to experience with exhaustively many transformed instances of an object or if there are mechanisms that allow the cells to show response invariance also to previously unseen instances of that object. They found object-selective cells in anterior IT which exhibited limited invariance to various transformations after training with single object views. While previous models accounted for the tuning of the cells for rotations in depth and for their selectivity to a specific object relative to a population of distractor objects, the model described here attempts to explain in a biologically plausible way the additional properties of translation and size invariance. Using the same stimuli as in the experiment, we find that model IT neurons exhibit invariance properties which closely parallel those of real neurons. Simulations show that the model is capable of unsupervised learning of view-tuned neurons.\n",
      "Unifying the Sensory and Motor Components of Sensorimotor Adaptation\n",
      "Adaptation of visually guided reaching movements in novel visuomotor environments (e.g. wearing prism goggles) comprises not only motor adaptation but also substantial sensory adaptation, corresponding to shifts in the perceived spatial location of visual and proprioceptive cues. Previous computational models of the sensory component of visuomotor adaptation have assumed that it is driven purely by the discrepancy introduced between visual and proprioceptive estimates of hand position and is independent of any motor component of adaptation. We instead propose a unified model in which sensory and motor adaptation are jointly driven by optimal Bayesian estimation of the sensory and motor contributions to perceived errors. Our model is able to account for patterns of performance errors during visuomotor adaptation as well as the subsequent perceptual aftereffects. This unified model also makes the surprising prediction that force field adaptation will elicit similar perceptual shifts, even though there is never any discrepancy between visual and proprioceptive observations. We confirm this prediction with an experiment.\n",
      "Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models\n",
      "Recent experiments have demonstrated that humans and animals typically reason probabilistically about their environment. This ability requires a neural code that represents probability distributions and neural circuits that are capable of implementing the operations of probabilistic inference. The proposed probabilistic population coding (PPC) framework provides a statistically efficient neural representation of probability distributions that is both broadly consistent with physiological measurements and capable of implementing some of the basic operations of probabilistic inference in a biologically plausible way. However, these experiments and the corresponding neural models have largely focused on simple (tractable) probabilistic computations such as cue combination, coordinate transformations, and decision making. As a result it remains unclear how to generalize this framework to more complex probabilistic computations. Here we address this short coming by showing that a very general approximate inference algorithm known as Variational Bayesian Expectation Maximization can be naturally implemented within the linear PPC framework. We apply this approach to a generic problem faced by any given layer of cortex, namely the identification of latent causes of complex mixtures of spikes. We identify a formal equivalent between this spike pattern demixing problem and topic models used for document classification, in particular Latent Dirichlet Allocation (LDA). We then construct a neural network implementation of variational inference and learning for LDA that utilizes a linear PPC. This network relies critically on two non-linear operations: divisive normalization and super-linear facilitation, both of which are ubiquitously observed in neural circuits. We also demonstrate how online learning can be achieved using a variation of Hebb's rule and describe an extension of this work which allows us to deal with time varying and correlated latent causes.\n",
      "Top-Down Control of Visual Attention: A Rational Account\n",
      "Theories of visual attention commonly posit that early parallel processes extract conspicuous features such as color contrast and motion from the visual field. These features are then combined into a saliency map, and attention is directed to the most salient regions first. Top-down attentional control is achieved by modulating the contribution of different feature types to the saliency map. A key source of data concerning attentional control comes from behavioral studies in which the effect of recent experience is examined as individuals repeatedly perform a perceptual discrimination task (e.g., what shape is the odd-colored object?). The robust finding is that repetition of features of recent trials (e.g., target color) facilitates performance. We view this facilitation as an adaptation to the statistical structure of the environment. We propose a probabilistic model of the environment that is updated after each trial. Under the assumption that attentional control operates so as to make performance more efficient for more likely environmental states, we obtain parsimonious explanations for data from four different experiments. Further, our model provides a rational explanation for why the influence of past experience on attentional control is short lived.\n",
      "Bayesian Modelling of fMRI lime Series\n",
      "We present a Hidden Markov Model (HMM) for inferring the hidden psychological state (or neural activity) during single trial fMRI activation experiments with blocked task paradigms. Inference is based on Bayesian methodology, using a combination of analytical and a variety of Markov Chain Monte Carlo (MCMC) sampling techniques. The advantage of this method is that detection of short time learning effects between repeated trials is possible since inference is based only on single trial experiments.\n",
      "Spike Feature Extraction Using Informative Samples\n",
      "This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer.\n",
      "Variational Laws of Visual Attention for Dynamic Scenes\n",
      "Computational models of visual attention are at the crossroad of disciplines like cognitive science, computational neuroscience, and computer vision. This paper proposes a model of attentional scanpath that is based on the principle that there are foundational laws that drive the emergence of visual attention. We devise variational laws of the eye-movement that rely on a generalized view of the Least Action Principle in physics. The potential energy captures details as well as peripheral visual features, while the kinetic energy corresponds with the classic interpretation in analytic mechanics. In addition, the Lagrangian contains a brightness invariance term, which characterizes significantly the scanpath trajectories. We obtain differential equations of visual attention as the stationary point of the generalized action, and we propose an algorithm to estimate the model parameters. Finally, we report experimental results to validate the model in tasks of saliency detection.\n",
      "Principal differences analysis: interpretable characterization of differences between distributions\n",
      "We introduce principal differences analysis (PDA) for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. Relying on the Cramer-Wold device, it requires no assumptions about the form of the underlying distributions, nor the nature of their inter-class differences. A sparse variant of the method is introduced to identify features responsible for the differences. We provide algorithms for both the original minimax formulation as well as its semidefinite relaxation. In addition to deriving some convergence results, we illustrate how the approach may be applied to identify differences between cell populations in the somatosensory cortex and hippocampus as manifested by single cell RNA-seq. Our broader framework extends beyond the specific choice of Wasserstein divergence.\n",
      "Orientation-Selective aVLSI Spiking Neurons\n",
      "We describe a programmable multi-chip VLSI neuronal system that can be used for exploring spike-based information processing models. The system consists of a silicon retina, a PIC microcontroller, and a transceiver chip whose integrate-and-fire neurons are connected in a soft winner-take-all architecture. The circuit on this multi-neuron chip approximates a cortical microcircuit. The neurons can be configured for different computational properties by the virtual connections of a selected set of pixels on the silicon retina. The virtual wiring between the different chips is effected by an event-driven communication protocol that uses asynchronous digital pulses, similar to spikes in a neuronal system. We used the multi-chip spike-based system to synthesize orientation-tuned neurons using both a feedforward model and a feedback model. The performance of our analog hardware spiking model matched the experimental observations and digital simulations of continuous-valued neurons. The multi-chip VLSI system has advantages over computer neuronal models in that it is real-time, and the computational time does not scale with the size of the neuronal network.\n",
      "Unsupervised learning models of primary cortical receptive fields and receptive field plasticity\n",
      "The efficient coding hypothesis holds that neural receptive fields are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism's lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive field properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive field properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive field plasticity during an organism's lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, first proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices.\n",
      "Neurons as Monte Carlo Samplers: Bayesian ï¿¼Inference and Learning in Spiking Networks\n",
      "We propose a spiking network model capable of performing both approximate inference and learning for any hidden Markov model. The lower layer sensory neurons detect noisy measurements of hidden world states. The higher layer neurons with recurrent connections infer a posterior distribution over world states from spike trains generated by sensory neurons. We show how such a neuronal network with synaptic plasticity can implement a form of Bayesian inference similar to Monte Carlo methods such as particle filtering. Each spike in the population of inference neurons represents a sample of a particular hidden world state. The spiking activity across the neural population approximates the posterior distribution of hidden state. The model provides a functional explanation for the Poisson-like noise commonly observed in cortical responses. Uncertainties in spike times provide the necessary variability for sampling during inference. Unlike previous models, the hidden world state is not observed by the sensory neurons, and the temporal dynamics of the hidden state is unknown. We demonstrate how such networks can sequentially learn hidden Markov models using a spike-timing dependent Hebbian learning rule and achieve power-law convergence rates.\n",
      "On the Computational Utility of Consciousness\n",
      "We propose a computational framework for understanding and modeling human consciousness. This framework integrates many existing theoretical perspectives, yet is sufficiently concrete to allow simulation experiments. We do not attempt to explain qualia (subjective experience), but instead ask what differences exist within the cognitive information processing system when a person is conscious of mentally-represented information versus when that information is unconscious. The central idea we explore is that the contents of consciousness correspond to temporally persistent states in a network of computational modules. Three simulations are described illustrating that the behavior of persistent states in the models corresponds roughly to the behavior of conscious states people experience when performing similar tasks. Our simulations show that periodic settling to persistent (i.e., conscious) states improves performance by cleaning up inaccuracies and noise, forcing decisions, and helping keep the system on track toward a solution.\n",
      "Reconstruction of Sparse Circuits Using Multi-neuronal Excitation (RESCUME)\n",
      "One of the central problems in neuroscience is reconstructing synaptic connectivity in neural circuits. Synapses onto a neuron can be probed by sequentially stimulating potentially pre-synaptic neurons while monitoring the membrane voltage of the post-synaptic neuron. Reconstructing a large neural circuit using such a approach is rather time-consuming and inefficient because the connectivity in neural circuits is sparse. Instead, we propose to measure a post-synaptic neuron's voltage while stimulating sequentially random subsets of multiple potentially pre-synaptic neurons. To reconstruct these synaptic connections from the recorded voltage we apply a decoding algorithm recently developed for compressive sensing. Compared to the brute force approach, our method promises significant time savings that grow with the size of the circuit. We use computer simulations to find optimal stimulation parameters and explore the feasibility of our reconstruction method under realistic experimental conditions including noise and non-linear synaptic integration. Multi-neuronal stimulation allows reconstructing synaptic connectivity just from the spiking activity of post-synaptic neurons, even when sub-threshold voltage is unavailable. By using calcium indicators, voltage-sensitive dyes, or multi-electrode arrays one could monitor activity of multiple post-synaptic neurons simultaneously, thus mapping their synaptic inputs in parallel, potentially reconstructing a complete neural circuit.\n",
      "Learning Multi-level Sparse Representations\n",
      "Bilinear approximation of a matrix is a powerful paradigm of unsupervised learning. In some applications, however, there is a natural hierarchy of concepts that ought to be reflected in the unsupervised analysis. For example, in the neuro-sciences image sequence considered here, there are the semantic concepts of pixel → neuron → assembly that should find their counterpart in the unsupervised analysis. Driven by this concrete problem, we propose a decomposition of the matrix of observations into a product of more than two sparse matrices, with the rank decreasing from lower to higher levels. In contrast to prior work, we allow for both hierarchical and heterarchical relations of lower-level to higher-level concepts. In addition, we learn the nature of these relations rather than imposing them. Finally, we describe an optimization scheme that allows to optimize the decomposition over all levels jointly, rather than in a greedy level-by-level fashion.\n",
      "\n",
      "The proposed bilevel SHMF (sparse heterarchical matrix factorization) is the first formalism that allows to simultaneously interpret a calcium imaging sequence in terms of the constituent neurons, their membership in assemblies, and the time courses of both neurons and assemblies. Experiments show that the proposed model fully recovers the structure from difficult synthetic data designed to imitate the experimental data. More importantly, bilevel SHMF yields plausible interpretations of real-world Calcium imaging data.\n",
      "A blind sparse deconvolution method for neural spike identification\n",
      "We consider the problem of estimating neural spikes from extracellular voltage recordings. Most current methods are based on clustering, which requires substantial human supervision and produces systematic errors by failing to properly handle temporally overlapping spikes. We formulate the problem as one of statistical inference, in which the recorded voltage is a noisy sum of the spike trains of each neuron convolved with its associated spike waveform. Joint maximum-a-posteriori (MAP) estimation of the waveforms and spikes is then a blind deconvolution problem in which the coefficients are sparse. We develop a block-coordinate descent method for approximating the MAP solution. We validate our method on data simulated according to the generative model, as well as on real data for which ground truth is available via simultaneous intracellular recordings. In both cases, our method substantially reduces the number of missed spikes and false positives when compared to a standard clustering algorithm, primarily by recovering temporally overlapping spikes. The method offers a fully automated alternative to clustering methods that is less susceptible to systematic errors.\n",
      "A framework for studying synaptic plasticity with neural spike train data\n",
      "Learning and memory in the brain are implemented by complex, time-varying changes in neural circuitry. The computational rules according to which synaptic weights change over time are the subject of much research, and are not precisely understood. Until recently, limitations in experimental methods have made it challenging to test hypotheses about synaptic plasticity on a large scale. However, as such data become available and these barriers are lifted, it becomes necessary to develop analysis techniques to validate plasticity models. Here, we present a highly extensible framework for modeling arbitrary synaptic plasticity rules on spike train data in populations of interconnected neurons. We treat synaptic weights as a (potentially nonlinear) dynamical system embedded in a fully-Bayesian generalized linear model (GLM). In addition, we provide an algorithm for inferring synaptic weight trajectories alongside the parameters of the GLM and of the learning rules. Using this method, we perform model comparison of two proposed variants of the well-known spike-timing-dependent plasticity (STDP) rule, where nonlinear effects play a substantial role. On synthetic data generated from the biophysical simulator NEURON, we show that we can recover the weight trajectories, the pattern of connectivity, and the underlying learning rules.\n",
      "Scalable Inference for Neuronal Connectivity from Calcium Imaging\n",
      "Fluorescent calcium imaging provides a potentially powerful tool for inferring connectivity in neural circuits with up to thousands of neurons. However, a key challenge in using calcium imaging for connectivity detection is that current systems often have a temporal response and frame rate that can be orders of magnitude slower than the underlying neural spiking process. Bayesian inference methods based on expectation-maximization (EM) have been proposed to overcome these limitations, but are often computationally demanding since the E-step in the EM procedure typically involves state estimation for a high-dimensional nonlinear dynamical system. In this work, we propose a computationally fast method for the state estimation based on a hybrid of loopy belief propagation and approximate message passing (AMP). The key insight is that a neural system as viewed through calcium imaging can be factorized into simple scalar dynamical systems for each neuron with linear interconnections between the neurons. Using the structure, the updates in the proposed hybrid AMP methodology can be computed by a set of one-dimensional state estimation procedures and linear transforms with the connectivity matrix. This yields a computationally scalable method for inferring connectivity of large neural circuits. Simulations of the method on realistic neural networks demonstrate good accuracy with computation times that are potentially significantly faster than current approaches based on Markov Chain Monte Carlo methods.\n",
      "Comparing Bayesian models for multisensory cue combination without mandatory integration\n",
      "Bayesian models of multisensory perception traditionally address the problem of estimating an underlying variable that is assumed to be the cause of the two sensory signals. The brain, however, has to solve a more general problem: it also has to establish which signals come from the same source and should be integrated, and which ones do not and should be segregated. In the last couple of years, a few models have been proposed to solve this problem in a Bayesian fashion. One of these has the strength that it formalizes the causal structure of sensory signals. We first compare these models on a formal level. Furthermore, we conduct a psychophysics experiment to test human performance in an auditory-visual spatial localization task in which integration is not mandatory. We find that the causal Bayesian inference model accounts for the data better than other models.\n",
      "Using hippocampal 'place cells' for navigation, exploiting phase coding\n",
      "A model of the hippocampus as a central element in rat navigation is presented. Simulations show both the behaviour of single cells and the resultant navigation of the rat. These are compared with single unit recordings and behavioural data. The firing of CA1 place cells is simulated as the (artificial) rat moves in an environment. This is the input for a neuronal network whose output, at each theta (θ) cycle, is the next direction of travel for the rat. Cells are characterised by the number of spikes fired and the time of firing with respect to hippocampal θ rhythm. 'Learning' occurs in 'on-off' synapses that are switched on by simultaneous pre- and post-synaptic activity. The simulated rat navigates successfully to goals encountered one or more times during exploration in open fields. One minute of random exploration of a 1m2 environment allows navigation to a newly-presented goal from novel starting positions. A limited number of obstacles can be successfully avoided.\n",
      "Demixed Principal Component Analysis\n",
      "In many experiments, the data points collected live in high-dimensional observation spaces, yet can be assigned a set of labels or parameters. In electrophysiological recordings, for instance, the responses of populations of neurons generally depend on mixtures of experimentally controlled parameters. The heterogeneity and diversity of these parameter dependencies can make visualization and interpretation of such data extremely difficult. Standard dimensionality reduction techniques such as principal component analysis (PCA) can provide a succinct and complete description of the data, but the description is constructed independent of the relevant task variables and is often hard to interpret. Here, we start with the assumption that a particularly informative description is one that reveals the dependency of the high-dimensional data on the individual parameters. We show how to modify the loss function of PCA so that the principal components seek to capture both the maximum amount of variance about the data, while also depending on a minimum number of parameters. We call this method demixed principal component analysis (dPCA) as the principal components here segregate the parameter dependencies. We phrase the problem as a probabilistic graphical model, and present a fast Expectation-Maximization (EM) algorithm. We demonstrate the use of this algorithm for electrophysiological data and show that it serves to demix the parameter-dependence of a neural population response.\n",
      "Efficient coding provides a direct link between prior and likelihood in perceptual Bayesian inference\n",
      "A common challenge for Bayesian models of perception is the fact that the two fundamental Bayesian components, the prior distribution and the likelihood function, are formally unconstrained. Here we argue that a neural system that emulates Bayesian inference is naturally constrained by the way it represents sensory information in populations of neurons. More specifically, we show that an efficient coding principle creates a direct link between prior and likelihood based on the underlying stimulus distribution. The resulting Bayesian estimates can show biases away from the peaks of the prior distribution, a behavior seemingly at odds with the traditional view of Bayesian estimation, yet one that has been reported in human perception. We demonstrate that our framework correctly accounts for the repulsive biases previously reported for the perception of visual orientation, and show that the predicted tuning characteristics of the model neurons match the reported orientation tuning properties of neurons in primary visual cortex. Our results suggest that efficient coding is a promising hypothesis in constraining Bayesian models of perceptual inference.\n",
      "Optimizing Instructional Policies\n",
      "Psychologists are interested in developing instructional policies that boost student learning. An instructional policy specifies the manner and content of instruction. For example, in the domain of concept learning, a policy might specify the nature of exemplars chosen over a training sequence. Traditional psychological studies compare several hand-selected policies, e.g., contrasting a policy that selects only difficult-to-classify exemplars with a policy that gradually progresses over the training sequence from easy exemplars to more difficult (known as fading). We propose an alternative to the traditional methodology in which we define a parameterized space of policies and search this space to identify the optimal policy. For example, in concept learning, policies might be described by a fading function that specifies exemplar difficulty over time. We propose an experimental technique for searching policy spaces using Gaussian process surrogate-based optimization and a generative model of student performance. Instead of evaluating a few experimental conditions each with many human subjects, as the traditional methodology does, our technique evaluates many experimental conditions each with a few subjects. Even though individual subjects provide only a noisy estimate of the population mean, the optimization method allows us to determine the shape of the policy space and to identify the global optimum, and is as efficient in its subject budget as a traditional A-B comparison. We evaluate the method via two behavioral studies, and suggest that the method has broad applicability to optimization problems involving humans outside the educational arena.\n",
      "Evidence for a Forward Dynamics Model in Human Adaptive Motor Control\n",
      "Based on computational principles, the concept of an internal model for adaptive control has been divided into a forward and an inverse model. However, there is as yet little evidence that learning control by the CNS is through adaptation of one or the other. Here we examine two adaptive control architectures, one based only on the inverse model and other based on a combination of forward and inverse models. We then show that for reaching movements of the hand in novel force fields, only the learning of the forward model results in key characteristics of performance that match the kinematics of human subjects. In contrast, the adaptive control system that relies only on the inverse model fails to produce the kinematic patterns observed in the subjects, despite the fact that it is more stable. Our results provide evidence that learning control of novel dynamics is via formation of a forward model.\n",
      "Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis\n",
      "Multitask learning can be effective when features useful in one task are also useful for other tasks, and the group lasso is a standard method for selecting a common subset of features. In this paper, we are interested in a less restrictive form of multitask learning, wherein (1) the available features can be organized into subsets according to a notion of similarity and (2) features useful in one task are similar, but not necessarily identical, to the features best suited for other tasks. The main contribution of this paper is a new procedure called Sparse Overlapping Sets (SOS) lasso, a convex optimization that automatically selects similar features for related learning tasks. Error bounds are derived for SOSlasso and its consistency is established for squared error loss. In particular, SOSlasso is motivated by multi-subject fMRI studies in which functional activity is classified using brain voxels as features. Experiments with real and synthetic data demonstrate the advantages of SOSlasso compared to the lasso and group lasso.\n",
      "Temporal Coherence, Natural Image Sequences, and the Visual Cortex\n",
      "We show that two important properties of the primary visual cortex emerge when the principle of temporal coherence is applied to natural image sequences. The properties are simple-cell-like receptive fields and complex-cell-like pooling of simple cell outputs, which emerge when we apply two different approaches to temporal coherence. In the first approach we extract receptive fields whose outputs are as temporally coherent as possible. This approach yields simple-cell-like receptive fields (oriented, localized, multiscale). Thus, temporal coherence is an alternative to sparse coding in modeling the emergence of simple cell receptive fields. The second approach is based on a two-layer statistical generative model of natural image sequences. In addition to modeling the temporal coherence of individual simple cells, this model includes inter-cell temporal dependencies. Estimation of this model from natural data yields both simple-cell-like receptive fields, and complex-cell-like pooling of simple cell outputs. In this completely unsupervised learning, both layers of the generative model are estimated simultaneously from scratch. This is a significant improvement on earlier statistical models of early vision, where only one layer has been learned, and others have been fixed a priori.\n",
      "Eye Micro-movements Improve Stimulus Detection Beyond the Nyquist Limit in the Peripheral Retina\n",
      "Even under perfect fixation the human eye is under steady motion (tremor, microsaccades, slow drift). The dynamic theory of vision [1, 2] states that eye-movements can improve hyperacuity. According to this theory, eye movements are thought to create variable spatial excitation patterns on the photoreceptor grid, which will allow for better spatiotemporal summation at later stages. We reexamine this theory using a realistic model of the vertebrate retina by comparing responses of a resting and a moving eye. The performance of simulated ganglion cells in a hyperacuity task is evaluated by ideal observer analysis. We find that in the central retina eye-micromovements have no effect on the performance. Here optical blurring limits vernier acuity. In the retinal periphery however, eye-micromovements clearly improve performance. Based on ROC analysis, our predictions are quantitatively testable in electro-physiological and psychophysical experiments.\n",
      "No evidence for active sparsification in the visual cortex\n",
      "The proposal that cortical activity in the visual cortex is optimized for sparse neural activity is one of the most established ideas in computational neuroscience. However, direct experimental evidence for optimal sparse coding remains inconclusive, mostly due to the lack of reference values on which to judge the measured sparseness. Here we analyze neural responses to natural movies in the primary visual cortex of ferrets at different stages of development and of rats while awake and under different levels of anesthesia. In contrast with prediction from a sparse coding model, our data shows that population and lifetime sparseness decrease with visual experience, and increase from the awake to anesthetized state. These results suggest that the representation in the primary visual cortex is not actively optimized to maximize sparseness.\n",
      "Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing\n",
      "EEG connectivity measures could provide a new type of feature space for inferring a subject's intention in Brain-Computer Interfaces (BCIs). However, very little is known on EEG connectivity patterns for BCIs. In this study, EEG connectivity during motor imagery (MI) of the left and right is investigated in a broad frequency range across the whole scalp by combining Beamforming with Transfer Entropy and taking into account possible volume conduction effects. Observed connectivity patterns indicate that modulation intentionally induced by MI is strongest in the γ-band, i.e., above 35 Hz. Furthermore, modulation between MI and rest is found to be more pronounced than between MI of different hands. This is in contrast to results on MI obtained with bandpower features, and might provide an explanation for the so far only moderate success of connectivity features in BCIs. It is concluded that future studies on connectivity based BCIs should focus on high frequency bands and consider experimental paradigms that maximally vary cognitive demands between conditions.\n",
      "Infinite Relational Modeling of Functional Connectivity in Resting State fMRI\n",
      "Functional magnetic resonance imaging (fMRI) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level. Most analyses of functional resting state networks (RSN) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain. While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact. In this paper we take a different view on the analysis of functional resting state networks. Starting from the definition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information. We use the infinite relational model (IRM) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects.\n",
      "Multilinear Subspace Regression: An Orthogonal Tensor Decomposition Approach\n",
      "A multilinear subspace regression model based on so called latent variable decomposition is introduced. Unlike standard regression methods which typically employ matrix (2D) data representations followed by vector subspace transformations, the proposed approach uses tensor subspace transformations to model common latent variables across both the independent and dependent data. The proposed approach aims to maximize the correlation between the so derived latent variables and is shown to be suitable for the prediction of multidimensional dependent data from multidimensional independent data, where for the estimation of the latent variables we introduce an algorithm based on Multilinear Singular Value Decomposition (MSVD) on a specially defined cross-covariance tensor. It is next shown that in this way we are also able to unify the existing Partial Least Squares (PLS) and N-way PLS regression algorithms within the same framework. Simulations on benchmark synthetic data confirm the advantages of the proposed approach, in terms of its predictive ability and robustness, especially for small sample sizes. The potential of the proposed technique is further illustrated on a real world task of the decoding of human intracranial electrocorticogram (ECoG) from a simultaneously recorded scalp electroencephalograph (EEG).\n",
      "Is Early Vision Optimized for Extracting Higher-order Dependencies?\n",
      "Linear implementations of the efficient coding hypothesis, such as independent component analysis (ICA) and sparse coding models, have provided functional explanations for properties of simple cells in V1 [1,2]. These models, however, ignore the non-linear behavior of neurons and fail to match individual and population properties of neural receptive fields in subtle but important ways. Hierarchical models, including Gaussian Scale Mixtures [3, 4] and other generative statistical models [5, 6], can capture higher-order regularities in natural images and explain nonlinear aspects of neural processing such as normalization and context effects [6,7]. Previously, it had been assumed that the lower level representation is independent of the hierarchy, and had been fixed when training these models. Here we examine the optimal lower-level representations derived in the context of a hierarchical model and find that the resulting representations are strikingly different from those based on linear models. Unlike the the basis functions and filters learned by ICA or sparse coding, these functions individually more closely resemble simple cell receptive fields and collectively span a broad range of spatial scales. Our work unifies several related approaches and observations about natural image structure and suggests that hierarchical models might yield better representations of image structure throughout the hierarchy.\n",
      "Probing the Compositionality of Intuitive Functions\n",
      "How do people learn about complex functional structure? Taking inspiration from other areas of cognitive science, we propose that this is accomplished by harnessing compositionality: complex structure is decomposed into simpler building blocks. We formalize this idea within the framework of Bayesian regression using a grammar over Gaussian process kernels. We show that participants prefer compositional over non-compositional function extrapolations, that samples from the human prior over functions are best described by a compositional model, and that people perceive compositional functions as more predictable than their non-compositional but otherwise similar counterparts. We argue that the compositional nature of intuitive functions is consistent with broad principles of human cognition.\n",
      "The human kernel\n",
      "Bayesian nonparametric models, such as Gaussian processes, provide a compelling framework for automatic statistical modelling: these models have a high degree of flexibility, and automatically calibrated complexity. However, automating human expertise remains elusive; for example, Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners. In this paper, we create function extrapolation problems and acquire human responses, and then design a kernel learning framework to reverse engineer the inductive biases of human learners across a set of behavioral experiments. We use the learned kernels to gain psychological insights and to extrapolate in humanlike ways that go beyond traditional stationary and polynomial kernels. Finally, we investigate Occam's razor in human and Gaussian process based function learning.\n",
      "Practical Bayesian optimization for model fitting with Bayesian adaptive direct search\n",
      "Computational models in fields such as computational neuroscience are often evaluated via stochastic simulation or numerical approximation. Fitting these models implies a difficult optimization problem over complex, possibly noisy parameter landscapes. Bayesian optimization (BO) has been successfully applied to solving expensive black-box problems in engineering and machine learning. Here we explore whether BO can be applied as a general tool for model fitting. First, we present a novel hybrid BO algorithm, Bayesian adaptive direct search (BADS), that achieves competitive performance with an affordable computational overhead for the running time of typical models. We then perform an extensive benchmark of BADS vs. many common and state-of-the-art nonconvex, derivative-free optimizers, on a set of model-fitting problems with real data and models from six studies in behavioral, cognitive, and computational neuroscience. With default settings, BADS consistently finds comparable or better solutions than other methods, including 'vanilla' BO, showing great promise for advanced BO techniques, and BADS in particular, as a general model-fitting tool.\n",
      "Prediction on Spike Data Using Kernel Algorithms\n",
      "We report and compare the performance of different learning algorithms based on data from cortical recordings. The task is to predict the orientation of visual stimuli from the activity of a population of simultaneously recorded neurons. We compare several ways of improving the coding of the input (i.e., the spike data) as well as of the output (i.e., the orientation), and report the results obtained using different kernel algorithms.\n",
      "Analog VLSI Model of Intersegmental Coordination with Nearest-Neighbor Coupling\n",
      "We have a developed an analog VLSI system that models the coordination of neurobiological segmental oscillators. We have implemented and tested a system that consists of a chain of eleven pattern generating circuits that are synaptically coupled to their nearest neighbors. Each pattern generating circuit is implemented with two silicon Morris-Lecar neurons that are connected in a reciprocally inhibitory network. We discuss the mechanisms of oscillations in the two-cell network and explore system behavior based on isotropic and anisotropic coupling, and frequency gradients along the chain of oscillators.\n",
      "Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits\n",
      "With the advent of modern stimulation techniques in neuroscience, the opportunity arises to map neuron to neuron connectivity. In this work, we develop a method for efficiently inferring posterior distributions over synaptic strengths in neural microcircuits. The input to our algorithm is data from experiments in which action potentials from putative presynaptic neurons can be evoked while a subthreshold recording is made from a single postsynaptic neuron. We present a realistic statistical model which accounts for the main sources of variability in this experiment and allows for significant prior information about the connectivity and neuronal cell types to be incorporated if available. Due to the technical challenges and sparsity of these systems, it is important to focus experimental time stimulating the neurons whose synaptic strength is most ambiguous, therefore we also develop an online optimal design algorithm for choosing which neurons to stimulate at each trial.\n",
      "Optimal Response Initiation: Why Recent Experience Matters\n",
      "In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond slowly and accurately, or quickly yet be prone to errors. Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed, but also to the recent stimulus history. When stimuli can be characterized on an easy-hard dimension (e.g., word frequency in a naming task), items preceded by easy trials are responded to more quickly, and with more errors, than items preceded by hard trials. We propose a rationally motivated mathematical model of this sequential adaptation of control, based on a diffusion model of the decision process in which difficulty corresponds to the drift rate for the correct response. The model assumes that responding is based on the posterior distribution over which response is correct, conditioned on the accumulated evidence. We derive this posterior as a function of the drift rate, and show that higher estimates of the drift rate lead to (normatively) faster responding. Trial-by-trial tracking of difficulty thus leads to sequential effects in speed and accuracy. Simulations show the model explains a variety of phenomena in human speeded decision making. We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures.\n",
      "Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System\n",
      "We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing self-organizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic field on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.\n",
      "Binary Coding in Auditory Cortex\n",
      "Cortical neurons have been reported to use both rate and temporal codes. Here we describe a novel mode in which each neuron generates exactly 0 or 1 action potentials, but not more, in response to a stimulus. We used cell-attached recording, which ensured single-unit isolation, to record responses in rat auditory cortex to brief tone pips. Surprisingly, the majority of neurons exhibited binary behavior with few multi-spike responses; several dramatic examples consisted of exactly one spike on 100% of trials, with no trial-to-trial variability in spike count. Many neurons were tuned to stimulus frequency. Since individual trials yielded at most one spike for most neurons, the information about stimulus frequency was encoded in the population, and would not have been accessible to later stages of processing that only had access to the activity of a single unit. These binary units allow a more efficient population code than is possible with conventional rate coding units, and are consistent with a model of cortical processing in which synchronous packets of spikes propagate stably from one neuronal population to the next.\n",
      "Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility\n",
      "Acoustic speech recognition degrades in the presence of noise. Compensatory information is available from the visual speech signals around the speaker's mouth. Previous attempts at using these visual speech signals to improve automatic speech recognition systems have combined the acoustic and visual speech information at a symbolic level using heuristic rules. In this paper, we demonstrate an alternative approach to fusing the visual and acoustic speech information by training feedforward neural networks to map the visual signal onto the corresponding short-term spectral amplitude envelope (STSAE) of the acoustic signal. This information can be directly combined with the degraded acoustic STSAE. Significant improvements are demonstrated in vowel recognition from noise-degraded acoustic signals. These results are compared to the performance of humans, as well as other pattern matching and estimation algorithms.\n",
      "Probabilistic principles in unsupervised learning of visual structure: human data and a model\n",
      "To find out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the conditional probabilities of the constituent fragments, and (2) the value of Barlow's criterion of suspicious coincidence (the ratio of joint probability to the product of marginals). We then compared the part verification response times for various probe/target combinations before and after the exposure. For composite probes, the speedup was much larger for targets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. This effect was modulated by the significance of their co-occurrence as estimated by Barlow's criterion. For lone-fragment probes, the speedup in all conditions was generally lower than for composites. These results shed light on the brain's strategies for unsupervised acquisition of structural information in vision.\n",
      "Analyzing human feature learning as nonparametric Bayesian inference\n",
      "Almost all successful machine learning algorithms and cognitive models require powerful representations capturing the features that are relevant to a particular problem. We draw on recent work in nonparametric Bayesian statistics to define a rational model of human feature learning that forms a featural representation from raw sensory data without pre-specifying the number of features. By comparing how the human perceptual system and our rational model use distributional and category information to infer feature representations, we seek to identify some of the forces that govern the process by which people separate and combine sensory primitives to form features.\n",
      "An Information-Theoretic Framework for Understanding Saccadic Eye Movements\n",
      "In this paper, we propose that information maximization can provide a unified framework for understanding saccadic eye movements. In this framework, the mutual information among the cortical representations of the retinal image, the priors constructed from our long term visual experience, and a dynamic short-term internal representation constructed from recent saccades provides a map for guiding eye navigation. By directing the eyes to locations of maximum complexity in neuronal ensemble responses at each step, the automatic saccadic eye movement system greedily collects information about the external world, while modifying the neural representations in the process. This framework attempts to connect several psychological phenomena, such as pop-out and inhibition of return, to long term visual experience and short term working memory. It also provides an interesting perspective on contextual computation and formation of neural representation in the visual system.\n",
      "Interference in Learning Internal Models of Inverse Dynamics in Humans\n",
      "Experiments were performed to reveal some of the computational properties of the human motor memory system. We show that as humans practice reaching movements while interacting with a novel mechanical environment, they learn an internal model of the inverse dynamics of that environment. Subjects show recall of this model at testing sessions 24 hours after the initial practice. The representation of the internal model in memory is such that there is interference when there is an attempt to learn a new inverse dynamics map immediately after an anticorrelated mapping was learned. We suggest that this interference is an indication that the same computational elements used to encode the first inverse dynamics map are being used to learn the second mapping. We predict that this leads to a forgetting of the initially learned skill.\n",
      "A rational decision making framework for inhibitory control\n",
      "Intelligent agents are often faced with the need to choose actions with uncertain consequences, and to modify those actions according to ongoing sensory processing and changing task demands. The requisite ability to dynamically modify or cancel planned actions is known as inhibitory control in psychology. We formalize inhibitory control as a rational decision-making problem, and apply to it to the classical stop-signal task. Using Bayesian inference and stochastic control tools, we show that the optimal policy systematically depends on various parameters of the problem, such as the relative costs of different action choices, the noise level of sensory inputs, and the dynamics of changing environmental demands. Our normative model accounts for a range of behavioral data in humans and animals in the stop-signal task, suggesting that the brain implements statistically optimal, dynamically adaptive, and reward-sensitive decision-making in the context of inhibitory control problems.\n",
      "Machine Learning Applied to Perception: Decision Images for Gender Classification\n",
      "We study gender discrimination of human faces using a combination of psychophysical classification and discrimination experiments together with methods from machine learning. We reduce the dimensionality of a set of face images using principal component analysis, and then train a set of linear classifiers on this reduced representation (linear support vector machines (SVMs), relevance vector machines (RVMs), Fisher linear discriminant (FLD), and prototype (prot) classifiers) using human classification data. Because we combine a linear preprocessor with linear classifiers, the entire system acts as a linear classifier, allowing us to visualise the decision-image corresponding to the normal vector of the separating hyperplanes (SH) of each classifier. We predict that the female-to-maleness transition along the normal vector for classifiers closely mimicking human classification (SVM and RVM [1]) should be faster than the transition along any other direction. A psychophysical discrimination experiment using the decision images as stimuli is consistent with this prediction.\n",
      "Experience-Guided Search: A Theory of Attentional Control\n",
      "People perform a remarkable range of tasks that require search of the visual environment for a target item among distractors. The Guided Search model (Wolfe, 1994, 2007), or GS, is perhaps the best developed psychological account of human visual search. To prioritize search, GS assigns saliency to locations in the visual field. Saliency is a linear combination of activations from retinotopic maps representing primitive visual features. GS includes heuristics for setting the gain coefficient associated with each map. Variants of GS have formalized the notion of optimization as a principle of attentional control (e.g., Baldwin & Mozer, 2006; Cave, 1999; Navalpakkam & Itti, 2006; Rao et al., 2002), but every GS-like model must be 'dumbed down' to match human data, e.g., by corrupting the saliency map with noise and by imposing arbitrary restrictions on gain modulation. We propose a principled probabilistic formulation of GS, called Experience-Guided Search (EGS), based on a generative model of the environment that makes three claims: (1) Feature detectors produce Poisson spike trains whose rates are conditioned on feature type and whether the feature belongs to a target or distractor; (2) the environment and/or task is nonstationary and can change over a sequence of trials; and (3) a prior specifies that features are more likely to be present for target than for distractors. Through experience, EGS infers latent environment variables that determine the gains for guiding search. Control is thus cast as probabilistic inference, not optimization. We show that EGS can replicate a range of human data from visual search, including data that GS does not address.\n",
      "An Information Theoretic Approach to the Functional Classification of Neurons\n",
      "A population of neurons typically exhibits a broad diversity of responses to sensory inputs. The intuitive notion of functional classification is that cells can be clustered so that most of the diversity is captured by the identity of the clusters rather than by individuals within clusters. We show how this intuition can be made precise using information theory, without any need to introduce a metric on the space of stimuli or responses. Applied to the retinal ganglion cells of the salamander, this approach recovers classical results, but also provides clear evidence for subclasses beyond those identified previously. Further, we find that each of the ganglion cells is functionally unique, and that even within the same subclass only a few spikes are needed to reliably distinguish between cells.\n",
      "Salient Contour Extraction by Temporal Binding in a Cortically-based Network\n",
      "It has been suggested that long-range intrinsic connections in striate cortex may play a role in contour extraction (Gilbert et al., 1996). A number of recent physiological and psychophysical studies have examined the possible role of long range connections in the modulation of contrast detection thresholds (Polat and Sagi, 1993, 1994; Kapadia et al., 1995; Kovacs and Julesz, 1994) and various pre-attentive detection tasks (Kovacs and Julesz, 1993; Field et al., 1993). We have developed a network architecture based on the anatomical connectivity of striate cortex, as well as the temporal dynamics of neuronal processing, that is able to reproduce the observed experimental results. The network has been tested on real images and has applications in terms of identifying salient contours in automatic image processing systems.\n",
      "Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning\n",
      "We model hippocampal place cells and head-direction cells by combining allothetic (visual) and idiothetic (proprioceptive) stimuli. Visual input, provided by a video camera on a miniature robot, is preprocessed by a set of Gabor filters on 31 nodes of a log-polar retinotopic graph. Unsupervised Hebbian learning is employed to incrementally build a population of localized overlapping place fields. Place cells serve as basis functions for reinforcement learning. Experimental results for goal-oriented navigation of a mobile robot are presented.\n",
      "Connectionist Implementation of a Theory of Generalization\n",
      "Empirically, generalization between a training and a test falls off in close approximation to an exponential decay function of distance between the two stimuli in the stimulus obtained by multidimensional scaling. Mathematically, this result is derivable from the assumption that an individual takes the training to belong to a region that includes that but is otherwise of unknown location, size, and shape in the space (Shepard, 1987). As the individual gains additional information about the consequential region--by finding other stimuli to be consequential or not--the theory predicts the shape of the generalization function to change toward the function relating actual probability of the consequence to location in the space. This paper describes a natural connectionist implementation of the theory, and illustrates how implications of the theory for generalization, discrimination, and classification learning can be explored by connectionist simulation.\n",
      "Efficient Simulation of Biological Neural Networks on Massively Parallel Supercomputers with Hypercube Architecture\n",
      "We present a neural network simulation which we implemented on the massively parallel Connection Machine 2. In contrast to previous work, this simulator is based on biologically realistic neurons with nontrivial single-cell dynamics, high connectivity with a structure modelled in agreement with biological data, and preservation of the temporal dynamics of spike interactions. We simulate neural networks of 16,384 neurons coupled by about 1000 synapses per neuron, and estimate the performance for much larger systems. Communication between neurons is identified as the computationally most demanding task and we present a novel method to overcome this bottleneck. The simulator has already been used to study the primary visual system of the cat.\n",
      "Filter Selection Model for Generating Visual Motion Signals\n",
      "Neurons in area MT of primate visual cortex encode the velocity of moving objects. We present a model of how MT cells aggregate responses from VI to form such a velocity representation. Two different sets of units, with local receptive fields, receive inputs from motion energy filters. One set of units forms estimates of local motion, while the second set computes the utility of these estimates. Outputs from this second set of units gate the outputs from the first set through a gain control mechanism. This active process for selecting only a subset of local motion responses to integrate into more global responses distinguishes our model from previous models of velocity estimation. The model yields accurate velocity estimates in synthetic images containing multiple moving targets of varying size, luminance, and spatial frequency profile and deals well with a number of transparency phenomena.\n",
      "Enforcing balance allows local supervised learning in spiking recurrent networks\n",
      "To predict sensory inputs or control motor trajectories, the brain must constantly learn temporal dynamics based on error feedback. However, it remains unclear how such supervised learning is implemented in biological neural networks. Learning in recurrent spiking networks is notoriously difficult because local changes in connectivity may have an unpredictable effect on the global dynamics. The most commonly used learning rules, such as temporal back-propagation, are not local and thus not biologically plausible. Furthermore, reproducing the Poisson-like statistics of neural responses requires the use of networks with balanced excitation and inhibition. Such balance is easily destroyed during learning. Using a top-down approach, we show how networks of integrate-and-fire neurons can learn arbitrary linear dynamical systems by feeding back their error as a feed-forward input. The network uses two types of recurrent connections: fast and slow. The fast connections learn to balance excitation and inhibition using a voltage-based plasticity rule. The slow connections are trained to minimize the error feedback using a current-based Hebbian learning rule. Importantly, the balance maintained by fast connections is crucial to ensure that global error signals are available locally in each neuron, in turn resulting in a local learning rule for the slow connections. This demonstrates that spiking networks can learn complex dynamics using purely local learning rules, using E/I balance as the key rather than an additional constraint. The resulting network implements a given function within the predictive coding scheme, with minimal dimensions and activity.\n",
      "Mutually Regressive Point Processes\n",
      "Many real-world data represent sequences of interdependent events unfolding over time. They can be modeled naturally as realizations of a point process. Despite many potential applications, existing point process models are limited in their ability to capture complex patterns of interaction. Hawkes processes admit many efficient inference algorithms, but are limited to mutually excitatory effects. Non- linear Hawkes processes allow for more complex influence patterns, but for their estimation it is typically necessary to resort to discrete-time approximations that may yield poor generative models. In this paper, we introduce the first general class of Bayesian point process models extended with a nonlinear component that allows both excitatory and inhibitory relationships in continuous time. We derive a fully Bayesian inference algorithm for these processes using Polya-Gamma augmentation and Poisson thinning. We evaluate the proposed model on single and multi-neuronal spike train recordings. Results demonstrate that the proposed model, unlike existing point process models, can generate biologically-plausible spike trains, while still achieving competitive predictive likelihoods.\n",
      "Metamers of neural networks reveal divergence from human perceptual systems\n",
      "Deep neural networks have been embraced as models of sensory systems, instantiating representational transformations that appear to resemble those in the visual and auditory systems. To more thoroughly investigate their similarity to biological systems, we synthesized model metamers – stimuli that produce the same responses at some stage of a network’s representation. We generated model metamers for natural stimuli by performing gradient descent on a noise signal, matching the responses of individual layers of image and audio networks to a natural image or speech signal. The resulting signals reflect the invariances instantiated in the network up to the matched layer. We then measured whether model metamers were recognizable to human observers – a necessary condition for the model representations to replicate those of humans. Although model metamers from early network layers were recognizable to humans, those from deeper layers were not. Auditory model metamers became more human-recognizable with architectural modifications that reduced aliasing from pooling operations, but those from the deepest layers remained unrecognizable. We also used the metamer test to compare model representations. Cross-model metamer recognition dropped off for deeper layers, roughly at the same point that human recognition deteriorated, indicating divergence across model representations. The results reveal discrepancies between model and human representations, but also show how metamers can help guide model refinement and elucidate model representations.\n",
      "Learning visual biases from human imagination\n",
      "Although the human visual system can recognize many concepts under challenging conditions, it still has some biases. In this paper, we investigate whether we can extract these biases and transfer them into a machine recognition system. We introduce a novel method that, inspired by well-known tools in human psychophysics, estimates the biases that the human visual system might use for recognition, but in computer vision feature spaces. Our experiments are surprising, and suggest that classifiers from the human visual system can be transferred into a machine with some success. Since these classifiers seem to capture favorable biases in the human visual system, we further present an SVM formulation that constrains the orientation of the SVM hyperplane to agree with the bias from human visual system. Our results suggest that transferring this human bias into machines may help object recognition systems generalize across datasets and perform better when very little training data is available.\n",
      "Maximum Covariance Unfolding : Manifold Learning for Bimodal Data\n",
      "We propose maximum covariance unfolding (MCU), a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities. Given high dimensional inputs from two different but naturally aligned sources, MCU computes a common low dimensional embedding that maximizes the cross-modal (inter-source) correlations while preserving the local (intra-source) distances. In this paper, we explore two applications of MCU. First we use MCU to analyze EEG-fMRI data, where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces. To perform this visualization, we augment MCU with an additional step for metric learning in the high dimensional voxel space. Second, we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia. To manage large applications of MCU, we develop a fast implementation based on ideas from spectral graph theory. These ideas transform the original problem for MCU, one of semidefinite programming, into a simpler problem in semidefinite quadratic linear programming.\n",
      "A Computational Model of Eye Movements during Object Class Detection\n",
      "We present a computational model of human eye movements in an object class detection task. The model combines state-of-the-art computer vision object class detection methods (SIFT features trained using AdaBoost) with a biologically plausible model of human eye movement to produce a sequence of simulated fixations, culminating with the acquisition of a target. We validated the model by comparing its behavior to the behavior of human observers performing the identical object class detection task (looking for a teddy bear among visually complex non-target objects). We found considerable agreement between the model and human data in multiple eye movement measures, including number of fixations, cumulative probability of fixating the target, and scanpath distance.\n",
      "Waveform Driven Plasticity in BiFeO3 Memristive Devices: Model and Implementation\n",
      "Memristive devices have recently been proposed as efficient implementations of plastic synapses in neuromorphic systems. The plasticity in these memristive devices, i.e. their resistance change, is defined by the applied waveforms. This behavior resembles biological synapses, whose plasticity is also triggered by mechanisms that are determined by local waveforms. However, learning in memristive devices has so far been approached mostly on a pragmatic technological level. The focus seems to be on finding any waveform that achieves spike-timing-dependent plasticity (STDP), without regard to the biological veracity of said waveforms or to further important forms of plasticity. Bridging this gap, we make use of a plasticity model driven by neuron waveforms that explains a large number of experimental observations and adapt it to the characteristics of the recently introduced BiFeO3 memristive material. Based on this approach, we show STDP for the first time for this material, with learning window replication superior to previous memristor-based STDP implementations. We also demonstrate in measurements that it is possible to overlay short and long term plasticity at a memristive device in the form of the well-known triplet plasticity. To the best of our knowledge, this is the first implementations of triplet plasticity on any physical memristive device.\n",
      "Sparse Bayesian structure learning with “dependent relevance determination” priors\n",
      "In many problem settings, parameter vectors are not merely sparse, but dependent in such a way that non-zero coefficients tend to cluster together. We refer to this form of dependency as region sparsity. Classical sparse regression methods, such as the lasso and automatic relevance determination (ARD), model parameters as independent a priori, and therefore do not exploit such dependencies. Here we introduce a hierarchical model for smooth, region-sparse weight vectors and tensors in a linear regression setting. Our approach represents a hierarchical extension of the relevance determination framework, where we add a transformed Gaussian process to model the dependencies between the prior variances of regression weights. We combine this with a structured model of the prior variances of Fourier coefficients, which eliminates unnecessary high frequencies. The resulting prior encourages weights to be region-sparse in two different bases simultaneously. We develop efficient approximate inference methods and show substantial improvements over comparable methods (e.g., group lasso and smooth RVM) for both simulated and real datasets from brain imaging.\n",
      "Causal time series analysis of functional magnetic resonance imaging data\n",
      "This review focuses on dynamic causal analysis of functional magnetic resonance (fMRI) data to infer brain connectivity from a time series analysis and dynamical systems perspective. Causal influence is expressed in the Wiener-Akaike-Granger-Schweder (WAGS) tradition and dynamical systems are treated in a state space modeling framework. The nature of the fMRI signal is reviewed with emphasis on the involved neuronal, physiological and physical processes and their modeling as dynamical systems. In this context, two streams of development in modeling causal brain connectivity using fMRI are discussed: time series approaches to causality in a discrete time tradition and dynamic systems and control theory approaches in a continuous time tradition. This review closes with discussion of ongoing work and future perspectives on the integration of the two approaches.\n",
      "VISIT: A Neural Model of Covert Visual Attention\n",
      "Visual attention is the ability to dynamically restrict processing to a subset of the visual field. Researchers have long argued that such a mechanism is necessary to efficiently perform many intermediate level visual tasks. This paper describes VISIT, a novel neural network model of visual attention. The current system models the search for target objects in scenes containing multiple distractors. This is a natural task for people, it is studied extensively by psychologists, and it requires attention. The network's behavior closely matches the known psychophysical data on visual search and visual attention. VISIT also matches much of the physiological data on attention and provides a novel view of the functionality of a number of visual areas. This paper concentrates on the biological plausibility of the model and its relationship to the primary visual cortex, pulvinar, superior colliculus and posterior parietal areas.\n",
      "Homeostatic plasticity in Bayesian spiking networks as Expectation Maximization with posterior constraints\n",
      "Recent spiking network models of Bayesian inference and unsupervised learning frequently assume either inputs to arrive in a special format or employ complex computations in neuronal activation functions and synaptic plasticity rules. Here we show in a rigorous mathematical treatment how homeostatic processes, which have previously received little attention in this context, can overcome common theoretical limitations and facilitate the neural implementation and performance of existing models. In particular, we show that homeostatic plasticity can be understood as the enforcement of a 'balancing' posterior constraint during probabilistic inference and learning with Expectation Maximization. We link homeostatic dynamics to the theory of variational inference, and show that nontrivial terms, which typically appear during probabilistic inference in a large class of models, drop out. We demonstrate the feasibility of our approach in a spiking Winner-Take-All architecture of Bayesian inference and learning. Finally, we sketch how the mathematical framework can be extended to richer recurrent network architectures. Altogether, our theory provides a novel perspective on the interplay of homeostatic processes and synaptic plasticity in cortical microcircuits, and points to an essential role of homeostasis during inference and learning in spiking networks.\n",
      "A Connectionist Model of the Owl's Sound Localization System\n",
      "We do not have a good understanding of how theoretical principles of learning are realized in neural systems. To address this problem we built a computational model of development in the owl's sound localization system. The structure of the model is drawn from known experimental data while the learning principles come from recent work in the field of brain style computation. The model accounts for numerous properties of the owl's sound localization system, makes specific and testable predictions for future experiments, and provides a theory of the developmental process.\n",
      "Measuring model complexity with the prior predictive\n",
      "In the last few decades, model complexity has received a lot of press. While many methods have been proposed that jointly measure a model's descriptive adequacy and its complexity, few measures exist that measure complexity in itself. Moreover, existing measures ignore the parameter prior, which is an inherent part of the model and affects the complexity. This paper presents a stand alone measure for model complexity, that takes the number of parameters, the functional form, the range of the parameters and the parameter prior into account. This Prior Predictive Complexity (PPC) is an intuitive and easy to compute measure. It starts from the observation that model complexity is the property of the model that enables it to fit a wide range of outcomes. The PPC then measures how wide this range exactly is.\n",
      "Measuring Neural Synchrony by Message Passing\n",
      "A novel approach to measure the interdependence of two time series is proposed, referred to as stochastic event (SES); it quantifies the alignment of two point processes by means of the following parameters: time delay, variance of the timing jitter, fraction of spurious events, and average similarity of events. SES may be applied to generic one-dimensional and multi-dimensional point processes, however, the paper mainly focusses on point processes in time-frequency domain. The average event similarity is in that case described by two parameters: the average frequency offset between events in the time-frequency plane, and the variance of the frequency offset (frequency jitter); SES then consists of five parameters in total. Those parameters quantify the synchrony of oscillatory events, and hence, they provide an alternative to existing synchrony measures that quantify amplitude or phase synchrony. The pairwise alignment of point processes is cast as a statistical inference problem, which is solved by applying the max-product algorithm on a graphical model. The SES parameters are determined from the resulting pairwise alignment by maximum a posteriori (MAP) estimation. The proposed interdependence measure is applied to the problem of detecting anomalies in EEG synchrony of Mild Cognitive Impairment (MCI) patients; the results indicate that SES significantly improves the sensitivity of EEG in detecting MCI.\n",
      "Plasticity Kernels and Temporal Statistics\n",
      "Computational mysteries surround the kernels relating the magnitude and sign of changes in efficacy as a function of the time difference between pre- and post-synaptic activity at a synapse. One important idea34 is that kernels result from filtering, ie an attempt by synapses to eliminate noise corrupting learning. This idea has hitherto been applied to trace learning rules; we apply it to experimentally-defined kernels, using it to reverse-engineer assumed signal statistics. We also extend it to consider the additional goal for filtering of weighting learning according to statistical surprise, as in the Z-score transform. This provides a fresh view of observed kernels and can lead to different, and more natural, signal statistics.\n",
      "A Low-Power Analog VLSI Visual Collision Detector\n",
      "We have designed and tested a single-chip analog VLSI sensor that detects imminent collisions by measuring radially expansive optic flow. The design of the chip is based on a model proposed to explain leg-extension behavior in flies during landing approaches. A new elementary motion detector (EMD) circuit was developed to measure optic flow. This EMD circuit models the bandpass nature of large monopolar cells (LMCs) immediately postsynaptic to photoreceptors in the fly visual system. A 16 × 16 array of 2-D motion detectors was fabricated on a 2.24 mm × 2.24 mm die in a standard 0.5-µm CMOS process. The chip consumes 140 µW of power from a 5 V supply. With the addition of wide-angle optics, the sensor is able to detect collisions around 500 ms before impact in complex, real-world scenes.\n",
      "Extracting Latent Structure From Multiple Interacting Neural Populations\n",
      "Developments in neural recording technology are rapidly enabling the recording of populations of neurons in multiple brain areas simultaneously, as well as the identification of the types of neurons being recorded (e.g., excitatory vs. inhibitory). There is a growing need for statistical methods to study the interaction among multiple, labeled populations of neurons. Rather than attempting to identify direct interactions between neurons (where the number of interactions grows with the number of neurons squared), we propose to extract a smaller number of latent variables from each population and study how these latent variables interact. Specifically, we propose extensions to probabilistic canonical correlation analysis (pCCA) to capture the temporal structure of the latent variables, as well as to distinguish within-population dynamics from across-population interactions (termed Group Latent Auto-Regressive Analysis, gLARA). We then applied these methods to populations of neurons recorded simultaneously in visual areas V1 and V2, and found that gLARA provides a better description of the recordings than pCCA. This work provides a foundation for studying how multiple populations of neurons interact and how this interaction supports brain function.\n",
      "Analysis of Unstandardized Contributions in Cross Connected Networks\n",
      "Understanding knowledge representations in neural nets has been a difficult problem. Principal components analysis (PCA) of contributions (products of sending activations and connection weights) has yielded valuable insights into knowledge representations, but much of this work has focused on the correlation matrix of contributions. The present work shows that analyzing the variance-covariance matrix of contributions yields more valid insights by taking account of weights.\n",
      "Hierarchical Learning of Dimensional Biases in Human Categorization\n",
      "Existing models of categorization typically represent to-be-classified items as points in a multidimensional space. While from a mathematical point of view, an infinite number of basis sets can be used to represent points in this space, the choice of basis set is psychologically crucial. People generally choose the same basis dimensions - and have a strong preference to generalize along the axes of these dimensions, but not diagonally. What makes some choices of dimension special? We explore the idea that the dimensions used by people echo the natural variation in the environment. Specifically, we present a rational model that does not assume dimensions, but learns the same type of dimensional generalizations that people display. This bias is shaped by exposing the model to many categories with a structure hypothesized to be like those which children encounter. The learning behaviour of the model captures the developmental shift from roughly isotropic for children to the axis-aligned generalization that adults show.\n",
      "A Productive, Systematic Framework for the Representation of Visual Structure\n",
      "We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common middle-scale parts, represented as image fragments. The model addresses the same concerns as previous work on compositional representation through the use of what+where receptive fields and attentional gain modulation. It does not require prior exposure to the individual parts, and avoids the need for abstract symbolic binding.\n",
      "On the connections between saliency and tracking\n",
      "A model connecting visual tracking and saliency has recently been proposed. This model is based on the saliency hypothesis for tracking which postulates that tracking is achieved by the top-down tuning, based on target features, of discriminant center-surround saliency mechanisms over time. In this work, we identify three main predictions that must hold if the hypothesis were true: 1) tracking reliability should be larger for salient than for non-salient targets, 2) tracking reliability should have a dependence on the defining variables of saliency, namely feature contrast and distractor heterogeneity, and must replicate the dependence of saliency on these variables, and 3) saliency and tracking can be implemented with common low level neural mechanisms. We confirm that the first two predictions hold by reporting results from a set of human behavior studies on the connection between saliency and tracking. We also show that the third prediction holds by constructing a common neurophysiologically plausible architecture that can computationally solve both saliency and tracking. This architecture is fully compliant with the standard physiological models of V1 and MT, and with what is known about attentional control in area LIP, while explaining the results of the human behavior experiments.\n",
      "The Fidelity of Local Ordinal Encoding\n",
      "A key question in neuroscience is how to encode sensory stimuli such as images and sounds. Motivated by studies of response properties of neurons in the early cortical areas, we propose an encoding scheme that dispenses with absolute measures of signal intensity or contrast and uses, instead, only local ordinal measures. In this scheme, the structure of a signal is represented by a set of equalities and inequalities across adjacent regions. In this paper, we focus on characterizing the fidelity of this representation strategy. We develop a regularization approach for image reconstruction from ordinal measures and thereby demonstrate that the ordinal representation scheme can faithfully encode signal structure. We also present a neurally plausible implementation of this computation that uses only local update rules. The results highlight the robustness and generalization ability of local ordinal encodings for the task of pattern classification.\n",
      "A Short-Term Memory Architecture for the Learning of Morphophonemic Rules\n",
      "Despite its successes, Rumelhart and McClelland's (1986) well-known approach to the learning of morphophonemic rules suffers from two deficiencies: (1) It performs the artificial task of associating forms with forms rather than perception or production. (2) It is not constrained in ways that humans learners are. This paper describes a model which addresses both objections. Using a simple recurrent architecture which takes both forms and meanings as inputs, the model learns to generate verbs in one or another tense, given arbitrary meanings, and to recognize the tenses of verbs. Furthermore, it fails to learn reversal processes unknown in human language.\n",
      "Recognizing Evoked Potentials in a Virtual Environment\n",
      "Virtual reality (VR) provides immersive and controllable experimental environments. It expands the bounds of possible evoked potential (EP) experiments by providing complex, dynamic environments in order to study cognition without sacrificing environmental control. VR also serves as a safe dynamic testbed for brain-computer interface (BCI) research. However, there has been some concern about detecting EP signals in a complex VR environment. This paper shows that EPs exist at red, green, and yellow lights in a virtual driving environment. Experimental results show the existence of the P3 EP at go and stop lights and the contingent negative variation (CNY) EP at lights. In order to test the feasibility of on-line recognition in VR, we looked at recognizing the P3 EP at red tights and the absence of this signal at yellow slow down lights. Recognition results show that the P3 may successfully be used to control the brakes of a VR car at lights.\n",
      "Human Rademacher Complexity\n",
      "We propose to use Rademacher complexity, originally developed in computational theory, as a measure of human capacity. Rademacher complexity measures a learner's ability to fit random labels, and can be used to bound the learner's true error based on the observed training sample error. We first review the definition of Rademacher complexity and its generalization bound. We then describe a learning the noise procedure to experimentally measure human Rademacher complexities. The results from empirical studies showed that: (i) human Rademacher complexity can be successfully measured, (ii) the complexity depends on the domain and training sample size in intuitive ways, (iii) human respects the generalization bounds, (iv) the bounds can be useful in predicting the danger of overfitting in human learning. Finally, we discuss the potential applications of human Rademacher complexity in cognitive science.\n",
      "Estimating the Location and Orientation of Complex, Correlated Neural Activity using MEG\n",
      "The synchronous brain activity measured via MEG (or EEG) can be interpreted as arising from a collection (possibly large) of current dipoles or sources located throughout the cortex. Estimating the number, location, and orientation of these sources remains a challenging task, one that is significantly compounded by the effects of source correlations and the presence of interference from spontaneous brain activity, sensor noise, and other artifacts. This paper derives an empirical Bayesian method for addressing each of these issues in a principled fashion. The resulting algorithm guarantees descent of a cost function uniquely designed to handle unknown orientations and arbitrary correlations. Robust interference suppression is also easily incorporated. In a restricted setting, the proposed method is shown to have theoretically zero bias estimating both the location and orientation of multi-component dipoles even in the presence of correlations, unlike a variety of existing Bayesian localization methods or common signal processing techniques such as beamforming and sLORETA. Empirical results on both simulated and real data sets verify the efficacy of this approach.\n",
      "3D Object Recognition: A Model of View-Tuned Neurons\n",
      "In 1990 Poggio and Edelman proposed a view-based model of object recognition that accounts for several psychophysical properties of certain recognition tasks. The model predicted the existence of view-tuned and view-invariant units, that were later found by Logothetis et al. (Logothetis et al., 1995) in IT cortex of monkeys trained with views of specific paperclip objects. The model, however, does not specify the inputs to the view-tuned units and their internal organization. In this paper we propose a model of these view-tuned units that is consistent with physiological data from single cell responses.\n",
      "Information Capacity and Robustness of Stochastic Neuron Models\n",
      "The reliability and accuracy of spike trains have been shown to depend on the nature of the stimulus that the neuron encodes. Adding ion channel stochasticity to neuronal models results in a macroscopic behavior that replicates the input-dependent reliability and precision of real neurons. We calculate the amount of information that an ion channel based stochastic Hodgkin-Huxley (HH) neuron model can encode about a wide set of stimuli. We show that both the information rate and the information per spike of the stochastic model are similar to the values reported experimentally. Moreover, the amount of information that the neuron encodes is correlated with the amplitude of fluctuations in the input, and less so with the average firing rate of the neuron. We also show that for the HH ion channel density, the information capacity is robust to changes in the density of ion channels in the membrane, whereas changing the ratio between the Na+ and K+ ion channels has a considerable effect on the information that the neuron can encode. Finally, we suggest that neurons may maximize their information capacity by appropriately balancing the density of the different ion channels that underlie neuronal excitability.\n",
      "A Bilinear Model for Sparse Coding\n",
      "Recent algorithms for sparse coding and independent component analysis (ICA) have demonstrated how localized features can be learned from natural images. However, these approaches do not take image transformations into account. As a result, they produce image codes that are redundant because the same feature is learned at multiple locations. We describe an algorithm for sparse coding based on a bilinear generative model of images. By explicitly modeling the interaction between image features and their transformations, the bilinear approach helps reduce redundancy in the image code and provides a basis for transformation-invariant vision. We present results demonstrating bilinear sparse coding of natural images. We also explore an extension of the model that can capture spatial relationships between the independent features of an object, thereby providing a new framework for parts-based object recognition.\n",
      "Fast Similarity Search via Optimal Sparse Lifting\n",
      "Similarity search is a fundamental problem in computing science with various applications and has attracted significant research attention, especially in large-scale search with high dimensions. Motivated by the evidence in biological science, our work develops a novel approach for similarity search. Fundamentally different from existing methods that typically reduce the dimension of the data to lessen the computational complexity and speed up the search, our approach projects the data into an even higher-dimensional space while ensuring the sparsity of the data in the output space, with the objective of further improving precision and speed. Specifically, our approach has two key steps. Firstly, it computes the optimal sparse lifting for given input samples and increases the dimension of the data while approximately preserving their pairwise similarity. Secondly, it seeks the optimal lifting operator that best maps input samples to the optimal sparse lifting. Computationally, both steps are modeled as optimization problems that can be efficiently and effectively solved by the Frank-Wolfe algorithm. Simple as it is, our approach has reported significantly improved results in empirical evaluations, and exhibited its high potentials in solving practical problems.\n",
      "Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity\n",
      "Resting state activity is brain activation that arises in the absence of any task, and is usually measured in awake subjects during prolonged fMRI scanning sessions where the only instruction given is to close the eyes and do nothing. It has been recognized in recent years that resting state activity is implicated in a wide variety of brain function. While certain networks of brain areas have different levels of activation at rest and during a task, there is nevertheless significant similarity between activations in the two cases. This suggests that recordings of resting state activity can be used as a source of unlabeled data to augment discriminative regression techniques in a semi-supervised setting. We evaluate this setting empirically yielding three main results: (i) regression tends to be improved by the use of Laplacian regularization even when no additional unlabeled data are available, (ii) resting state data seem to have a similar marginal distribution to that recorded during the execution of a visual processing task implying largely similar types of activation, and (iii) this source of information can be broadly exploited to improve the robustness of empirical inference in fMRI studies, an inherently data poor domain.\n",
      "Task and Spatial Frequency Effects on Face Specialization\n",
      "There is strong evidence that face processing is localized in the brain. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and nonface object recognition may be served by partially independent mechanisms in the brain. Is neural specialization innate or learned? We suggest that this specialization could be tbe result of a competitive learning mechanism that, during development, devotes neural resources to the tasks they are best at performing. Furtber, we suggest that the specialization arises as an interaction between task requirements and developmental constraints. In this paper, we present a feed-forward computational model of visual processing, in which two modules compete to classify input stimuli. When one module receives low spatial frequency information and the other receives high spatial frequency information, and the task is to identify the faces while simply classifying the objects, the low frequency network shows a strong specialization for faces. No other combination of tasks and inputs shows this strong specialization. We take these results as support for the idea that an innately-specified face processing module is unnecessary.\n",
      "A Biologically Plausible Model for Rapid Natural Scene Identification\n",
      "Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scene's visual gist. Here we investigated whether a neural response model based on the Weibull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measured EEC activity of 32 subjects viewing brief Hashes of 700 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli, we derived an across subject Weibull response model. We used this model to predict the HKG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the mode) predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicted the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene was visually similar to the observed scene itself. Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images. Together, these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification.\n",
      "Mass Meta-analysis in Talairach Space\n",
      "We provide a method for mass meta-analysis in a neuroinformatics database containing stereotaxic Talairach coordinates from neuroimaging experiments. Database labels are used to group the individual experiments, e.g., according to cognitive function, and the consistent pattern of the experiments within the groups are determined. The method voxelizes each group of experiments via a kernel density estimation, forming probability density volumes. The values in the probability density volumes are compared to null-hypothesis distributions generated by resamplings from the entire unlabeled set of experiments, and the distances to the null-hypotheses are used to sort the voxels across groups of experiments. This allows for mass meta-analysis, with the construction of a list with the most prominent associations between brain areas and group labels. Furthermore, the method can be used for functional labeling of voxels.\n",
      "Modeling Neural Population Spiking Activity with Gibbs Distributions\n",
      "Probabilistic modeling of correlated neural population firing activity is central to understanding the neural code and building practical decoding algorithms. No parametric models currently exist for modeling multi-variate correlated neural data and the high dimensional nature of the data makes fully non-parametric methods impractical. To address these problems we propose an energy-based model in which the joint probability of neural activity is represented using learned functions of the 1D marginal histograms of the data. The parameters of the model are learned using contrastive divergence and an optimization procedure for finding appropriate marginal directions. We evaluate the method using real data recorded from a population of motor cortical neurons. In particular, we model the joint probability of population spiking times and 2D hand position and show that the likelihood of test data under our model is significantly higher than under other models. These results suggest that our model captures correlations in the firing activity. Our rich probabilistic model of neural population activity is a step towards both measurement of the importance of correlations in neural coding and improved decoding of population activity.\n",
      "The Conjoint Effect of Divisive Normalization and Orientation Selectivity on Redundancy Reduction\n",
      "Bandpass filtering, orientation selectivity, and contrast gain control are prominent features of sensory coding at the level of V1 simple cells. While the effect of bandpass filtering and orientation selectivity can be assessed within a linear model, contrast gain control is an inherently nonlinear computation. Here we employ the class of $L_p$ elliptically contoured distributions to investigate the extent to which the two features---orientation selectivity and contrast gain control---are suited to model the statistics of natural images. Within this framework we find that contrast gain control can play a significant role for the removal of redundancies in natural images. Orientation selectivity, in contrast, has only a very limited potential for redundancy reduction.\n",
      "Fast Sampling-Based Inference in Balanced Neuronal Networks\n",
      "Multiple lines of evidence support the notion that the brain performs probabilistic inference in multiple cognitive domains, including perception and decision making. There is also evidence that probabilistic inference may be implemented in the brain through the (quasi-)stochastic activity of neural circuits, producing samples from the appropriate posterior distributions, effectively implementing a Markov chain Monte Carlo algorithm. However, time becomes a fundamental bottleneck in such sampling-based probabilistic representations: the quality of inferences depends on how fast the neural circuit generates new, uncorrelated samples from its stationary distribution (the posterior). We explore this bottleneck in a simple, linear-Gaussian latent variable model, in which posterior sampling can be achieved by stochastic neural networks with linear dynamics. The well-known Langevin sampling (LS) recipe, so far the only sampling algorithm for continuous variables of which a neural implementation has been suggested, naturally fits into this dynamical framework. However, we first show analytically and through simulations that the symmetry of the synaptic weight matrix implied by LS yields critically slow mixing when the posterior is high-dimensional. Next, using methods from control theory, we construct and inspect networks that are optimally fast, and hence orders of magnitude faster than LS, while being far more biologically plausible. In these networks, strong - but transient - selective amplification of external noise generates the spatially correlated activity fluctuations prescribed by the posterior. Intriguingly, although a detailed balance of excitation and inhibition is dynamically maintained, detailed balance of Markov chain steps in the resulting sampler is violated, consistent with recent findings on how statistical irreversibility can overcome the speed limitation of random walks in other domains.\n",
      "Forward dynamic models in human motor control: Psychophysical evidence\n",
      "Based on computational principles, with as yet no direct experimental validation, it has been proposed that the central nervous system (CNS) uses an internal model to simulate the dynamic behavior of the motor system in planning, control and learning (Sutton and Barto, 1981; Ito, 1984; Kawato et al., 1987; Jordan and Rumelhart, 1992; Miall et al., 1993). We present experimental results and simulations based on a novel approach that investigates the temporal propagation of errors in the sensorimotor integration process. Our results provide direct support for the existence of an internal model.\n",
      "Optimal context separation of spiking haptic signals by second-order somatosensory neurons\n",
      "We study an encoding/decoding mechanism accounting for the relative spike timing of the signals propagating from peripheral nerve fibers to second-order so-matosensory neurons in the cuneate nucleus (CN). The CN is modeled as a population of spiking neurons receiving as inputs the spatiotemporal responses of real mechanoreceptors obtained via microneurography recordings in humans. The efficiency of the haptic discrimination process is quantified by a novel definition of entropy that takes into full account the metrical properties of the spike train space. This measure proves to be a suitable decoding scheme for generalizing the classical Shannon entropy to spike-based neural codes. It permits an assessment of neurotransmission in the presence of a large output space (i.e. hundreds of spike trains) with 1 ms temporal precision. It is shown that the CN population code performs a complete discrimination of 81 distinct stimuli already within 35 ms of the first afferent spike, whereas a partial discrimination (80% of the maximum information transmission) is possible as rapidly as 15 ms. This study suggests that the CN may not constitute a mere synaptic relay along the somatosensory pathway but, rather, it may convey optimal contextual accounts (in terms of fast and reliable information transfer) of peripheral tactile inputs to downstream structures of the central nervous system.\n",
      "Categorization Under Complexity: A Unified MDL Account of Human Learning of Regular and Irregular Categories\n",
      "We present an account of human concept learning—that is, learning of categories from examples—based on the principle of minimum description length (MDL). In support of this theory, we tested a wide range of two-dimensional concept types, including both regular (simple) and highly irregular (complex) structures, and found the MDL theory to give a good account of subjects' performance. This suggests that the intrinsic complexity of a concept (that is, its description length) systematically influences its learnability.\n",
      "Restricted Boltzmann machines modeling human choice\n",
      "We extend the multinomial logit model to represent some of the empirical phenomena that are frequently observed in the choices made by humans. These phenomena include the similarity effect, the attraction effect, and the compromise effect. We formally quantify the strength of these phenomena that can be represented by our choice model, which illuminates the flexibility of our choice model. We then show that our choice model can be represented as a restricted Boltzmann machine and that its parameters can be learned effectively from data. Our numerical experiments with real data of human choices suggest that we can train our choice model in such a way that it represents the typical phenomena of choice.\n",
      "Testing a Bayesian Measure of Representativeness Using a Large Image Database\n",
      "How do people determine which elements of a set are most representative of that set? We extend an existing Bayesian measure of representativeness, which indicates the representativeness of a sample from a distribution, to define a measure of the representativeness of an item to a set. We show that this measure is formally related to a machine learning method known as Bayesian Sets. Building on this connection, we derive an analytic expression for the representativeness of objects described by a sparse vector of binary features. We then apply this measure to a large database of images, using it to determine which images are the most representative members of different sets. Comparing the resulting predictions to human judgments of representativeness provides a test of this measure with naturalistic stimuli, and illustrates how databases that are more commonly used in computer vision and machine learning can be used to evaluate psychological theories.\n",
      "Utilizing lime: Asynchronous Binding\n",
      "Historically, connectionist systems have not excelled at representing and manipulating complex structures. How can a system composed of simple neuron-like computing elements encode complex relations? Recently, researchers have begun to appreciate that representations can extend in both time and space. Many researchers have proposed that the synchronous firing of units can encode complex representations. I identify the limitations of this approach and present an asynchronous model of binding that effectively represents complex structures. The asynchronous model extends the synchronous approach. I argue that our cognitive architecture utilizes a similar mechanism.\n",
      "Statistical Models of Linear and Nonlinear Contextual Interactions in Early Visual Processing\n",
      "A central hypothesis about early visual processing is that it represents inputs in a coordinate system matched to the statistics of natural scenes. Simple versions of this lead to Gabor-like receptive fields and divisive gain modulation from local surrounds; these have led to influential neural and psychological models of visual processing. However, these accounts are based on an incomplete view of the visual context surrounding each point. Here, we consider an approximate model of linear and non-linear correlations between the responses of spatially distributed Gabor-like receptive fields, which, when trained on an ensemble of natural scenes, unifies a range of spatial context effects. The full model accounts for neural surround data in primary visual cortex (V1), provides a statistical foundation for perceptual phenomena associated with Li's (2002) hypothesis that V1 builds a saliency map, and fits data on the tilt illusion.\n",
      "Catastrophic Interference in Human Motor Learning\n",
      "Biological sensorimotor systems are not static maps that transform input (sensory information) into output (motor behavior). Evidence from many lines of research suggests that their representations are plastic, experience-dependent entities. While this plasticity is essential for flexible behavior, it presents the nervous system with difficult organizational challenges. If the sensorimotor system adapts itself to perform well under one set of circumstances, will it then perform poorly when placed in an environment with different demands (negative transfer)? Will a later experience-dependent change undo the benefits of previous learning (catastrophic interference)? We explore the first question in a separate paper in this volume (Shadmehr et al. 1995). Here we present psychophysical and computational results that explore the question of catastrophic interference in the context of a dynamic motor learning task. Under some conditions, subjects show evidence of catastrophic interference. Under other conditions, however, subjects appear to be immune to its effects. These results suggest that motor learning can undergo a process of consolidation. Modular neural networks are well suited for the demands of learning multiple input/output mappings. By incorporating the notion of fast- and slow-changing connections into a modular architecture, we were able to account for the psychophysical results.\n",
      "Firing rate predictions in optimal balanced networks\n",
      "How are firing rates in a spiking network related to neural input, connectivity and network function? This is an important problem because firing rates are a key measure of network activity, in both the study of neural computation and neural network dynamics. However, it is a difficult problem, because the spiking mechanism of individual neurons is highly non-linear, and these individual neurons interact strongly through connectivity. We develop a new technique for calculating firing rates in optimal balanced networks. These are particularly interesting networks because they provide an optimal spike-based signal representation while producing cortex-like spiking activity through a dynamic balance of excitation and inhibition. We can calculate firing rates by treating balanced network dynamics as an algorithm for optimising signal representation. We identify this algorithm and then calculate firing rates by finding the solution to the algorithm. Our firing rate calculation relates network firing rates directly to network input, connectivity and function. This allows us to explain the function and underlying mechanism of tuning curves in a variety of systems.\n",
      "Human and Ideal Observers for Detecting Image Curves\n",
      "This paper compares the ability of human observers to detect target image curves with that of an ideal observer. The target curves are sampled from a generative model which specifies (probabilistically) the geometry and local intensity properties of the curve. The ideal observer performs Bayesian inference on the generative model using MAP estimation. Varying the probability model for the curve geometry enables us investigate whether human performance is best for target curves that obey specific shape statistics, in particular those observed on natural shapes. Experiments are performed with data on both rectangular and hexagonal lattices. Our results show that human observers' performance approaches that of the ideal observer and are, in general, closest to the ideal for conditions where the target curve tends to be straight or similar to natural statistics on curves. This suggests a bias of human observers towards straight curves and natural statistics.\n",
      "Facial Memory Is Kernel Density Estimation (Almost)\n",
      "We compare the ability of three exemplar-based memory models, each using three different stimulus representations, to account for the probability a human subject responded old in an old/new facial memory experiment. The models are 1) the Generalized Context Model, 2) SimSample, a probabilistic sampling model, and 3) MMOM, a novel model related to kernel density estimation that explicitly encodes stimulus distinctiveness. The representations are 1) positions of stimuli in MDS face space, 2) projections of test faces onto the eigenfaces of the study set, and 3) a representation based on response to a grid of Gabor filter jets. Of the 9 model/representation combinations, only the distinctiveness model in MDS space predicts the observed morph familiarity inversion effect, in which the subjects' false alarm rate for morphs between similar faces is higher than their hit rate for many of the studied faces. This evidence is consistent with the hypothesis that human memory for faces is a kernel density estimation task, with the caveat that distinctive faces require larger kernels than do typical faces.\n",
      "Bayesian inference for low rank spatiotemporal neural receptive fields\n",
      "The receptive field (RF) of a sensory neuron describes how the neuron integrates sensory stimuli over time and space. In typical experiments with naturalistic or flickering spatiotemporal stimuli, RFs are very high-dimensional, due to the large number of coefficients needed to specify an integration profile across time and space. Estimating these coefficients from small amounts of data poses a variety of challenging statistical and computational problems. Here we address these challenges by developing Bayesian reduced rank regression methods for RF estimation. This corresponds to modeling the RF as a sum of space-time separable (i.e., rank-1) filters. This approach substantially reduces the number of parameters needed to specify the RF, from 1K-10K down to mere 100s in the examples we consider, and confers substantial benefits in statistical power and computational efficiency. We introduce a novel prior over low-rank RFs using the restriction of a matrix normal prior to the manifold of low-rank matrices, and use row and column covariances to obtain sparse, smooth, localized estimates of the spatial and temporal RF components. We develop two methods for inference in the resulting hierarchical model: (1) a fully Bayesian method using blocked-Gibbs sampling; and (2) a fast, approximate method that employs alternating ascent of conditional marginal likelihoods. We develop these methods for Gaussian and Poisson noise models, and show that low-rank estimates substantially outperform full rank estimates using neural data from retina and V1.\n",
      "Topographic Map Formation by Silicon Growth Cones\n",
      "We describe a self-configuring neuromorphic chip that uses a model of activity-dependent axon remodeling to automatically wire topographic maps based solely on input correlations. Axons are guided by growth cones, which arc modeled in analog VLSI for the first time. Growth cones migrate up neurotropin gradients, which arc represented by charge diffusing in transistor channels. Virtual axons move by rerouting address-events. We refined an initially gross topographic projection by simulating retinal wave input.\n",
      "Cross-Spectral Factor Analysis\n",
      "In neuropsychiatric disorders such as schizophrenia or depression, there is often a disruption in the way that regions of the brain synchronize with one another. To facilitate understanding of network-level synchronization between brain regions, we introduce a novel model of multisite low-frequency neural recordings, such as local field potentials (LFPs) and electroencephalograms (EEGs). The proposed model, named Cross-Spectral Factor Analysis (CSFA), breaks the observed signal into factors defined by unique spatio-spectral properties. These properties are granted to the factors via a Gaussian process formulation in a multiple kernel learning framework. In this way, the LFP signals can be mapped to a lower dimensional space in a way that retains information of relevance to neuroscientists. Critically, the factors are interpretable. The proposed approach empirically allows similar performance in classifying mouse genotype and behavioral context when compared to commonly used approaches that lack the interpretability of CSFA. We also introduce a semi-supervised approach, termed discriminative CSFA (dCSFA). CSFA and dCSFA provide useful tools for understanding neural dynamics, particularly by aiding in the design of causal follow-up experiments.\n",
      "Organizing recurrent network dynamics by task-computation to enable continual learning\n",
      "Biological systems face dynamic environments that require continual learning. It is not well understood how these systems balance the tension between flexibility for learning and robustness for memory of previous behaviors. Continual learning without catastrophic interference also remains a challenging problem in machine learning. Here, we develop a novel learning rule designed to minimize interference between sequentially learned tasks in recurrent networks. Our learning rule preserves network dynamics within activity-defined subspaces used for previously learned tasks. It encourages dynamics associated with new tasks that might otherwise interfere to instead explore orthogonal subspaces, and it allows for reuse of previously established dynamical motifs where possible. Employing a set of tasks used in neuroscience, we demonstrate that our approach successfully eliminates catastrophic interference and offers a substantial improvement over previous continual learning algorithms. Using dynamical systems analysis, we show that networks trained using our approach can reuse similar dynamical structures across similar tasks. This possibility for shared computation allows for faster learning during sequential training. Finally, we identify organizational differences that emerge when training tasks sequentially versus simultaneously.\n",
      "CogLTX: Applying BERT to Long Texts\n",
      "None\n",
      "An Efficient P300-based Brain-Computer Interface with Minimal Calibration Time\n",
      "In this paper we propose a new design for P300-based BCI, in order to reduce the calibration time of the system. Our BCI is based on Regularized Canonical Correlation Analysis for feature extraction and Regularized Linear Discriminant Analysis for classification. Evaluations suggested that this design can reach good P300 detection performances while using much less training examples than current approaches, hence effectively reducing the calibration time.\n",
      "Homeostasis in a Silicon Integrate and Fire Neuron\n",
      "In this work, we explore homeostasis in a silicon integrate-and-fire neuron. The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. Homeostasis is implemented via two schemes. One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. The second scheme adapts the synaptic depending on the neuron's activity. The threshold is lowered if the neuron's activity decreases over a long time and is increased for prolonged increase in postsynaptic activity. Both these mechanisms for adaptation use floating-gate technology. The results shown here are measured from a chip fabricated in a 2-µm CMOS process.\n",
      "Synchrony Detection by Analogue VLSI Neurons with Bimodal STDP Synapses\n",
      "We present test results from spike-timing correlation learning experiments carried out with silicon neurons with STDP (Spike Timing Dependent Plasticity) synapses. The weight change scheme of the STDP synapses can be set to either weight-independent or weight-dependent mode. We present results that characterise the learning window implemented for both modes of operation. When presented with spike trains with different types of synchronisation the neurons develop bimodal weight distributions. We also show that a 2-layered network of silicon spiking neurons with STDP synapses can perform hierarchical synchrony detection.\n",
      "Receptive Fields without Spike-Triggering\n",
      "Stimulus selectivity of sensory neurons is often characterized by estimating their receptive field properties such as orientation selectivity. Receptive fields are usually derived from the mean (or covariance) of the spike-triggered stimulus ensemble. This approach treats each spike as an independent message but does not take into account that information might be conveyed through patterns of neural activity that are distributed across space or time. Can we find a concise description for the processing of a whole population of neurons analogous to the receptive field for single neurons? Here, we present a generalization of the linear receptive field which is not bound to be triggered on individual spikes but can be meaningfully linked to distributed response patterns. More precisely, we seek to identify those stimulus features and the corresponding patterns of neural activity that are most reliably coupled. We use an extension of reverse-correlation methods based on canonical correlation analysis. The resulting population receptive fields span the subspace of stimuli that is most informative about the population response. We evaluate our approach using both neuronal models and multi-electrode recordings from rabbit retinal ganglion cells. We show how the model can be extended to capture nonlinear stimulus-response relationships using kernel canonical correlation analysis, which makes it possible to test different coding mechanisms. Our technique can also be used to calculate receptive fields from multi-dimensional neural measurements such as those obtained from dynamic imaging methods.\n",
      "Simulation of Optimal Movements Using the Minimum-Muscle-Tension-Change Model\n",
      "This work discusses various optimization techniques which were proposed in models for controlling arm movements. In particular, the minimum-muscle-tension-change model is investigated. A dynamic simulator of the monkey's arm, including seventeen single and double joint muscles, is utilized to generate horizontal hand movements. The hand trajectories produced by this algorithm are discussed.\n",
      "Perceptual Metamers in Stereoscopic Vision\n",
      "Theories of cue combination suggest the possibility of constructing visual stimuli that evoke different patterns of neural activity in areas of the brain, but that cannot be distinguished by any behavioral measure of perception. Such stimuli, if they exist, would be interesting for two reasons. First, one could know that none of the differences between the stimuli survive past the computations used to build the percepts. Second, it can be difficult to distinguish stimulus-driven components of measured neural activity from top-down components (such as those due to the interestingness of the stimuli). Changing the stimulus without changing the percept could be exploited to measure the stimulus-driven activity. Here we describe stimuli in which vertical and horizontal disparities trade during the construction of percepts of slanted surfaces, yielding stimulus equivalence classes. Equivalence class membership changed after a change of vergence eye posture alone, without changes to the retinal images. A formal correspondence can be drawn between these perceptual metamers and more familiar sensory metamers such as color metamers.\n",
      "Natural Dolphin Echo Recognition Using an Integrator Gateway Network\n",
      "We have been studying the performance of a bottlenosed dolphin on a delayed matching-to-sample task to gain insight into the processes and mechanisms that the animal uses during echolocation. The dolphin recognizes targets by emitting natural sonar signals and listening to the echoes that return. This paper describes a novel neural network architecture, called an integrator gateway network, that we have developed to account for this performance. The integrator gateway network combines information from multiple echoes to classify targets with about 90% accuracy. In contrast, a standard backpropagation network performed with only about 63% accuracy.\n",
      "Spikernels: Embedding Spiking Neurons in Inner-Product Spaces\n",
      "Inner-product operators, often referred to as kernels in statistical learning, define a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efficient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand movement velocities from cortical recordings. In all of our experiments all the kernels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance.\n",
      "Finding the Key to a Synapse\n",
      "Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature.\n",
      "A Reinforcement Learning Theory for Homeostatic Regulation\n",
      "Reinforcement learning models address animal's behavioral adaptation to its changing environment, and are based on the assumption that Pavlovian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are concerned with behavioral adaptation in response to the state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that integrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identical. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.\n",
      "Bayesian model learning in human visual perception\n",
      "Humans make optimal perceptual decisions in noisy and ambiguous conditions. Computations underlying such optimal behavior have been shown to rely on probabilistic inference according to generative models whose structure is usually taken to be known a priori. We argue that Bayesian model selection is ideal for inferring similar and even more complex model structures from experience. We find in experiments that humans learn subtle statistical properties of visual scenes in a completely unsupervised manner. We show that these findings are well captured by Bayesian model learning within a class of models that seek to explain observed variables by independent hidden causes.\n",
      "Learning to classify complex patterns using a VLSI network of spiking neurons\n",
      "We propose a compact, low power VLSI network of spiking neurons which can learn to classify complex patterns of mean firing rates on-line and in real-time. The network of integrate-and-fire neurons is connected by bistable synapses that can change their weight using a local spike-based plasticity mechanism. Learning is supervised by a teacher which provides an extra input to the output neurons during training. The synaptic weights are updated only if the current generated by the plastic synapses does not match the output desired by the teacher (as in the perceptron learning rule). We present experimental results that demonstrate how this VLSI network is able to robustly classify uncorrelated linearly separable spatial patterns of mean firing rates.\n",
      "Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks\n",
      "It is open how neurons in the brain are able to learn without supervision to discriminate between spatio-temporal firing patterns of presynaptic neurons. We show that a known unsupervised learning algorithm, Slow Feature Analysis (SFA), is able to acquire the classification capability of Fisher's Linear Discriminant (FLD), a powerful algorithm for supervised learning, if temporally adjacent samples are likely to be from the same class. We also demonstrate that it enables linear readout neurons of cortical microcircuits to learn the detection of repeating firing patterns within a stream of spike trains with the same firing statistics, as well as discrimination of spoken digits, in an unsupervised manner.\n",
      "Selective Attention for Handwritten Digit Recognition\n",
      "Completely parallel object recognition is NP-complete. Achieving a recognizer with feasible complexity requires a compromise between parallel and sequential processing where a system selectively focuses on parts of a given image, one after another. Successive fixations are generated to sample the image and these samples are processed and abstracted to generate a temporal context in which results are integrated over time. A computational model based on a partially recurrent feedforward network is proposed and made credible by testing on the real-world problem of recognition of handwritten digits with encouraging results.\n",
      "Channel Noise in Excitable Neural Membranes\n",
      "Stochastic fluctuations of voltage-gated ion channels generate current and voltage noise in neuronal membranes. This noise may be a critical determinant of the efficacy of information processing within neural systems. Using Monte-Carlo simulations, we carry out a systematic investigation of the relationship between channel kinetics and the resulting membrane voltage noise using a stochastic Markov version of the Mainen-Sejnowski model of dendritic excitability in cortical neurons. Our simulations show that kinetic parameters which lead to an increase in membrane excitability (increasing channel densities, decreasing temperature) also lead to an increase in the magnitude of the subthreshold voltage noise. Noise also increases as the membrane is depolarized from rest towards threshold. This suggests that channel fluctuations may interfere with a neuron's ability to function as an integrator of its synaptic inputs and may limit the reliability and precision of neural information processing.\n",
      "An MEG Study of Response Latency and Variability in the Human Visual System During a Visual-Motor Integration Task\n",
      "Human reaction times during sensory-motor tasks vary considerably. To begin to understand how this variability arises, we examined neuronal populational response time variability at early versus late visual processing stages. The conventional view is that precise temporal information is gradually lost as information is passed through a layered network of mean-rate We tested in humans whether neuronal populations at different processing stages behave like mean-rate units. A blind source separation algorithm was applied to MEG signals from sensory-motor integration tasks. Response time latency and variability for multiple visual sources were estimated by detecting single-trial stimulus-locked events for each source. In two subjects tested on four visual reaction time tasks, we reliably identified sources belonging to early and late visual processing stages. The standard deviation of response latency was smaller for early rather than late processing stages. This supports the hypothesis that human populational response time variability increases from early to late visual processing stages.\n",
      "Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex\n",
      "How do cortical neurons represent the acoustic environment? This question is often addressed by probing with simple stimuli such as clicks or tone pips. Such stimuli have the advantage of yielding easily interpreted answers, but have the disadvantage that they may fail to uncover complex or higher-order neuronal response properties.\n",
      "\n",
      "Here we adopt an alternative approach, probing neuronal responses with complex acoustic stimuli, including animal vocalizations and music. We have used in vivo whole cell methods in the rat auditory cortex to record subthreshold membrane potential fluctuations elicited by these stimuli. Whole cell recording reveals the total synaptic input to a neuron from all the other neurons in the circuit, instead of just its output—a sparse binary spike train—as in conventional single unit physiological recordings. Whole cell recording thus provides a much richer source of information about the neuron's response.\n",
      "\n",
      "Many neurons responded robustly and reliably to the complex stimuli in our ensemble. Here we analyze the linear component—the spectro-temporal receptive field (STRF)—of the transformation from the sound (as represented by its time-varying spectrogram) to the neuron's membrane potential. We find that the STRF has a rich dynamical structure, including excitatory regions positioned in general accord with the prediction of the simple tuning curve. We also find that in many cases, much of the neuron's response, although deterministically related to the stimulus, cannot be predicted by the linear component, indicating the presence of as-yet-uncharacterized nonlinear response properties.\n",
      "How Prior Probability Influences Decision Making: A Unifying Probabilistic Model\n",
      "How does the brain combine prior knowledge with sensory evidence when making decisions under uncertainty? Two competing descriptive models have been proposed based on experimental data. The first posits an additive offset to a decision variable, implying a static effect of the prior. However, this model is inconsistent with recent data from a motion discrimination task involving temporal integration of uncertain sensory evidence. To explain this data, a second model has been proposed which assumes a time-varying influence of the prior. Here we present a normative model of decision making that incorporates prior knowledge in a principled way. We show that the additive offset model and the time-varying prior model emerge naturally when decision making is viewed within the framework of partially observable Markov decision processes (POMDPs). Decision making in the model reduces to (1) computing beliefs given observations and prior information in a Bayesian manner, and (2) selecting actions based on these beliefs to maximize the expected sum of future rewards. We show that the model can explain both data previously explained using the additive offset model as well as more recent data on the time-varying influence of prior knowledge on decision making.\n",
      "Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics\n",
      "How are the spatial patterns of spontaneous and evoked population responses related? We study the impact of connectivity on the spatial pattern of fluctuations in the input-generated response, by comparing the distribution of evoked and intrinsically generated activity across the different units of a neural network. We develop a complementary approach to principal component analysis in which separate high-variance directions are derived for each input condition. We analyze subspace angles to compute the difference between the shapes of trajectories corresponding to different network states, and the orientation of the low-dimensional subspaces that driven trajectories occupy within the full space of neuronal activity. In addition to revealing how the spatiotemporal structure of spontaneous activity affects input-evoked responses, these methods can be used to infer input selectivity induced by network dynamics from experimentally accessible measures of spontaneous activity (e.g. from voltage- or calcium-sensitive optical imaging experiments). We conclude that the absence of a detailed spatial map of afferent inputs and cortical connectivity does not limit our ability to design spatially extended stimuli that evoke strong responses.\n",
      "Analog Cochlear Model for Multiresolution Speech Analysis\n",
      "This paper discusses the parameterization of speech by an analog cochlear model. The tradeoff between time and frequency resolution is viewed as the fundamental difference between conventional spectrographic analysis and cochlear signal processing for broadband, rapid-changing signals. The model's response exhibits a wavelet-like analysis in the scale domain that preserves good temporal resolution; the frequency of each spectral component in a broadband signal can be accurately determined from the interpeak intervals in the instantaneous firing rates of auditory fibers. Such properties of the cochlear model are demonstrated with natural speech and synthetic complex signals.\n",
      "EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection\n",
      "Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject's intent. An elegant approach to improve the accuracy of BCIs consists in a verification procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment confirms the previously reported presence of a new kind of ErrP. These Interaction exhibit a first sharp negative peak followed by a positive peak and a second broader negative peak (~290, ~350 and ~470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classifier embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject's intent while trying to mentally drive the cursor of 73.1%. These results show that it's possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the brain-computer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex.\n",
      "A computational model of hippocampal function in trace conditioning\n",
      "We introduce a new reinforcement-learning model for the role of the hippocampus in classical conditioning, focusing on the differences between trace and delay conditioning. In the model, all stimuli are represented both as unindividuated wholes and as a series of temporal elements with varying delays. These two stimulus representations interact, producing different patterns of learning in trace and delay conditioning. The model proposes that hippocampal lesions eliminate long-latency temporal elements, but preserve short-latency temporal elements. For trace conditioning, with no contiguity between cue and reward, these long-latency temporal elements are necessary for learning adaptively timed responses. For delay conditioning, the continued presence of the cue supports conditioned responding, and the short-latency elements suppress responding early in the cue. In accord with the empirical data, simulated hippocampal damage impairs trace conditioning, but not delay conditioning, at medium-length intervals. With longer intervals, learning is impaired in both procedures, and, with shorter intervals, in neither. In addition, the model makes novel predictions about the response topography with extended cues or post-training lesions. These results demonstrate how temporal contiguity, as in delay conditioning, changes the timing problem faced by animals, rendering it both easier and less susceptible to disruption by hippocampal lesions.\n",
      "Perceiving Complex Visual Scenes: An Oscillator Neural Network Model that Integrates Selective Attention, Perceptual Organisation, and Invariant Recognition\n",
      "Which processes underly our ability to quickly recognize familiar objects within a complex visual input scene? In this paper an implemented neural network model is described that attempts to specify how selective visual attention, perceptual organisation, and invariance transformations might work together in order to segment, select, and recognize objects out of complex input scenes containing multiple, possibly overlapping objects. Retinotopically organized feature maps serve as input for two main processing routes: the 'where-pathway' dealing with location information and the 'what-pathway' computing the shape and attributes of objects. A location-based attention mechanism operates on an early stage of visual processing selecting a contigous region of the visual field for preferential processing. Additionally, location-based attention plays an important role for invariant object recognition controling appropriate normalization processes within the what-pathway. Object recognition is supported through the segmentation of the visual field into distinct entities. In order to represent different segmented entities at the same time, the model uses an oscillatory binding mechanism. Connections between the where-pathway and the what-pathway lead to a flexible cooperation between different functional subsystems producing an overall behavior which is consistent with a variety of psychophysical data.\n",
      "Bayesian active learning with localized priors for fast receptive field characterization\n",
      "Active learning methods can dramatically improve the yield of neurophysiology experiments by adaptively selecting stimuli to probe a neuron's receptive field (RF). Bayesian active learning methods specify a posterior distribution over the RF given the data collected so far in the experiment, and select a stimulus on each time step that maximally reduces posterior uncertainty. However, existing methods tend to employ simple Gaussian priors over the RF and do not exploit uncertainty at the level of hyperparameters. Incorporating this uncertainty can substantially speed up active learning, particularly when RFs are smooth, sparse, or local in space and time. Here we describe a novel framework for active learning under hierarchical, conditionally Gaussian priors. Our algorithm uses sequential Markov Chain Monte Carlo sampling (particle filtering with MCMC) to construct a mixture-of-Gaussians representation of the RF posterior, and selects optimal stimuli using an approximate infomax criterion. The core elements of this algorithm are parallelizable, making it computationally efficient for real-time experiments. We apply our algorithm to simulated and real neural data, and show that it can provide highly accurate receptive field estimates from very limited data, even with a small number of hyperparameter samples.\n",
      "Population Decoding Based on an Unfaithful Model\n",
      "We study a population decoding paradigm in which the maximum likelihood inference is based on an unfaithful decoding model (UMLI). This is usually the case for neural population decoding because the encoding process of the brain is not exactly known, or because a simplified decoding model is preferred for saving computational cost. We consider an unfaithful decoding model which neglects the pair-wise correlation between neuronal activities, and prove that UMLI is asymptotically efficient when the neuronal correlation is uniform or of limited-range. The performance of UMLI is compared with that of the maximum likelihood inference based on a faithful model and that of the center of mass decoding method. It turns out that UMLI has advantages of decreasing the computational complexity remarkablely and maintaining a high-level decoding accuracy at the same time. The effect of correlation on the decoding accuracy is also discussed.\n",
      "Learning Efficient Auditory Codes Using Spikes Predicts Cochlear Filters\n",
      "The representation of acoustic signals at the cochlear nerve must serve a wide range of auditory tasks that require exquisite sensitivity in both time and frequency. Lewicki (2002) demonstrated that many of the filtering properties of the cochlea could be explained in terms of efficient coding of natural sounds. This model, however, did not account for properties such as phase-locking or how sound could be encoded in terms of action potentials. Here, we extend this theoretical approach with algorithm for learning efficient auditory codes using a spiking population code. Here, we propose an algorithm for learning efficient auditory codes using a theoretical model for coding sound in terms of spikes. In this model, each spike encodes the precise time position and magnitude of a localized, time varying kernel function. By adapting the kernel functions to the statistics natural sounds, we show that, compared to conventional signal representations, the spike code achieves far greater coding efficiency. Furthermore, the inferred kernels show both striking similarities to measured cochlear filters and a similar bandwidth versus frequency dependence.\n",
      "Spherical Units as Dynamic Consequential Regions: Implications for Attention, Competition and Categorization\n",
      "Spherical Units can be used to construct dynamic reconfigurable consequential regions, the geometric bases for Shepard's (1987) theory of stimulus generalization in animals and humans. We derive from Shepard's (1987) generalization theory a particular multi-layer network with dynamic (centers and radii) spherical regions which possesses a specific mass function (Cauchy). This learning model generalizes the configural-cue network model (Gluck & Bower 1988): (1) configural cues can be learned and do not require pre-wiring the power-set of cues, (2) Consequential regions are continuous rather than discrete and (3) Competition amoungst receptive fields is shown to be increased by the global extent of a particular mass function (Cauchy). We compare other common mass functions (Gaussian; used in models of Moody & Darken; 1989, Krushke, 1990) or just standard backpropogation networks with hyperplane/logistic hidden units showing that neither fare as well as models of human generalization and learning.\n",
      "Wiring Optimization in the Brain\n",
      "The complexity of cortical circuits may be characterized by the number of synapses per neuron. We study the dependence of complexity on the fraction of the cortical volume that is made up of (that is, of axons and dendrites), and find that complexity is maximized when wire takes up about 60% of the cortical volume. This prediction is in good agreement with experimental observations. A consequence of our arguments is that any rearrangement of neurons that takes more wire would sacrifice computational power.\n",
      "A Holistic Approach to Compositional Semantics: a connectionist model and robot experiments\n",
      "We present a novel connectionist model for acquiring the semantics of a simple language through the behavioral experiences of a real robot. We focus on the compositionality of semantics, a fundamental characteristic of human language, which is the ability to understand the meaning of a sentence as a combination of the meanings of words. We also pay much attention to the embodiment of a robot, which means that the robot should acquire semantics which matches its body, or sensory-motor system. The essential claim is that an embodied compositional semantic representation can be self-organized from generalized correspondences between sentences and behavioral patterns. This claim is examined and confirmed through simple experiments in which a robot generates corresponding behaviors from unlearned sentences by analogy with the correspondences between learned sentences and behaviors.\n",
      "An Analog Implementation of the Constant Average Statistics Constraint For Sensor Calibration\n",
      "We use the constant statistics constraint to calibrate an array of sensors that contains gain and offset variations. This algorithm has been mapped to analog hardware and designed and fabricated with a 2µm CMOS technology. Measured results from the chip show that the system achieves invariance to gain and offset variations of the input signal.\n",
      "Learning with Temporal Derivatives in Pulse-Coded Neuronal Systems\n",
      "A number of learning models have recently been proposed which involve calculations of temporal differences (or derivatives in continuous-time models). These models, like most adaptive network models, are formulated in terms of frequency (or activation), a useful abstraction of neuronal firing rates. To more precisely evaluate the implications of a neuronal model, it may be preferable to develop a model which transmits discrete pulse-coded information. We point out that many functions and properties of neuronal processing and learning may depend, in subtle ways, on the pulse-coded nature of the information coding and transmission properties of neuron systems. When compared to formulations in terms of activation, computing with temporal derivatives (or differences) as proposed by Kosko (1986), Klopf (1988), and Sutton (1988), is both more stable and easier when reformulated for a more neuronally realistic pulse-coded system. In reformulating these models in terms of pulse-coding, our motivation has been to enable us to draw further parallels and connections between real-time behavioral models of learning and biological circuit models of the substrates underlying learning and memory.\n",
      "Rational inference of relative preferences\n",
      "Statistical decision theory axiomatically assumes that the relative desirability of different options that humans perceive is well described by assigning them option-specific scalar utility functions. However, this assumption is refuted by observed human behavior, including studies wherein preferences have been shown to change systematically simply through variation in the set of choice options presented. In this paper, we show that interpreting desirability as a relative comparison between available options at any particular decision instance results in a rational theory of value-inference that explains heretofore intractable violations of rational choice behavior in human subjects. Complementarily, we also characterize the conditions under which a rational agent selecting optimal options indicated by dynamic value inference in our framework will behave identically to one whose preferences are encoded using a static ordinal utility function.\n",
      "EEG-GRAPH: A factor-graph-based model for capturing spatial, temporal, and observational relationships in electroencephalograms\n",
      "This paper presents a probabilistic-graphical model that can be used to infer characteristics of instantaneous brain activity by jointly analyzing spatial and temporal dependencies observed in electroencephalograms (EEG). Specifically, we describe a factor-graph-based model with customized factor-functions defined based on domain knowledge, to infer pathologic brain activity with the goal of identifying seizure-generating brain regions in epilepsy patients. We utilize an inference technique based on the graph-cut algorithm to exactly solve graph inference in polynomial time. We validate the model by using clinically collected intracranial EEG data from 29 epilepsy patients to show that the model correctly identifies seizure-generating brain regions. Our results indicate that our model outperforms two conventional approaches used for seizure-onset localization (5-7% better AUC: 0.72, 0.67, 0.65) and that the proposed inference technique provides 3-10% gain in AUC (0.72, 0.62, 0.69) compared to sampling-based alternatives.\n",
      "Analytical Solution of Spike-timing Dependent Plasticity Based on Synaptic Biophysics\n",
      "Spike timing plasticity (STDP) is a special form of synaptic plasticity where the relative timing of post- and presynaptic activity determines the change of the synaptic weight. On the postsynaptic side, active back-propagating spikes in dendrites seem to play a crucial role in the induction of spike timing dependent plasticity. We argue that postsynaptically the temporal change of the membrane potential determines the weight change. Coming from the presynaptic side induction of STDP is closely related to the activation of NMDA channels. Therefore, we will calculate analytically the change of the synaptic weight by correlating the derivative of the membrane potential with the activity of the NMDA channel. Thus, for this calculation we utilise biophysical variables of the physiological cell. The final result shows a weight change curve which conforms with measurements from biology. The positive part of the weight change curve is determined by the NMDA activation. The negative part of the weight change curve is determined by the membrane potential change. Therefore, the weight change curve should change its shape depending on the distance from the soma of the postsynaptic cell. We find temporally asymmetric weight change close to the soma and temporally symmetric weight change in the distal dendrite.\n",
      "Bayesian Belief Polarization\n",
      "Empirical studies have documented cases of belief polarization, where two people with opposing prior beliefs both strengthen their beliefs after observing the same evidence. Belief polarization is frequently offered as evidence of human irrationality, but we demonstrate that this phenomenon is consistent with a fully Bayesian approach to belief revision. Simulation results indicate that belief polarization is not only possible but relatively common within the set of Bayesian models that we consider.\n",
      "Principles of real-time computing with feedback applied to cortical microcircuit models\n",
      "The network topology of neurons in the brain exhibits an abundance of feedback connections, but the computational function of these feedback connections is largely unknown. We present a computational theory that characterizes the gain in computational power achieved through feedback in dynamical systems with fading memory. It implies that many such systems acquire through feedback universal computational capabilities for analog computing with a non-fading memory. In particular, we show that feedback enables such systems to process time-varying input streams in diverse ways according to rules that are implemented through internal states of the dynamical system. In contrast to previous attractor-based computational models for neural networks, these flexible internal states are high-dimensional attractors of the circuit dynamics, that still allow the circuit state to absorb new information from online input streams. In this way one arrives at novel models for working memory, integration of evidence, and reward expectation in cortical circuits. We show that they are applicable to circuits of conductance-based Hodgkin-Huxley (HH) neurons with high levels of noise that reflect experimental data on in-vivo conditions.\n",
      "Neurally Plausible Reinforcement Learning of Working Memory Tasks\n",
      "A key function of brains is undoubtedly the abstraction and maintenance of information from the environment for later use. Neurons in association cortex play an important role in this process: by learning these neurons become tuned to relevant features and represent the information that is required later as a persistent elevation of their activity [1]. It is however not well known how such neurons acquire these task-relevant working memories. Here we introduce a biologically plausible learning scheme grounded in Reinforcement Learning (RL) theory [2] that explains how neurons become selective for relevant information by trial and error learning. The model has memory units which learn useful internal state representations to solve working memory tasks by transforming partially observable Markov decision problems (POMDP) into MDPs. We propose that synaptic plasticity is guided by a combination of attentional feedback signals from the action selection stage to earlier processing levels and a globally released neuromodulatory signal. Feedback signals interact with feedforward signals to form synaptic tags at those connections that are responsible for the stimulus-response mapping. The neuromodulatory signal interacts with tagged synapses to determine the sign and strength of plasticity. The learning scheme is generic because it can train networks in different tasks, simply by varying inputs and rewards. It explains how neurons in association cortex learn to 1) temporarily store task-relevant information in non-linear stimulus-response mapping tasks [1, 3, 4] and 2) learn to optimally integrate probabilistic evidence for perceptual decision making [5, 6].\n",
      "Information Rates and Optimal Decoding in Large Neural Populations\n",
      "Many fundamental questions in theoretical neuroscience involve optimal decoding and the computation of Shannon information rates in populations of spiking neurons. In this paper, we apply methods from the asymptotic theory of statistical inference to obtain a clearer analytical understanding of these quantities. We find that for large neural populations carrying a finite total amount of information, the full spiking population response is asymptotically as informative as a single observation from a Gaussian process whose mean and covariance can be characterized explicitly in terms of network and single neuron properties. The Gaussian form of this asymptotic sufficient statistic allows us in certain cases to perform optimal Bayesian decoding by simple linear transformations, and to obtain closed-form expressions of the Shannon information carried by the network. One technical advantage of the theory is that it may be applied easily even to non-Poisson point process network models; for example, we find that under some conditions, neural populations with strong history-dependent (non-Poisson) effects carry exactly the same information as do simpler equivalent populations of non-interacting Poisson neurons with matched firing rates. We argue that our findings help to clarify some results from the recent literature on neural decoding and neuroprosthetic design.\n",
      "A model of transparent motion and non-transparent motion aftereffects\n",
      "A model of human motion perception is presented. The model contains two stages of direction selective units. The first stage contains broadly tuned units, while the second stage contains units that are narrowly tuned. The model accounts for the motion aftereffect through adapting units at the first stage and inhibitory interactions at the second stage. The model explains how two populations of dots moving in slightly different directions are perceived as a single population moving in the direction of the vector sum, and how two populations moving in strongly different directions are perceived as transparent motion. The model also explains why the motion aftereffect in both cases appears as non-transparent motion.\n",
      "Predicting Speech Intelligibility from a Population of Neurons\n",
      "A major issue in evaluating speech enhancement and hearing compensation algorithms is to come up with a suitable metric that predicts intelligibility as judged by a human listener. Previous methods such as the widely used Speech Transmission Index (STI) fail to account for masking effects that arise from the highly nonlinear cochlear transfer function. We therefore propose a Neural Articulation Index (NAI) that estimates speech intelligibility from the instantaneous neural spike rate over time, produced when a signal is processed by an auditory neural model. By using a well developed model of the auditory periphery and detection theory we show that human perceptual discrimination closely matches the modeled distortion in the instantaneous spike rates of the auditory nerve. In highly rippled frequency transfer conditions the NAI's prediction error is 8% versus the STI's prediction error of 10.8%.\n",
      "The rat as particle filter\n",
      "The core tenet of Bayesian modeling is that subjects represent beliefs as distributions over possible hypotheses. Such models have fruitfully been applied to the study of learning in the context of animal conditioning experiments (and analogously designed human learning tasks), where they explain phenomena such as retrospective revaluation that seem to demonstrate that subjects entertain multiple hypotheses simultaneously. However, a recent quantitative analysis of individual subject records by Gallistel and colleagues cast doubt on a very broad family of conditioning models by showing that all of the key features the models capture about even simple learning curves are artifacts of averaging over subjects. Rather than smooth learning curves (which Bayesian models interpret as revealing the gradual tradeoff from prior to posterior as data accumulate), subjects acquire suddenly, and their predictions continue to fluctuate abruptly. These data demand revisiting the model of the individual versus the ensemble, and also raise the worry that more sophisticated behaviors thought to support Bayesian models might also emerge artifactually from averaging over the simpler behavior of individuals. We suggest that the suddenness of changes in subjects’ beliefs (as expressed in conditioned behavior) can be modeled by assuming they are conducting inference using sequential Monte Carlo sampling with a small number of samples — one, in our simulations. Ensemble behavior resembles exact Bayesian models since, as in particle filters, it averages over many samples. Further, the model is capable of exhibiting sophisticated behaviors like retrospective revaluation at the ensemble level, even given minimally sophisticated individuals that do not track uncertainty from trial to trial. These results point to the need for more sophisticated experimental analysis to test Bayesian models, and refocus theorizing on the individual, while at the same time clarifying why the ensemble may be of interest.\n",
      "A dynamical model of priming and repetition blindness\n",
      "We describe a model of visual word recognition that accounts for several aspects of the temporal processing of sequences of briefly presented words. The model utilizes a new representation for written words, based on dynamic time warping and multidimensional scaling. The visual input passes through cascaded perceptual, comparison, and detection stages. We describe how these dynamical processes can account for several aspects of word recognition, including repetition priming and repetition blindness.\n",
      "Optimal Neural Codes for Control and Estimation\n",
      "Agents acting in the natural world aim at selecting appropriate actions based on noisy and partial sensory observations. Many behaviors leading to decision making and action selection in a closed loop setting are naturally phrased within a control theoretic framework. Within the framework of optimal Control Theory, one is usually given a cost function which is minimized by selecting a control law based on the observations. While in standard control settings the sensors are assumed fixed, biological systems often gain from the extra flexibility of optimizing the sensors themselves. However, this sensory adaptation is geared towards control rather than perception, as is often assumed. In this work we show that sensory adaptation for control differs from sensory adaptation for perception, even for simple control setups. This implies, consistently with recent experimental results, that when studying sensory adaptation, it is essential to account for the task being performed.\n",
      "A Bayesian Framework for Tilt Perception and Confidence\n",
      "The misjudgement of tilt in images lies at the heart of entertaining visual illusions and rigorous perceptual psychophysics. A wealth of findings has attracted many mechanistic models, but few clear computational principles. We adopt a Bayesian approach to perceptual tilt estimation, showing how a smoothness prior offers a powerful way of addressing much confusing data. In particular, we faithfully model recent results showing that confidence in estimation can be systematically affected by the same aspects of images that affect bias. Confidence is central to Bayesian modeling approaches, and is applicable in many other perceptual domains.\n",
      "Visual Cortex Circuitry and Orientation Tuning\n",
      "A simple mathematical model for the large-scale circuitry of primary visual cortex is introduced. It is shown that a basic cortical architecture of recurrent local excitation and lateral inhibition can account quantitatively for such properties as orientation tuning. The model can also account for such local effects as cross-orientation suppression. It is also shown that nonlocal state-dependent coupling between similar orientation patches, when added to the model, can satisfactorily reproduce such effects as non-local iso--orientation suppression, and non-local cross-orientation enhancement. Following this an account is given of perceptual phenomena involving object segmentation, such as popout, and the direct and indirect tilt illusions.\n",
      "What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach\n",
      "We study optimal image encoding based on a generative approach with non-linear feature combinations and explicit position encoding. By far most approaches to unsupervised learning of visual features, such as sparse coding or ICA, account for translations by representing the same features at different positions. Some earlier models used a separate encoding of features and their positions to facilitate invariant data encoding and recognition. All probabilistic generative models with explicit position encoding have so far assumed a linear superposition of components to encode image patches. Here, we for the first time apply a model with non-linear feature superposition and explicit position encoding for patches. By avoiding linear superpositions, the studied model represents a closer match to component occlusions which are ubiquitous in natural images. In order to account for occlusions, the non-linear model encodes patches qualitatively very different from linear models by using component representations separated into mask and feature parameters. We first investigated encodings learned by the model using artificial data with mutually occluding components. We find that the model extracts the components, and that it can correctly identify the occlusive components with the hidden variables of the model. On natural image patches, the model learns component masks and features for typical image components. By using reverse correlation, we estimate the receptive fields associated with the model's hidden units. We find many Gabor-like or globular receptive fields as well as fields sensitive to more complex structures. Our results show that probabilistic models that capture occlusions and invariances can be trained efficiently on image patches, and that the resulting encoding represents an alternative model for the neural encoding of images in the primary visual cortex.\n",
      "Timing and Partial Observability in the Dopamine System\n",
      "According to a series of influential models, dopamine (DA) neurons signal reward prediction error using a temporal-difference (TD) algorithm. We address a problem not convincingly solved in these accounts: how to maintain a representation of cues that predict delayed consequences. Our new model uses a TD rule grounded in partially observable semi-Markov processes, a formalism that captures two largely neglected features of DA experiments: hidden state and temporal variability. Previous models predicted rewards using a tapped delay line representation of sensory inputs; we replace this with a more active process of inference about the underlying state of the world. The DA system can then learn to map these inferred states to reward predictions using TD. The new model can explain previously vexing data on the responses of DA neurons in the face of temporal variability. By combining statistical model-based learning with a physiologically grounded TD theory, it also brings into contact with physiology some insights about behavior that had previously been confined to more abstract psychological models.\n",
      "Spiking and saturating dendrites differentially expand single neuron computation capacity\n",
      "The integration of excitatory inputs in dendrites is non-linear: multiple excitatory inputs can produce a local depolarization departing from the arithmetic sum of each input's response taken separately. If this depolarization is bigger than the arithmetic sum, the dendrite is spiking; if the depolarization is smaller, the dendrite is saturating. Decomposing a dendritic tree into independent dendritic spiking units greatly extends its computational capacity, as the neuron then maps onto a two layer neural network, enabling it to compute linearly non-separable Boolean functions (lnBFs). How can these lnBFs be implemented by dendritic architectures in practise? And can saturating dendrites equally expand computational capacity? To address these questions we use a binary neuron model and Boolean algebra. First, we confirm that spiking dendrites enable a neuron to compute lnBFs using an architecture based on the disjunctive normal form (DNF). Second, we prove that saturating dendrites as well as spiking dendrites enable a neuron to compute lnBFs using an architecture based on the conjunctive normal form (CNF). Contrary to a DNF-based architecture, in a CNF-based architecture, dendritic unit tunings do not imply the neuron tuning, as has been observed experimentally. Third, we show that one cannot use a DNF-based architecture with saturating dendrites. Consequently, we show that an important family of lnBFs implemented with a CNF-architecture can require an exponential number of saturating dendritic units, whereas the same family implemented with either a DNF-architecture or a CNF-architecture always require a linear number of spiking dendritic units. This minimization could explain why a neuron spends energetic resources to make its dendrites spike.\n",
      "Ocular Dominance and Patterned Lateral Connections in a Self-Organizing Model of the Primary Visual Cortex\n",
      "A neural network model for the self-organization of ocular dominance and lateral connections from binocular input is presented. The self-organizing process results in a network where (1) afferent weights of each neuron organize into smooth hill-shaped receptive fields primarily on one of the retinas, (2) neurons with common eye preference form connected, intertwined patches, and (3) lateral connections primarily link regions of the same eye preference. Similar self-organization of cortical structures has been observed experimentally in strabismic kittens. The model shows how patterned lateral connections in the cortex may develop based on correlated activity and explains why lateral connection patterns follow receptive field properties such as ocular dominance.\n",
      "Perfect Associative Learning with Spike-Timing-Dependent Plasticity\n",
      "Recent extensions of the Perceptron as the Tempotron and the Chronotron suggest that this theoretical concept is highly relevant for understanding networks of spiking neurons in the brain. It is not known, however, how the computational power of the Perceptron might be accomplished by the plasticity mechanisms of real synapses. Here we prove that spike-timing-dependent plasticity having an anti-Hebbian form for excitatory synapses as well as a spike-timing-dependent plasticity of Hebbian shape for inhibitory synapses are sufficient for realizing the original Perceptron Learning Rule if these respective plasticity mechanisms act in concert with the hyperpolarisation of the post-synaptic neurons. We also show that with these simple yet biologically realistic dynamics Tempotrons and Chronotrons are learned. The proposed mechanism enables incremental associative learning from a continuous stream of patterns and might therefore underly the acquisition of long term memories in cortex. Our results underline that learning processes in realistic networks of spiking neurons depend crucially on the interactions of synaptic plasticity mechanisms with the dynamics of participating neurons.\n",
      "Correlates of Attention in a Model of Dynamic Visual Recognition\n",
      "Given a set of objects in the visual field, how does the the visual system learn to attend to a particular object of interest while ignoring the rest? How are occlusions and background clutter so effortlessly discounted for when recognizing a familiar object? In this paper, we attempt to answer these questions in the context of a Kalman filter-based model of visual recognition that has previously proved useful in explaining certain neurophysiological phenomena such as endstopping and related extra-classical receptive field effects in the visual cortex. By using results from the field of robust statistics, we describe an extension of the Kalman filter model that can handle multiple objects in the visual field. The resulting robust Kalman filter model demonstrates how certain forms of attention can be viewed as an emergent property of the interaction between top-down expectations and bottom-up signals. The model also suggests functional interpretations of certain attention-related effects that have been observed in visual cortical neurons. Experimental results are provided to help demonstrate the ability of the model to perform robust segmentation and recognition of objects and image sequences in the presence of varying degrees of occlusions and clutter.\n",
      "Neuronal Adaptation for Sampling-Based Probabilistic Inference in Perceptual Bistability\n",
      "It has been argued that perceptual multistability reflects probabilistic inference performed by the brain when sensory input is ambiguous. Alternatively, more traditional explanations of multistability refer to low-level mechanisms such as neuronal adaptation. We employ a Deep Boltzmann Machine (DBM) model of cortical processing to demonstrate that these two different approaches can be combined in the same framework. Based on recent developments in machine learning, we show how neuronal adaptation can be understood as a mechanism that improves probabilistic, sampling-based inference. Using the ambiguous Necker cube image, we analyze the perceptual switching exhibited by the model. We also examine the influence of spatial attention, and explore how binocular rivalry can be modeled with the same approach. Our work joins earlier studies in demonstrating how the principles underlying DBMs relate to cortical processing, and offers novel perspectives on the neural implementation of approximate probabilistic inference in the brain.\n",
      "Unsupervised Pixel-prediction\n",
      "When a sensory system constructs a model of the environment from its input, it might need to verify the model's accuracy. One method of verification is multivariate time-series prediction: a good model could predict the near-future activity of its inputs, much as a good scientific theory predicts future data. Such a predicting model would require copious top-down connections to compare the predictions with the input. That feedback could improve the model's performance in two ways: by biasing internal activity toward expected patterns, and by generating specific error signals if the predictions fail. A proof-of-concept model-an event-driven, computationally efficient layered network, incorporating cortical features like all-excitatory synapses and local inhibition--was constructed to make near-future predictions of a simple, moving stimulus. After unsupervised learning, the network contained units not only tuned to obvious features of the stimulus like contour orientation and motion, but also to contour discontinuity (end-stopping) and illusory contours.\n",
      "A Predictive Switching Model of Cerebellar Movement Control\n",
      "We present a hypothesis about how the cerebellum could participate in regulating movement in the presence of significant feedback delays without resorting to a forward model of the motor plant. We show how a simplified cerebellar model can learn to control end-point positioning of a nonlinear spring-mass system with realistic delays in both afferent and efferent pathways. The model's operation involves prediction, but instead of predicting sensory input, it directly regulates movement by reacting in an anticipatory fashion to input patterns that include delayed sensory feedback.\n",
      "How biased are maximum entropy models\n",
      "Maximum entropy models have become popular statistical models in neuroscience and other areas in biology, and can be useful tools for obtaining estimates of mutual information in biological systems. However, maximum entropy models fit to small data sets can be subject to sampling bias; i.e. the true entropy of the data can be severely underestimated. Here we study the sampling properties of estimates of the entropy obtained from maximum entropy models. We show that if the data is generated by a distribution that lies in the model class, the bias is equal to the number of parameters divided by twice the number of observations. However, in practice, the true distribution is usually outside the model class, and we show here that this misspecification can lead to much larger bias. We provide a perturbative approximation of the maximally expected bias when the true model is out of model class, and we illustrate our results using numerical simulations of an Ising model; i.e. the second-order maximum entropy distribution on binary data.\n",
      "Unsupervised learning of an efficient short-term memory network\n",
      "Learning in recurrent neural networks has been a topic fraught with difficulties and problems. We here report substantial progress in the unsupervised learning of recurrent networks that can keep track of an input signal. Specifically, we show how these networks can learn to efficiently represent their present and past inputs, based on local learning rules only. Our results are based on several key insights. First, we develop a local learning rule for the recurrent weights whose main aim is to drive the network into a regime where, on average, feedforward signal inputs are canceled by recurrent inputs. We show that this learning rule minimizes a cost function. Second, we develop a local learning rule for the feedforward weights that, based on networks in which recurrent inputs already predict feedforward inputs, further minimizes the cost. Third, we show how the learning rules can be modified such that the network can directly encode non-whitened inputs. Fourth, we show that these learning rules can also be applied to a network that feeds a time-delayed version of the network output back into itself. As a consequence, the network starts to efficiently represent both its signal inputs and their history. We develop our main theory for linear networks, but then sketch how the learning rules could be transferred to balanced, spiking networks.\n",
      "Know Thy Neighbour: A Normative Theory of Synaptic Depression\n",
      "Synapses exhibit an extraordinary degree of short-term malleability, with release probabilities and effective synaptic strengths changing markedly over multiple timescales. From the perspective of a fixed computational operation in a network, this seems like a most unacceptable degree of added variability. We suggest an alternative theory according to which short-term synaptic plasticity plays a normatively-justifiable role. This theory starts from the commonplace observation that the spiking of a neuron is an incomplete, digital, report of the analog quantity that contains all the critical information, namely its membrane potential. We suggest that a synapse solves the inverse problem of estimating the pre-synaptic membrane potential from the spikes it receives, acting as a recursive filter. We show that the dynamics of short-term synaptic depression closely resemble those required for optimal filtering, and that they indeed support high quality estimation. Under this account, the local postsynaptic potential and the level of synaptic resources track the (scaled) mean and variance of the estimated presynaptic membrane potential. We make experimentally testable predictions for how the statistics of subthreshold membrane potential fluctuations and the form of spiking non-linearity should be related to the properties of short-term plasticity in any particular cell type.\n",
      "Neural Models for Part-Whole Hierarchies\n",
      "We present a connectionist method for representing images that explicitly addresses their hierarchical nature. It blends data from neuroscience about whole-object viewpoint sensitive cells in inferotemporal cortex and attentional basis-field modulation in V4 with ideas about hierarchical descriptions based on microfeatures. The resulting model makes critical use of bottom-up and top-down pathways for analysis and synthesis. We illustrate the model with a simple example of representing information about faces.\n",
      "LTD Facilitates Learning in a Noisy Environment\n",
      "Long-term potentiation (LTP) has long been held as a biological substrate for associative learning. Recently, evidence has emerged that long-term depression (LTD) results when the presynaptic cell fires after the postsynaptic cell. The computational utility of LTD is explored here. Synaptic modification kernels for both LTP and LTD have been proposed by other laboratories based studies of one postsynaptic unit. Here, the interaction between time-dependent LTP and LTD is studied in small networks.\n",
      "Active Inference in Concept Learning\n",
      "People are active experimenters, not just passive observers, constantly seeking new information relevant to their goals. A reasonable approach to active information gathering is to ask questions and conduct experiments that maximize the expected information gain, given current beliefs (Fedorov 1972, MacKay 1992, Oaksford & Chater 1994). In this paper we present results on an exploratory experiment designed to study people's active information gathering behavior on a concept learning task (Tenenbaum 2000). The results of the experiment are analyzed in terms of the expected information gain of the questions asked by subjects.\n",
      "Neurometric function analysis of population codes\n",
      "The relative merits of different population coding schemes have mostly been analyzed in the framework of stimulus reconstruction using Fisher Information. Here, we consider the case of stimulus discrimination in a two alternative forced choice paradigm and compute neurometric functions in terms of the minimal discrimination error and the Jensen-Shannon information to study neural population codes. We first explore the relationship between minimum discrimination error, Jensen-Shannon Information and Fisher Information and show that the discrimination framework is more informative about the coding accuracy than Fisher Information as it defines an error for any pair of possible stimuli. In particular, it includes Fisher Information as a special case. Second, we use the framework to study population codes of angular variables. Specifically, we assess the impact of different noise correlations structures on coding accuracy in long versus short decoding time windows. That is, for long time window we use the common Gaussian noise approximation. To address the case of short time windows we analyze the Ising model with identical noise correlation structure. In this way, we provide a new rigorous framework for assessing the functional consequences of noise correlation structures for the representational accuracy of neural population codes that is in particular applicable to short-time population coding.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "known_concepts = {\n",
    "    \"Neuroscience\",\n",
    "    \"Psychology\",\n",
    "    \"Visual cortex\",\n",
    "    \"Stimulus (psychology)\",\n",
    "    \"Receptive field\",\n",
    "    \"Perception\",\n",
    "    \"Neural coding\",\n",
    "    \"Sensory system\",\n",
    "    \"Cognitive psychology\",\n",
    "    \"Macaque\",\n",
    "    \"Excitatory postsynaptic potential\",\n",
    "    \"Cognition\",\n",
    "    \"Postsynaptic potential\",\n",
    "    \"Eye movement\",\n",
    "    \"Functional magnetic resonance imaging\",\n",
    "    \"Visual search\",\n",
    "    \"Electroencephalography\",\n",
    "    \"Synaptic plasticity\",\n",
    "    \"Cognitive science\",\n",
    "    \"Long-term potentiation\",\n",
    "    \"Simple cell\",\n",
    "    \"Inhibitory postsynaptic potential\",\n",
    "    \"Hippocampal formation\",\n",
    "    \"Hebbian theory\",\n",
    "    \"Binocular neurons\",\n",
    "    \"Neocortex\",\n",
    "    \"Striate cortex\",\n",
    "    \"Spike-timing-dependent plasticity\",\n",
    "    \"Orientation column\",\n",
    "    \"Metaplasticity\",\n",
    "    \"Brain–computer interface\",\n",
    "    \"Auditory cortex\",\n",
    "    \"Retina\",\n",
    "    \"Somatosensory system\",\n",
    "    \"Surround suppression\",\n",
    "    \"Saccadic masking\",\n",
    "    \"Psychophysics\",\n",
    "    \"Saccade\",\n",
    "    \"Primate\",\n",
    "    \"Spike train\",\n",
    "    \"Neuroimaging\",\n",
    "    \"Gaze\",\n",
    "    \"Nonsynaptic plasticity\",\n",
    "    \"Prefrontal cortex\",\n",
    "    \"Hippocampus\",\n",
    "    \"Adaptation (eye)\",\n",
    "    \"Motor imagery\",\n",
    "    \"Neural decoding\",\n",
    "    \"Neurophysiology\",\n",
    "}\n",
    "\n",
    "known_journals = {\n",
    "    'PLOS Computational Biology',\n",
    "    'Trends in Neurosciences',\n",
    "    'Vision Research',\n",
    "    'Nature Neuroscience',\n",
    "    'Journal of Neurophysiology',\n",
    "    'Neuron',\n",
    "    'Psychological Science',\n",
    "    'Psychological Review',\n",
    "    'Current Opinion in Neurobiology',\n",
    "    'The Journal of Neuroscience',\n",
    "    'Cognition',\n",
    "    'Trends in Cognitive Sciences',\n",
    "    'Journal of experimental psychology',\n",
    "    'Cerebral Cortex',\n",
    "    'The Journal of Physiology',\n",
    "    'Cognitive Psychology',\n",
    "    'PLOS Biology',\n",
    "    'Behavioral and Brain Sciences',\n",
    "    'Journal of Vision',\n",
    "    'Nature Reviews Neuroscience',\n",
    "    'Annual Review of Neuroscience',\n",
    "    'Experimental Brain Research',\n",
    "    'American Journal of Psychology',\n",
    "    'Behavioral Ecology and Sociobiology',\n",
    "    'Neurobiology of Learning and Memory',\n",
    "    \"European Journal of Neuroscience\",\n",
    "    \"Neurocomputing\",\n",
    "    \"Attention Perception & Psychophysics\",\n",
    "    \"Current Biology\",\n",
    "    \"Electroencephalography and Clinical Neurophysiology\",\n",
    "    \"Progress in Brain Research\",\n",
    "    \"Developmental Psychology\",\n",
    "    \"NeuroImage\",\n",
    "    \"Memory & Cognition\",\n",
    "    \"Visual Neuroscience\",\n",
    "    \"Journal of Computational Neuroscience\",\n",
    "    \"Clinical Neurophysiology\",\n",
    "    \"Proceedings of the Annual Meeting of the Cognitive Science Society\",\n",
    "    \"Neuropsychologia\",\n",
    "    \"Quarterly Journal of Experimental Psychology\",\n",
    "    \"Psychonomic Bulletin & Review\",\n",
    "    \"Journal of Cognitive Neuroscience\",\n",
    "    \"Psychology Press eBooks\",\n",
    "    \"Journal of Personality and Social Psychology\",\n",
    "    \"Current Directions in Psychological Science\",\n",
    "    \"Biological Psychology\",\n",
    "    \"Brain and Cognition\",\n",
    "    \"Neurobiology of Learning and Memory\",\n",
    "    \"Spatial Vision\",\n",
    "    \"Human Brain Mapping\",\n",
    "    \"Journal of the Acoustical Society of America\",\n",
    "    \"Journal of Experimental Psychology: General\",\n",
    "    \"Journal of Neural Engineering\",\n",
    "    \"Journal of Neuroscience Methods\",\n",
    "    \"Journal of Educational Psychology\",\n",
    "    \"Brain Research\",\n",
    "    \"Journal of Experimental Psychology: Human Perception and Performance\",\n",
    "    \"Journal of Experimental Psychology: Learning, Memory and Cognition\",\n",
    "    \"Journal of Memory and Language\",\n",
    "    \"Cognitive Science\",\n",
    "    \"Child Development\",\n",
    "    \"Journal of comparative neurology\",\n",
    "    \"Psychological Bulletin\",\n",
    "    \"Psychophysiology\",\n",
    "    \"Brain\",\n",
    "}\n",
    "\n",
    "def get_journal(ref):\n",
    "    if 'primary_location' in ref and 'source' in ref['primary_location'] and ref['primary_location']['source'] is not None and 'display_name' in ref['primary_location']['source']:\n",
    "        return ref['primary_location']['source']['display_name']\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "references = []\n",
    "concepts = collections.Counter()\n",
    "journals = collections.Counter()\n",
    "for idx, row in df_ref.iterrows():\n",
    "    nrefs = 0\n",
    "    refs = row.references\n",
    "    for ref in refs:\n",
    "        concept_view = [(c['level'], c['display_name'], c['id']) for c in ref['concepts'] if c['score'] > .55]\n",
    "        concept_names = {c['display_name'] for c in ref['concepts'] if c['score'] > .55}\n",
    "        journal = get_journal(ref)\n",
    "        if journal in known_journals: #concept_names.intersection(known_concepts) or  or ():\n",
    "            nrefs += 1\n",
    "            concepts.update(concept_view)\n",
    "            journals.update([journal])\n",
    "            references.append(ref)\n",
    "            \n",
    "    if nrefs >= 3:\n",
    "        the_row = df.iloc[idx]\n",
    "        print(the_row.title)\n",
    "        print(the_row.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\",\n",
      "\"Nature\",\n",
      "\"Neural Information Processing Systems\",\n",
      "\"Neural Computation\",\n",
      "\"Science\",\n",
      "\"Proceedings of the National Academy of Sciences of the United States of America\",\n",
      "\"Biological Cybernetics\",\n",
      "\"arXiv (Cornell University)\",\n",
      "\"International Conference on Machine Learning\",\n",
      "\"The MIT Press eBooks\",\n",
      "\"Network: Computation In Neural Systems\",\n",
      "\"IEEE Transactions on Biomedical Engineering\",\n",
      "\"IEEE Transactions on Rehabilitation Engineering\",\n",
      "\"Lecture Notes in Computer Science\",\n",
      "\"Artificial Intelligence\",\n",
      "\"Neural Networks\",\n",
      "\"Proceedings of The Royal Society B: Biological Sciences\",\n",
      "\"MIT Press eBooks\",\n",
      "\"IEEE Transactions on Neural Systems and Rehabilitation Engineering\",\n",
      "\"PubMed\",\n",
      "\"Journal of Machine Learning Research\",\n",
      "\"Meeting of the Association for Computational Linguistics\",\n",
      "\"Journal of Mathematical Biology\",\n",
      "\"Springer eBooks\",\n",
      "\"Journal of the Optical Society of America\",\n",
      "\"Elsevier eBooks\",\n",
      "\"Cambridge University Press eBooks\",\n",
      "\"PLOS ONE\",\n",
      "\"Proceedings of the Royal Society of London\",\n",
      "\"National Conference on Artificial Intelligence\",\n",
      "\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\n",
      "\"IEEE Transactions on Neural Networks\",\n",
      "\"HAL (Le Centre pour la Communication Scientifique Directe)\",\n",
      "\"Physical Review Letters\",\n",
      "\"Choice Reviews Online\",\n",
      "\"Proceedings of SPIE\",\n",
      "\"Philosophical Transactions of the Royal Society B\",\n",
      "\"Oxford University Press eBooks\",\n",
      "\"Nature Methods\",\n",
      "\"IEEE International Conference on Neural Networks\",\n",
      "\"Journal of the American Statistical Association\",\n",
      "\"Proceedings of the IEEE\",\n",
      "\"International Journal of Neural Systems\",\n",
      "\"Machine Learning\",\n"
     ]
    }
   ],
   "source": [
    "for j, num in journals.most_common(100):\n",
    "    if j not in known_journals:\n",
    "        print('\"' + j + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Computer science\",\n",
      "\"Artificial intelligence\",\n",
      "\"Pattern recognition (psychology)\",\n",
      "\"Coding (social sciences)\",\n",
      "\"Spike (software development)\",\n",
      "\"Set (abstract data type)\",\n",
      "\"Context (archaeology)\",\n",
      "\"Inference\",\n",
      "\"Task (project management)\",\n",
      "\"Connectionism\",\n",
      "\"Representation (politics)\",\n",
      "\"Object (grammar)\",\n",
      "\"Bayesian probability\",\n",
      "\"Population\",\n",
      "\"Feature (linguistics)\",\n",
      "\"Orientation (vector space)\",\n",
      "\"Categorization\",\n",
      "\"Computer vision\",\n",
      "\"Benchmark (surveying)\",\n",
      "\"Probabilistic logic\",\n",
      "\"Contrast (vision)\",\n",
      "\"Bayesian inference\",\n",
      "\"Artificial neural network\",\n",
      "\"Independent component analysis\",\n",
      "\"Generalization\",\n",
      "\"Cognitive neuroscience of visual object recognition\",\n",
      "\"Domain adaptation\",\n",
      "\"Domain (mathematical analysis)\",\n",
      "\"Reinforcement learning\",\n",
      "\"Basis (linear algebra)\",\n",
      "\"Spatial frequency\",\n",
      "\"Curse of dimensionality\",\n",
      "\"Decoding methods\",\n",
      "\"Biology\",\n",
      "\"Neuron\",\n",
      "\"Face (sociological concept)\",\n",
      "\"Fixation (population genetics)\",\n",
      "\"Principal component analysis\",\n",
      "\"Nonlinear system\",\n",
      "\"Similarity (geometry)\",\n",
      "\"Action (physics)\",\n",
      "\"Noise (video)\",\n",
      "\"Normalization (sociology)\",\n",
      "\"Overfitting\",\n",
      "\"Infomax\",\n",
      "\"Backpropagation\",\n",
      "\"Component (thermodynamics)\",\n",
      "\"Speech recognition\",\n",
      "\"Detector\",\n",
      "\"Interface (matter)\",\n",
      "\"Machine learning\",\n",
      "\"Variety (cybernetics)\",\n",
      "\"Sparse approximation\",\n",
      "\"Synapse\",\n",
      "\"Associative property\",\n",
      "\"Dropout (neural networks)\",\n",
      "\"Basis function\",\n"
     ]
    }
   ],
   "source": [
    "for (_, name, _), num in concepts.most_common(100):\n",
    "    if name not in known_concepts:\n",
    "        print('\"' + name + '\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorships_to_string(authorships):\n",
    "    names = [a['author'].get('display_name', \"\") for a in authorships]\n",
    "    if len(names) > 5:\n",
    "        return \", \".join(names[:5]) + \", et al.\"\n",
    "    return \", \".join(names)\n",
    "df_sub['author_list'] = df_sub.authorships.map(authorships_to_string)\n",
    "df_sub['journal'] = df_sub.primary_location.map(lambda x: x['source']['display_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[['id', 'title', 'publication_year', 'journal', 'author_list', 'cited_by_count', 'category', 'abstract']].to_csv('../data/processed/neuroai-works.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>ids</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>type</th>\n",
       "      <th>open_access</th>\n",
       "      <th>authorships</th>\n",
       "      <th>...</th>\n",
       "      <th>referenced_works</th>\n",
       "      <th>related_works</th>\n",
       "      <th>ngrams_url</th>\n",
       "      <th>cited_by_api_url</th>\n",
       "      <th>counts_by_year</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>created_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>neuro_related</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_year</th>\n",
       "      <th>journal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <th>Proceedings of the ... AAAI Conference on Artificial Intelligence</th>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2019</th>\n",
       "      <th>Computer Vision and Pattern Recognition</th>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>87</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Computer Vision</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Learning Representations</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>168</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Machine Learning</th>\n",
       "      <td>701</td>\n",
       "      <td>6</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>...</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>493</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Information Processing Systems</th>\n",
       "      <td>1314</td>\n",
       "      <td>12</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>...</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "      <td>1301</td>\n",
       "      <td>1314</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proceedings of the ... AAAI Conference on Artificial Intelligence</th>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>...</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2020</th>\n",
       "      <th>Computer Vision and Pattern Recognition</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Computer Vision</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Learning Representations</th>\n",
       "      <td>677</td>\n",
       "      <td>2</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>...</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>644</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Machine Learning</th>\n",
       "      <td>1058</td>\n",
       "      <td>7</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>...</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>719</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Information Processing Systems</th>\n",
       "      <td>1608</td>\n",
       "      <td>17</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "      <td>1252</td>\n",
       "      <td>1608</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proceedings of the ... AAAI Conference on Artificial Intelligence</th>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>...</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2342</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2021</th>\n",
       "      <th>Computer Vision and Pattern Recognition</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Computer Vision</th>\n",
       "      <td>432</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>324</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Learning Representations</th>\n",
       "      <td>797</td>\n",
       "      <td>4</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>...</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "      <td>738</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Conference on Machine Learning</th>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>...</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>757</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Information Processing Systems</th>\n",
       "      <td>1837</td>\n",
       "      <td>10</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>...</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "      <td>1166</td>\n",
       "      <td>1837</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proceedings of the ... AAAI Conference on Artificial Intelligence</th>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>...</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <th>Proceedings of the ... AAAI Conference on Artificial Intelligence</th>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>...</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       id   \n",
       "publication_year journal                                                    \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...   906  \\\n",
       "2019             Computer Vision and Pattern Recognition              268   \n",
       "                 International Conference on Computer Vision            6   \n",
       "                 International Conference on Learning Representa...   234   \n",
       "                 International Conference on Machine Learning         701   \n",
       "                 Neural Information Processing Systems               1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1383   \n",
       "2020             Computer Vision and Pattern Recognition               12   \n",
       "                 International Conference on Computer Vision           23   \n",
       "                 International Conference on Learning Representa...   677   \n",
       "                 International Conference on Machine Learning        1058   \n",
       "                 Neural Information Processing Systems               1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  2344   \n",
       "2021             Computer Vision and Pattern Recognition                9   \n",
       "                 International Conference on Computer Vision          432   \n",
       "                 International Conference on Learning Representa...   797   \n",
       "                 International Conference on Machine Learning        1113   \n",
       "                 Neural Information Processing Systems               1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...  1142   \n",
       "\n",
       "                                                                      doi   \n",
       "publication_year journal                                                    \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...   906  \\\n",
       "2019             Computer Vision and Pattern Recognition                1   \n",
       "                 International Conference on Computer Vision            0   \n",
       "                 International Conference on Learning Representa...     2   \n",
       "                 International Conference on Machine Learning           6   \n",
       "                 Neural Information Processing Systems                 12   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1383   \n",
       "2020             Computer Vision and Pattern Recognition                1   \n",
       "                 International Conference on Computer Vision            0   \n",
       "                 International Conference on Learning Representa...     2   \n",
       "                 International Conference on Machine Learning           7   \n",
       "                 Neural Information Processing Systems                 17   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  2344   \n",
       "2021             Computer Vision and Pattern Recognition                0   \n",
       "                 International Conference on Computer Vision            6   \n",
       "                 International Conference on Learning Representa...     4   \n",
       "                 International Conference on Machine Learning           5   \n",
       "                 Neural Information Processing Systems                 10   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...  1142   \n",
       "\n",
       "                                                                     title   \n",
       "publication_year journal                                                     \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...    906  \\\n",
       "2019             Computer Vision and Pattern Recognition               268   \n",
       "                 International Conference on Computer Vision             6   \n",
       "                 International Conference on Learning Representa...    234   \n",
       "                 International Conference on Machine Learning          701   \n",
       "                 Neural Information Processing Systems                1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...   1383   \n",
       "2020             Computer Vision and Pattern Recognition                12   \n",
       "                 International Conference on Computer Vision            23   \n",
       "                 International Conference on Learning Representa...    677   \n",
       "                 International Conference on Machine Learning         1058   \n",
       "                 Neural Information Processing Systems                1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...   2344   \n",
       "2021             Computer Vision and Pattern Recognition                 9   \n",
       "                 International Conference on Computer Vision           432   \n",
       "                 International Conference on Learning Representa...    797   \n",
       "                 International Conference on Machine Learning         1113   \n",
       "                 Neural Information Processing Systems                1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...   1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...   1142   \n",
       "\n",
       "                                                                     display_name   \n",
       "publication_year journal                                                            \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...           906  \\\n",
       "2019             Computer Vision and Pattern Recognition                      268   \n",
       "                 International Conference on Computer Vision                    6   \n",
       "                 International Conference on Learning Representa...           234   \n",
       "                 International Conference on Machine Learning                 701   \n",
       "                 Neural Information Processing Systems                       1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1383   \n",
       "2020             Computer Vision and Pattern Recognition                       12   \n",
       "                 International Conference on Computer Vision                   23   \n",
       "                 International Conference on Learning Representa...           677   \n",
       "                 International Conference on Machine Learning                1058   \n",
       "                 Neural Information Processing Systems                       1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          2344   \n",
       "2021             Computer Vision and Pattern Recognition                        9   \n",
       "                 International Conference on Computer Vision                  432   \n",
       "                 International Conference on Learning Representa...           797   \n",
       "                 International Conference on Machine Learning                1113   \n",
       "                 Neural Information Processing Systems                       1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...          1142   \n",
       "\n",
       "                                                                     publication_date   \n",
       "publication_year journal                                                                \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...               906  \\\n",
       "2019             Computer Vision and Pattern Recognition                          268   \n",
       "                 International Conference on Computer Vision                        6   \n",
       "                 International Conference on Learning Representa...               234   \n",
       "                 International Conference on Machine Learning                     701   \n",
       "                 Neural Information Processing Systems                           1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1383   \n",
       "2020             Computer Vision and Pattern Recognition                           12   \n",
       "                 International Conference on Computer Vision                       23   \n",
       "                 International Conference on Learning Representa...               677   \n",
       "                 International Conference on Machine Learning                    1058   \n",
       "                 Neural Information Processing Systems                           1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              2344   \n",
       "2021             Computer Vision and Pattern Recognition                            9   \n",
       "                 International Conference on Computer Vision                      432   \n",
       "                 International Conference on Learning Representa...               797   \n",
       "                 International Conference on Machine Learning                    1113   \n",
       "                 Neural Information Processing Systems                           1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...              1142   \n",
       "\n",
       "                                                                      ids   \n",
       "publication_year journal                                                    \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...   906  \\\n",
       "2019             Computer Vision and Pattern Recognition              268   \n",
       "                 International Conference on Computer Vision            6   \n",
       "                 International Conference on Learning Representa...   234   \n",
       "                 International Conference on Machine Learning         701   \n",
       "                 Neural Information Processing Systems               1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1383   \n",
       "2020             Computer Vision and Pattern Recognition               12   \n",
       "                 International Conference on Computer Vision           23   \n",
       "                 International Conference on Learning Representa...   677   \n",
       "                 International Conference on Machine Learning        1058   \n",
       "                 Neural Information Processing Systems               1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  2344   \n",
       "2021             Computer Vision and Pattern Recognition                9   \n",
       "                 International Conference on Computer Vision          432   \n",
       "                 International Conference on Learning Representa...   797   \n",
       "                 International Conference on Machine Learning        1113   \n",
       "                 Neural Information Processing Systems               1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...  1142   \n",
       "\n",
       "                                                                     primary_location   \n",
       "publication_year journal                                                                \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...               906  \\\n",
       "2019             Computer Vision and Pattern Recognition                          268   \n",
       "                 International Conference on Computer Vision                        6   \n",
       "                 International Conference on Learning Representa...               234   \n",
       "                 International Conference on Machine Learning                     701   \n",
       "                 Neural Information Processing Systems                           1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1383   \n",
       "2020             Computer Vision and Pattern Recognition                           12   \n",
       "                 International Conference on Computer Vision                       23   \n",
       "                 International Conference on Learning Representa...               677   \n",
       "                 International Conference on Machine Learning                    1058   \n",
       "                 Neural Information Processing Systems                           1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              2344   \n",
       "2021             Computer Vision and Pattern Recognition                            9   \n",
       "                 International Conference on Computer Vision                      432   \n",
       "                 International Conference on Learning Representa...               797   \n",
       "                 International Conference on Machine Learning                    1113   \n",
       "                 Neural Information Processing Systems                           1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...              1142   \n",
       "\n",
       "                                                                     type   \n",
       "publication_year journal                                                    \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...   906  \\\n",
       "2019             Computer Vision and Pattern Recognition              268   \n",
       "                 International Conference on Computer Vision            6   \n",
       "                 International Conference on Learning Representa...   234   \n",
       "                 International Conference on Machine Learning         701   \n",
       "                 Neural Information Processing Systems               1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1383   \n",
       "2020             Computer Vision and Pattern Recognition               12   \n",
       "                 International Conference on Computer Vision           23   \n",
       "                 International Conference on Learning Representa...   677   \n",
       "                 International Conference on Machine Learning        1058   \n",
       "                 Neural Information Processing Systems               1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  2344   \n",
       "2021             Computer Vision and Pattern Recognition                9   \n",
       "                 International Conference on Computer Vision          432   \n",
       "                 International Conference on Learning Representa...   797   \n",
       "                 International Conference on Machine Learning        1113   \n",
       "                 Neural Information Processing Systems               1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...  1142   \n",
       "\n",
       "                                                                     open_access   \n",
       "publication_year journal                                                           \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...          906  \\\n",
       "2019             Computer Vision and Pattern Recognition                     268   \n",
       "                 International Conference on Computer Vision                   6   \n",
       "                 International Conference on Learning Representa...          234   \n",
       "                 International Conference on Machine Learning                701   \n",
       "                 Neural Information Processing Systems                      1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         1383   \n",
       "2020             Computer Vision and Pattern Recognition                      12   \n",
       "                 International Conference on Computer Vision                  23   \n",
       "                 International Conference on Learning Representa...          677   \n",
       "                 International Conference on Machine Learning               1058   \n",
       "                 Neural Information Processing Systems                      1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         2344   \n",
       "2021             Computer Vision and Pattern Recognition                       9   \n",
       "                 International Conference on Computer Vision                 432   \n",
       "                 International Conference on Learning Representa...          797   \n",
       "                 International Conference on Machine Learning               1113   \n",
       "                 Neural Information Processing Systems                      1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...         1142   \n",
       "\n",
       "                                                                     authorships   \n",
       "publication_year journal                                                           \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...          906  \\\n",
       "2019             Computer Vision and Pattern Recognition                     268   \n",
       "                 International Conference on Computer Vision                   6   \n",
       "                 International Conference on Learning Representa...          234   \n",
       "                 International Conference on Machine Learning                701   \n",
       "                 Neural Information Processing Systems                      1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         1383   \n",
       "2020             Computer Vision and Pattern Recognition                      12   \n",
       "                 International Conference on Computer Vision                  23   \n",
       "                 International Conference on Learning Representa...          677   \n",
       "                 International Conference on Machine Learning               1058   \n",
       "                 Neural Information Processing Systems                      1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         2344   \n",
       "2021             Computer Vision and Pattern Recognition                       9   \n",
       "                 International Conference on Computer Vision                 432   \n",
       "                 International Conference on Learning Representa...          797   \n",
       "                 International Conference on Machine Learning               1113   \n",
       "                 Neural Information Processing Systems                      1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...         1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...         1142   \n",
       "\n",
       "                                                                     ...   \n",
       "publication_year journal                                             ...   \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...  ...  \\\n",
       "2019             Computer Vision and Pattern Recognition             ...   \n",
       "                 International Conference on Computer Vision         ...   \n",
       "                 International Conference on Learning Representa...  ...   \n",
       "                 International Conference on Machine Learning        ...   \n",
       "                 Neural Information Processing Systems               ...   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  ...   \n",
       "2020             Computer Vision and Pattern Recognition             ...   \n",
       "                 International Conference on Computer Vision         ...   \n",
       "                 International Conference on Learning Representa...  ...   \n",
       "                 International Conference on Machine Learning        ...   \n",
       "                 Neural Information Processing Systems               ...   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  ...   \n",
       "2021             Computer Vision and Pattern Recognition             ...   \n",
       "                 International Conference on Computer Vision         ...   \n",
       "                 International Conference on Learning Representa...  ...   \n",
       "                 International Conference on Machine Learning        ...   \n",
       "                 Neural Information Processing Systems               ...   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...  ...   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...  ...   \n",
       "\n",
       "                                                                     referenced_works   \n",
       "publication_year journal                                                                \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...               906  \\\n",
       "2019             Computer Vision and Pattern Recognition                          268   \n",
       "                 International Conference on Computer Vision                        6   \n",
       "                 International Conference on Learning Representa...               234   \n",
       "                 International Conference on Machine Learning                     701   \n",
       "                 Neural Information Processing Systems                           1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1383   \n",
       "2020             Computer Vision and Pattern Recognition                           12   \n",
       "                 International Conference on Computer Vision                       23   \n",
       "                 International Conference on Learning Representa...               677   \n",
       "                 International Conference on Machine Learning                    1058   \n",
       "                 Neural Information Processing Systems                           1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              2344   \n",
       "2021             Computer Vision and Pattern Recognition                            9   \n",
       "                 International Conference on Computer Vision                      432   \n",
       "                 International Conference on Learning Representa...               797   \n",
       "                 International Conference on Machine Learning                    1113   \n",
       "                 Neural Information Processing Systems                           1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...              1142   \n",
       "\n",
       "                                                                     related_works   \n",
       "publication_year journal                                                             \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...            906  \\\n",
       "2019             Computer Vision and Pattern Recognition                       268   \n",
       "                 International Conference on Computer Vision                     6   \n",
       "                 International Conference on Learning Representa...            234   \n",
       "                 International Conference on Machine Learning                  701   \n",
       "                 Neural Information Processing Systems                        1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           1383   \n",
       "2020             Computer Vision and Pattern Recognition                        12   \n",
       "                 International Conference on Computer Vision                    23   \n",
       "                 International Conference on Learning Representa...            677   \n",
       "                 International Conference on Machine Learning                 1058   \n",
       "                 Neural Information Processing Systems                        1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           2344   \n",
       "2021             Computer Vision and Pattern Recognition                         9   \n",
       "                 International Conference on Computer Vision                   432   \n",
       "                 International Conference on Learning Representa...            797   \n",
       "                 International Conference on Machine Learning                 1113   \n",
       "                 Neural Information Processing Systems                        1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...           1142   \n",
       "\n",
       "                                                                     ngrams_url   \n",
       "publication_year journal                                                          \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...         906  \\\n",
       "2019             Computer Vision and Pattern Recognition                    268   \n",
       "                 International Conference on Computer Vision                  6   \n",
       "                 International Conference on Learning Representa...         234   \n",
       "                 International Conference on Machine Learning               701   \n",
       "                 Neural Information Processing Systems                     1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...        1383   \n",
       "2020             Computer Vision and Pattern Recognition                     12   \n",
       "                 International Conference on Computer Vision                 23   \n",
       "                 International Conference on Learning Representa...         677   \n",
       "                 International Conference on Machine Learning              1058   \n",
       "                 Neural Information Processing Systems                     1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...        2344   \n",
       "2021             Computer Vision and Pattern Recognition                      9   \n",
       "                 International Conference on Computer Vision                432   \n",
       "                 International Conference on Learning Representa...         797   \n",
       "                 International Conference on Machine Learning              1113   \n",
       "                 Neural Information Processing Systems                     1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...        1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...        1142   \n",
       "\n",
       "                                                                     cited_by_api_url   \n",
       "publication_year journal                                                                \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...               906  \\\n",
       "2019             Computer Vision and Pattern Recognition                          268   \n",
       "                 International Conference on Computer Vision                        6   \n",
       "                 International Conference on Learning Representa...               234   \n",
       "                 International Conference on Machine Learning                     701   \n",
       "                 Neural Information Processing Systems                           1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1383   \n",
       "2020             Computer Vision and Pattern Recognition                           12   \n",
       "                 International Conference on Computer Vision                       23   \n",
       "                 International Conference on Learning Representa...               677   \n",
       "                 International Conference on Machine Learning                    1058   \n",
       "                 Neural Information Processing Systems                           1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              2344   \n",
       "2021             Computer Vision and Pattern Recognition                            9   \n",
       "                 International Conference on Computer Vision                      432   \n",
       "                 International Conference on Learning Representa...               797   \n",
       "                 International Conference on Machine Learning                    1113   \n",
       "                 Neural Information Processing Systems                           1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...              1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...              1142   \n",
       "\n",
       "                                                                     counts_by_year   \n",
       "publication_year journal                                                              \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...             906  \\\n",
       "2019             Computer Vision and Pattern Recognition                        268   \n",
       "                 International Conference on Computer Vision                      6   \n",
       "                 International Conference on Learning Representa...             234   \n",
       "                 International Conference on Machine Learning                   701   \n",
       "                 Neural Information Processing Systems                         1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...            1383   \n",
       "2020             Computer Vision and Pattern Recognition                         12   \n",
       "                 International Conference on Computer Vision                     23   \n",
       "                 International Conference on Learning Representa...             677   \n",
       "                 International Conference on Machine Learning                  1058   \n",
       "                 Neural Information Processing Systems                         1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...            2344   \n",
       "2021             Computer Vision and Pattern Recognition                          9   \n",
       "                 International Conference on Computer Vision                    432   \n",
       "                 International Conference on Learning Representa...             797   \n",
       "                 International Conference on Machine Learning                  1113   \n",
       "                 Neural Information Processing Systems                         1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...            1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...            1142   \n",
       "\n",
       "                                                                     updated_date   \n",
       "publication_year journal                                                            \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...           906  \\\n",
       "2019             Computer Vision and Pattern Recognition                      268   \n",
       "                 International Conference on Computer Vision                    6   \n",
       "                 International Conference on Learning Representa...           234   \n",
       "                 International Conference on Machine Learning                 701   \n",
       "                 Neural Information Processing Systems                       1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1383   \n",
       "2020             Computer Vision and Pattern Recognition                       12   \n",
       "                 International Conference on Computer Vision                   23   \n",
       "                 International Conference on Learning Representa...           677   \n",
       "                 International Conference on Machine Learning                1058   \n",
       "                 Neural Information Processing Systems                       1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          2344   \n",
       "2021             Computer Vision and Pattern Recognition                        9   \n",
       "                 International Conference on Computer Vision                  432   \n",
       "                 International Conference on Learning Representa...           797   \n",
       "                 International Conference on Machine Learning                1113   \n",
       "                 Neural Information Processing Systems                       1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...          1142   \n",
       "\n",
       "                                                                     created_date   \n",
       "publication_year journal                                                            \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...           906  \\\n",
       "2019             Computer Vision and Pattern Recognition                      268   \n",
       "                 International Conference on Computer Vision                    6   \n",
       "                 International Conference on Learning Representa...           234   \n",
       "                 International Conference on Machine Learning                 701   \n",
       "                 Neural Information Processing Systems                       1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1383   \n",
       "2020             Computer Vision and Pattern Recognition                       12   \n",
       "                 International Conference on Computer Vision                   23   \n",
       "                 International Conference on Learning Representa...           677   \n",
       "                 International Conference on Machine Learning                1058   \n",
       "                 Neural Information Processing Systems                       1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          2344   \n",
       "2021             Computer Vision and Pattern Recognition                        9   \n",
       "                 International Conference on Computer Vision                  432   \n",
       "                 International Conference on Learning Representa...           797   \n",
       "                 International Conference on Machine Learning                1113   \n",
       "                 Neural Information Processing Systems                       1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...          1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...          1142   \n",
       "\n",
       "                                                                     abstract   \n",
       "publication_year journal                                                        \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...       906  \\\n",
       "2019             Computer Vision and Pattern Recognition                   87   \n",
       "                 International Conference on Computer Vision                1   \n",
       "                 International Conference on Learning Representa...       168   \n",
       "                 International Conference on Machine Learning             493   \n",
       "                 Neural Information Processing Systems                   1301   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      1383   \n",
       "2020             Computer Vision and Pattern Recognition                    3   \n",
       "                 International Conference on Computer Vision               20   \n",
       "                 International Conference on Learning Representa...       644   \n",
       "                 International Conference on Machine Learning             719   \n",
       "                 Neural Information Processing Systems                   1252   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      2342   \n",
       "2021             Computer Vision and Pattern Recognition                    2   \n",
       "                 International Conference on Computer Vision              324   \n",
       "                 International Conference on Learning Representa...       738   \n",
       "                 International Conference on Machine Learning             757   \n",
       "                 Neural Information Processing Systems                   1166   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...      1142   \n",
       "\n",
       "                                                                     neuro_related   \n",
       "publication_year journal                                                             \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...            906  \\\n",
       "2019             Computer Vision and Pattern Recognition                       268   \n",
       "                 International Conference on Computer Vision                     6   \n",
       "                 International Conference on Learning Representa...            234   \n",
       "                 International Conference on Machine Learning                  701   \n",
       "                 Neural Information Processing Systems                        1314   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           1383   \n",
       "2020             Computer Vision and Pattern Recognition                        12   \n",
       "                 International Conference on Computer Vision                    23   \n",
       "                 International Conference on Learning Representa...            677   \n",
       "                 International Conference on Machine Learning                 1058   \n",
       "                 Neural Information Processing Systems                        1608   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           2344   \n",
       "2021             Computer Vision and Pattern Recognition                         9   \n",
       "                 International Conference on Computer Vision                   432   \n",
       "                 International Conference on Learning Representa...            797   \n",
       "                 International Conference on Machine Learning                 1113   \n",
       "                 Neural Information Processing Systems                        1837   \n",
       "                 Proceedings of the ... AAAI Conference on Artif...           1945   \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...           1142   \n",
       "\n",
       "                                                                     category  \n",
       "publication_year journal                                                       \n",
       "2018             Proceedings of the ... AAAI Conference on Artif...       906  \n",
       "2019             Computer Vision and Pattern Recognition                  268  \n",
       "                 International Conference on Computer Vision                6  \n",
       "                 International Conference on Learning Representa...       234  \n",
       "                 International Conference on Machine Learning             701  \n",
       "                 Neural Information Processing Systems                   1314  \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      1383  \n",
       "2020             Computer Vision and Pattern Recognition                   12  \n",
       "                 International Conference on Computer Vision               23  \n",
       "                 International Conference on Learning Representa...       677  \n",
       "                 International Conference on Machine Learning            1058  \n",
       "                 Neural Information Processing Systems                   1608  \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      2344  \n",
       "2021             Computer Vision and Pattern Recognition                    9  \n",
       "                 International Conference on Computer Vision              432  \n",
       "                 International Conference on Learning Representa...       797  \n",
       "                 International Conference on Machine Learning            1113  \n",
       "                 Neural Information Processing Systems                   1837  \n",
       "                 Proceedings of the ... AAAI Conference on Artif...      1945  \n",
       "2022             Proceedings of the ... AAAI Conference on Artif...      1142  \n",
       "\n",
       "[20 rows x 33 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['journal'] = df.primary_location.map(lambda x: x['source']['display_name'])\n",
    "df.groupby(['publication_year', 'journal']).count().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(df[\"neuro_related\"] == 1).sum()\n",
    "len(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroai-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
